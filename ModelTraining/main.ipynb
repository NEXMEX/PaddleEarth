{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 第十一届 “中国软件杯”百度遥感赛项：变化检测功能\n",
    "\n",
    "## 比赛介绍\n",
    "---\n",
    "\n",
    "“中国软件杯”大学生软件设计大赛是一项面向中国在校学生的公益性赛事，是2021年全国普通高校大学生竞赛榜单内竞赛。大赛由国家工业和信息化部、教育部、江苏省人民政府共同主办，致力于正确引导我国在校学生积极参加软件科研活动，切实增强自我创新能力和实际动手能力，为我国软件和信息技术服务业培养出更多高端、优秀的人才。2022年，百度飞桨承办了A组和B组两个赛道，本赛题为A组。\n",
    "\n",
    "[比赛官网链接](https://aistudio.baidu.com/aistudio/competition/detail/151/0/introduction)\n",
    "\n",
    "### 赛题背景\n",
    "\n",
    "掌握国土资源利用和土地覆盖类型，是地理国情普查与监测的重要内容。高效获取准确、客观的土地利用情况，监测国土变化情况，可以为国家和地方提供地理国情信息决策支撑。随着遥感、传感器技术的发展，特别是多时相高分辨率遥感图像数据的普及，使我们可以足不出户，就能掌握全球任一地表的细微变化。\n",
    "\n",
    "目前，我国遥感领域已步入了高分辨率影像的快车道，对遥感数据的分析应用服务的需求也与日俱增。传统方式对高分辨率卫星遥感图像的对特征刻画能力差且依赖人工经验工作量巨大。随着人工智能技术的兴起，特别是基于深度学习的图像识别方法获得了极大的发展，相关技术也推动了遥感领域的变革。相对于传统基于人海战术的目视解译方法，基于深度学习的遥感图像识别技术可以自动分析图像中的地物类型，在准确率和效率方面展现出极大的潜力。\n",
    "\n",
    "此次赛题由百度飞桨和[北航LEVIR团队](http://levir.buaa.edu.cn/) 共同设置，要求选手使用百度AI Studio平台进行训练，基于国产化人工智能框架——百度飞桨PaddlePaddle框架进行开发，设计并开发一个可以通过深度学习技术实现对遥感图像自动解译的WEB系统。\n",
    "\n",
    "### 任务说明\n",
    "\n",
    "变化检测部分要求参赛者利用提供的训练数据，实现对多时相图像中的建筑变化检测。具体而言，多时相遥感图像建筑物变化检测任务是给定两张不同时间拍摄的相同位置（地理配准）的遥感图像，要求定位出其中建筑变化的区域。\n",
    "\n",
    "参考链接：[什么是遥感影像变化检测？](https://baike.baidu.com/item/%E5%8F%98%E5%8C%96%E6%A3%80%E6%B5%8B/8636264)\n",
    "\n",
    "### 数据集介绍\n",
    "\n",
    "参见[数据集链接](https://aistudio.baidu.com/aistudio/datasetdetail/134796)和[赛题说明](https://aistudio.baidu.com/aistudio/competition/detail/151/0/task-definition)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-07-06T08:48:43.573790Z",
     "iopub.status.busy": "2022-07-06T08:48:43.573567Z",
     "iopub.status.idle": "2022-07-06T08:49:22.297781Z",
     "shell.execute_reply": "2022-07-06T08:49:22.296519Z",
     "shell.execute_reply.started": "2022-07-06T08:48:43.573767Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 解压数据集\n",
    "# 该操作涉及大量文件IO，可能需要一些时间\n",
    "!unzip -o -d /home/aistudio/data/data134796/dataset /home/aistudio/data/data134796/train_data.zip > /dev/null\n",
    "!unzip -o -d /home/aistudio/data/data134796/dataset /home/aistudio/data/data134796/test_data.zip > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-07-06T08:49:22.301074Z",
     "iopub.status.busy": "2022-07-06T08:49:22.300428Z",
     "iopub.status.idle": "2022-07-06T08:49:22.419377Z",
     "shell.execute_reply": "2022-07-06T08:49:22.418478Z",
     "shell.execute_reply.started": "2022-07-06T08:49:22.301040Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集划分已完成。\n"
     ]
    }
   ],
   "source": [
    "# 划分训练集/验证集，并生成文件名列表\n",
    "\n",
    "import random\n",
    "import os.path as osp\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "# 随机数生成器种子\n",
    "RNG_SEED = 114514\n",
    "# 调节此参数控制训练集数据的占比\n",
    "TRAIN_RATIO = 0.985\n",
    "# 数据集路径\n",
    "DATA_DIR = '/home/aistudio/data/data134796/dataset/'\n",
    "\n",
    "\n",
    "def write_rel_paths(phase, names, out_dir, prefix=''):\n",
    "    \"\"\"将文件相对路径存储在txt格式文件中\"\"\"\n",
    "    with open(osp.join(out_dir, phase+'.txt'), 'w') as f:\n",
    "        for name in names:\n",
    "            f.write(\n",
    "                ' '.join([\n",
    "                    osp.join(prefix, 'A', name),\n",
    "                    osp.join(prefix, 'B', name),\n",
    "                    osp.join(prefix, 'label', name)\n",
    "                ])\n",
    "            )\n",
    "            f.write('\\n')\n",
    "\n",
    "\n",
    "random.seed(RNG_SEED)\n",
    "\n",
    "# 随机划分训练集/验证集\n",
    "names = list(map(osp.basename, glob(osp.join(DATA_DIR, 'train', 'label', '*.png'))))\n",
    "# 对文件名进行排序，以确保多次运行结果一致\n",
    "names.sort()\n",
    "random.shuffle(names)\n",
    "len_train = int(len(names)*TRAIN_RATIO) # 向下取整\n",
    "write_rel_paths('train', names[:len_train], DATA_DIR, prefix='train')\n",
    "write_rel_paths('val', names[len_train:], DATA_DIR, prefix='train')\n",
    "\n",
    "# 处理测试集\n",
    "test_names = map(osp.basename, glob(osp.join(DATA_DIR, 'test', 'A', '*.png')))\n",
    "test_names = sorted(test_names)\n",
    "write_rel_paths(\n",
    "    'test', \n",
    "    test_names, \n",
    "    DATA_DIR,\n",
    "    prefix='test'\n",
    ")\n",
    "\n",
    "print(\"数据集划分已完成。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练与推理\n",
    "---\n",
    "\n",
    "本项目使用[PaddleRS](https://github.com/PaddleCV-SIG/PaddleRS)套件搭建模型训练与推理框架。PaddleRS是基于飞桨开发的遥感处理平台，支持遥感图像分类、目标检测、图像分割、以及变化检测等常用遥感任务，能够帮助开发者更便捷地完成从训练到部署全流程遥感深度学习应用。在变化检测方面，PaddleRS目前支持9个state-of-the-art（SOTA）模型，且复杂的训练和推理过程被封装到数个API中，能够提供开箱即用的用户体验。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T08:49:22.420746Z",
     "iopub.status.busy": "2022-07-06T08:49:22.420469Z",
     "iopub.status.idle": "2022-07-06T08:49:33.836594Z",
     "shell.execute_reply": "2022-07-06T08:49:33.835218Z",
     "shell.execute_reply.started": "2022-07-06T08:49:22.420722Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: 无法将'/home/aistudio/PaddleRS-develop' 移动至'/home/aistudio/PaddleRS/PaddleRS-develop': 目录非空\n"
     ]
    }
   ],
   "source": [
    "# 安装第三方库\n",
    "!pip install scikit-image > /dev/null\n",
    "!pip install matplotlib==3.4 > /dev/null\n",
    "\n",
    "# 安装PaddleRS（AI Studio上缓存的版本）\n",
    "!unzip -o -d /home/aistudio/ /home/aistudio/data/data135375/PaddleRS-develop.zip > /dev/null\n",
    "!mv /home/aistudio/PaddleRS-develop /home/aistudio/PaddleRS\n",
    "!pip install -e /home/aistudio/PaddleRS > /dev/null\n",
    "# 因为`sys.path`可能没有及时更新，这里选择手动更新\n",
    "import sys\n",
    "sys.path.append('/home/aistudio/PaddleRS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T08:49:33.838664Z",
     "iopub.status.busy": "2022-07-06T08:49:33.838157Z",
     "iopub.status.idle": "2022-07-06T08:49:38.350278Z",
     "shell.execute_reply": "2022-07-06T08:49:38.349390Z",
     "shell.execute_reply.started": "2022-07-06T08:49:33.838633Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:130: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if data.dtype == np.object:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07-06 16:49:37 MainThread @utils.py:79] WRN paddlepaddle version: 2.2.2. The dynamic graph version of PARL is under development, not fully tested and supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-06 16:49:37,812-WARNING: VersionError: PaddlePaddle version 2.3.0 or higher is required, but 2.2.2 installed, please upgrade your PaddlePaddle to 2.3.0 or other higher version.\n",
      "2022-07-06 16:49:37,813-WARNING: If you want to use training-aware and post-training quantization, please use Paddle >= {min_paddle_version} or develop version\n",
      "2022-07-06 16:49:38,229-WARNING: cannot import name 'quant_post' from 'paddleslim.quant' (/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim/quant/__init__.py)\n"
     ]
    }
   ],
   "source": [
    "# 导入一些需要用到的库\n",
    "\n",
    "import random\n",
    "import os\n",
    "import os.path as osp\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddlers as pdrs\n",
    "from paddlers import transforms as T\n",
    "from skimage.io import imread, imsave\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T08:49:38.351950Z",
     "iopub.status.busy": "2022-07-06T08:49:38.351522Z",
     "iopub.status.idle": "2022-07-06T08:49:38.357283Z",
     "shell.execute_reply": "2022-07-06T08:49:38.356581Z",
     "shell.execute_reply.started": "2022-07-06T08:49:38.351919Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义全局变量\n",
    "# 可在此处调整实验所用超参数\n",
    "\n",
    "# 随机种子\n",
    "SEED = 1919810\n",
    "\n",
    "# 数据集路径\n",
    "DATA_DIR = '/home/aistudio/data/data134796/dataset/'\n",
    "# 实验路径。实验目录下保存输出的模型权重和结果\n",
    "EXP_DIR = '/home/aistudio/exp/'\n",
    "# 保存最佳模型的路径\n",
    "BEST_CKP_PATH = osp.join(EXP_DIR, 'best_model', 'model.pdparams')\n",
    "\n",
    "# 训练的epoch数\n",
    "NUM_EPOCHS = 500\n",
    "# 每多少个epoch保存一次模型权重参数\n",
    "SAVE_INTERVAL_EPOCHS = 10\n",
    "# 初始学习率\n",
    "LR = 0.001\n",
    "# 学习率衰减步长（注意，单位为迭代次数而非epoch数），即每多少次迭代将学习率衰减一半\n",
    "DECAY_STEP = 1000\n",
    "# 训练阶段 batch size\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "# 推理阶段 batch size\n",
    "INFER_BATCH_SIZE = 16\n",
    "# 加载数据所使用的进程数\n",
    "NUM_WORKERS = 4\n",
    "# 裁块大小\n",
    "CROP_SIZE = 512\n",
    "# 模型推理阶段使用的滑窗步长\n",
    "STRIDE = 64\n",
    "# 影像原始大小\n",
    "ORIGINAL_SIZE = (1024, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T08:49:38.358673Z",
     "iopub.status.busy": "2022-07-06T08:49:38.358359Z",
     "iopub.status.idle": "2022-07-06T08:49:39.630951Z",
     "shell.execute_reply": "2022-07-06T08:49:39.630115Z",
     "shell.execute_reply.started": "2022-07-06T08:49:38.358648Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<paddle.fluid.core_avx.Generator at 0x7f22a5f9a1b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 固定随机种子，尽可能使实验结果可复现\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "paddle.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T08:49:39.632907Z",
     "iopub.status.busy": "2022-07-06T08:49:39.632188Z",
     "iopub.status.idle": "2022-07-06T08:49:40.365917Z",
     "shell.execute_reply": "2022-07-06T08:49:40.364966Z",
     "shell.execute_reply.started": "2022-07-06T08:49:39.632870Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义一些辅助函数\n",
    "\n",
    "def info(msg, **kwargs):\n",
    "    print(msg, **kwargs)\n",
    "\n",
    "\n",
    "def warn(msg, **kwargs):\n",
    "    print('\\033[0;31m'+msg, **kwargs)\n",
    "\n",
    "\n",
    "def quantize(arr):\n",
    "    return (arr*255).astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 模型构建\n",
    "\n",
    "作为演示，本项目选用LEVIR小组2021年的作品——基于Transformer的变化检测模型BIT-CD[1]。原论文请参考[此链接](https://ieeexplore.ieee.org/document/9491802)，原作者官方实现请参考[此链接](https://github.com/justchenhao/BIT_CD)。\n",
    "\n",
    "> [1] Hao Chen, Zipeng Qi, and Zhenwei Shi. **Remote Sensing Image Change Detection with Transformers.** *IEEE Transactions on Geoscience and Remote Sensing.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T08:49:40.367644Z",
     "iopub.status.busy": "2022-07-06T08:49:40.367182Z",
     "iopub.status.idle": "2022-07-06T08:49:43.658202Z",
     "shell.execute_reply": "2022-07-06T08:49:43.657231Z",
     "shell.execute_reply.started": "2022-07-06T08:49:40.367613Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0706 16:49:40.550621  2333 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 10.1\n",
      "W0706 16:49:40.554858  2333 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n"
     ]
    }
   ],
   "source": [
    "# 调用PaddleRS API一键构建模型\n",
    "model = pdrs.tasks.BIT(\n",
    "    # 模型输出类别数\n",
    "    num_classes=2,\n",
    "    # 是否使用混合损失函数，默认使用交叉熵损失函数训练\n",
    "    use_mixed_loss=False,\n",
    "    # 模型输入通道数\n",
    "    in_channels=3,\n",
    "    # 模型使用的骨干网络，支持'resnet18'或'resnet34'\n",
    "    backbone='resnet34',\n",
    "    # 骨干网络中的resnet stage数量\n",
    "    n_stages=4,\n",
    "    # 是否使用tokenizer获取语义token\n",
    "    use_tokenizer=True,\n",
    "    # token的长度\n",
    "    token_len=4,\n",
    "    # 若不使用tokenizer，则使用池化方式获取token。此参数设置池化模式，有'max'和'avg'两种选项，分别对应最大池化与平均池化\n",
    "    pool_mode='max',\n",
    "    # 池化操作输出特征图的宽和高（池化方式得到的token的长度为pool_size的平方）\n",
    "    pool_size=2,\n",
    "    # 是否在Transformer编码器中加入位置编码（positional embedding）\n",
    "    enc_with_pos=True,\n",
    "    # Transformer编码器使用的注意力模块（attention block）个数\n",
    "    enc_depth=2,\n",
    "    # Transformer编码器中每个注意力头的嵌入维度（embedding dimension）\n",
    "    enc_head_dim=64,\n",
    "    # Transformer解码器使用的注意力模块个数\n",
    "    dec_depth=8,\n",
    "    # Transformer解码器中每个注意力头的嵌入维度\n",
    "    dec_head_dim=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T08:49:43.660018Z",
     "iopub.status.busy": "2022-07-06T08:49:43.659582Z",
     "iopub.status.idle": "2022-07-06T08:49:43.669133Z",
     "shell.execute_reply": "2022-07-06T08:49:43.668425Z",
     "shell.execute_reply.started": "2022-07-06T08:49:43.659990Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BIT(\n",
       "  (backbone): Backbone(\n",
       "    (resnet): ResNet(\n",
       "      (conv1): Conv2D(3, 64, kernel_size=[7, 7], stride=[2, 2], padding=3, data_format=NCHW)\n",
       "      (bn1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)\n",
       "      (relu): ReLU()\n",
       "      (maxpool): MaxPool2D(kernel_size=3, stride=2, padding=1)\n",
       "      (layer1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (bn1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)\n",
       "          (relu): ReLU()\n",
       "          (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (bn2): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (bn1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)\n",
       "          (relu): ReLU()\n",
       "          (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (bn2): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (bn1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)\n",
       "          (relu): ReLU()\n",
       "          (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (bn2): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2D(64, 128, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)\n",
       "          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)\n",
       "          (relu): ReLU()\n",
       "          (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2D(64, 128, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW)\n",
       "            (1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)\n",
       "          (relu): ReLU()\n",
       "          (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)\n",
       "          (relu): ReLU()\n",
       "          (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)\n",
       "        )\n",
       "        (3): BasicBlock(\n",
       "          (conv1): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)\n",
       "          (relu): ReLU()\n",
       "          (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2D(128, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "          (relu): ReLU()\n",
       "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2D(128, 256, kernel_size=[1, 1], data_format=NCHW)\n",
       "            (1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "          (relu): ReLU()\n",
       "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "          (relu): ReLU()\n",
       "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "        )\n",
       "        (3): BasicBlock(\n",
       "          (conv1): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "          (relu): ReLU()\n",
       "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "        )\n",
       "        (4): BasicBlock(\n",
       "          (conv1): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "          (relu): ReLU()\n",
       "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "        )\n",
       "        (5): BasicBlock(\n",
       "          (conv1): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "          (relu): ReLU()\n",
       "          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Identity()\n",
       "      (avgpool): Identity()\n",
       "      (fc): Identity()\n",
       "    )\n",
       "    (upsample): Upsample(scale_factor=2, mode=nearest, align_corners=False, align_mode=0, data_format=NCHW)\n",
       "    (conv_out): Conv3x3(\n",
       "      (seq): Sequential(\n",
       "        (0): Pad2D(padding=[1, 1, 1, 1], mode=constant, value=0.0, data_format=NCHW)\n",
       "        (1): Conv2D(256, 32, kernel_size=[3, 3], data_format=NCHW)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_att): Conv1x1(\n",
       "    (seq): Sequential(\n",
       "      (0): Conv2D(32, 4, kernel_size=[1, 1], data_format=NCHW)\n",
       "    )\n",
       "  )\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): LayerList(\n",
       "      (0): LayerList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm(normalized_shape=[32], epsilon=1e-05)\n",
       "            (fn): SelfAttention(\n",
       "              (fc_q): Linear(in_features=32, out_features=512, dtype=float32)\n",
       "              (fc_k): Linear(in_features=32, out_features=512, dtype=float32)\n",
       "              (fc_v): Linear(in_features=32, out_features=512, dtype=float32)\n",
       "              (fc_out): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=32, dtype=float32)\n",
       "                (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm(normalized_shape=[32], epsilon=1e-05)\n",
       "            (fn): FeedForward(\n",
       "              (0): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (1): GELU(approximate=False)\n",
       "              (2): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "              (3): Linear(in_features=64, out_features=32, dtype=float32)\n",
       "              (4): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): LayerList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm(normalized_shape=[32], epsilon=1e-05)\n",
       "            (fn): SelfAttention(\n",
       "              (fc_q): Linear(in_features=32, out_features=512, dtype=float32)\n",
       "              (fc_k): Linear(in_features=32, out_features=512, dtype=float32)\n",
       "              (fc_v): Linear(in_features=32, out_features=512, dtype=float32)\n",
       "              (fc_out): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=32, dtype=float32)\n",
       "                (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm(normalized_shape=[32], epsilon=1e-05)\n",
       "            (fn): FeedForward(\n",
       "              (0): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (1): GELU(approximate=False)\n",
       "              (2): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "              (3): Linear(in_features=64, out_features=32, dtype=float32)\n",
       "              (4): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (layers): LayerList(\n",
       "      (0): LayerList(\n",
       "        (0): Residual2(\n",
       "          (fn): PreNorm2(\n",
       "            (norm): LayerNorm(normalized_shape=[32], epsilon=1e-05)\n",
       "            (fn): CrossAttention(\n",
       "              (fc_q): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (fc_k): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (fc_v): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (fc_out): Sequential(\n",
       "                (0): Linear(in_features=64, out_features=32, dtype=float32)\n",
       "                (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm(normalized_shape=[32], epsilon=1e-05)\n",
       "            (fn): FeedForward(\n",
       "              (0): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (1): GELU(approximate=False)\n",
       "              (2): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "              (3): Linear(in_features=64, out_features=32, dtype=float32)\n",
       "              (4): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): LayerList(\n",
       "        (0): Residual2(\n",
       "          (fn): PreNorm2(\n",
       "            (norm): LayerNorm(normalized_shape=[32], epsilon=1e-05)\n",
       "            (fn): CrossAttention(\n",
       "              (fc_q): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (fc_k): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (fc_v): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (fc_out): Sequential(\n",
       "                (0): Linear(in_features=64, out_features=32, dtype=float32)\n",
       "                (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm(normalized_shape=[32], epsilon=1e-05)\n",
       "            (fn): FeedForward(\n",
       "              (0): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (1): GELU(approximate=False)\n",
       "              (2): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "              (3): Linear(in_features=64, out_features=32, dtype=float32)\n",
       "              (4): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): LayerList(\n",
       "        (0): Residual2(\n",
       "          (fn): PreNorm2(\n",
       "            (norm): LayerNorm(normalized_shape=[32], epsilon=1e-05)\n",
       "            (fn): CrossAttention(\n",
       "              (fc_q): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (fc_k): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (fc_v): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (fc_out): Sequential(\n",
       "                (0): Linear(in_features=64, out_features=32, dtype=float32)\n",
       "                (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm(normalized_shape=[32], epsilon=1e-05)\n",
       "            (fn): FeedForward(\n",
       "              (0): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (1): GELU(approximate=False)\n",
       "              (2): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "              (3): Linear(in_features=64, out_features=32, dtype=float32)\n",
       "              (4): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): LayerList(\n",
       "        (0): Residual2(\n",
       "          (fn): PreNorm2(\n",
       "            (norm): LayerNorm(normalized_shape=[32], epsilon=1e-05)\n",
       "            (fn): CrossAttention(\n",
       "              (fc_q): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (fc_k): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (fc_v): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (fc_out): Sequential(\n",
       "                (0): Linear(in_features=64, out_features=32, dtype=float32)\n",
       "                (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm(normalized_shape=[32], epsilon=1e-05)\n",
       "            (fn): FeedForward(\n",
       "              (0): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (1): GELU(approximate=False)\n",
       "              (2): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "              (3): Linear(in_features=64, out_features=32, dtype=float32)\n",
       "              (4): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): LayerList(\n",
       "        (0): Residual2(\n",
       "          (fn): PreNorm2(\n",
       "            (norm): LayerNorm(normalized_shape=[32], epsilon=1e-05)\n",
       "            (fn): CrossAttention(\n",
       "              (fc_q): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (fc_k): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (fc_v): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (fc_out): Sequential(\n",
       "                (0): Linear(in_features=64, out_features=32, dtype=float32)\n",
       "                (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm(normalized_shape=[32], epsilon=1e-05)\n",
       "            (fn): FeedForward(\n",
       "              (0): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (1): GELU(approximate=False)\n",
       "              (2): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "              (3): Linear(in_features=64, out_features=32, dtype=float32)\n",
       "              (4): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): LayerList(\n",
       "        (0): Residual2(\n",
       "          (fn): PreNorm2(\n",
       "            (norm): LayerNorm(normalized_shape=[32], epsilon=1e-05)\n",
       "            (fn): CrossAttention(\n",
       "              (fc_q): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (fc_k): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (fc_v): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (fc_out): Sequential(\n",
       "                (0): Linear(in_features=64, out_features=32, dtype=float32)\n",
       "                (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm(normalized_shape=[32], epsilon=1e-05)\n",
       "            (fn): FeedForward(\n",
       "              (0): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (1): GELU(approximate=False)\n",
       "              (2): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "              (3): Linear(in_features=64, out_features=32, dtype=float32)\n",
       "              (4): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): LayerList(\n",
       "        (0): Residual2(\n",
       "          (fn): PreNorm2(\n",
       "            (norm): LayerNorm(normalized_shape=[32], epsilon=1e-05)\n",
       "            (fn): CrossAttention(\n",
       "              (fc_q): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (fc_k): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (fc_v): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (fc_out): Sequential(\n",
       "                (0): Linear(in_features=64, out_features=32, dtype=float32)\n",
       "                (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm(normalized_shape=[32], epsilon=1e-05)\n",
       "            (fn): FeedForward(\n",
       "              (0): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (1): GELU(approximate=False)\n",
       "              (2): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "              (3): Linear(in_features=64, out_features=32, dtype=float32)\n",
       "              (4): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): LayerList(\n",
       "        (0): Residual2(\n",
       "          (fn): PreNorm2(\n",
       "            (norm): LayerNorm(normalized_shape=[32], epsilon=1e-05)\n",
       "            (fn): CrossAttention(\n",
       "              (fc_q): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (fc_k): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (fc_v): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (fc_out): Sequential(\n",
       "                (0): Linear(in_features=64, out_features=32, dtype=float32)\n",
       "                (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm(normalized_shape=[32], epsilon=1e-05)\n",
       "            (fn): FeedForward(\n",
       "              (0): Linear(in_features=32, out_features=64, dtype=float32)\n",
       "              (1): GELU(approximate=False)\n",
       "              (2): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "              (3): Linear(in_features=64, out_features=32, dtype=float32)\n",
       "              (4): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (upsample): Upsample(scale_factor=4, mode=bilinear, align_corners=False, align_mode=0, data_format=NCHW)\n",
       "  (conv_out): Sequential(\n",
       "    (0): Conv3x3(\n",
       "      (seq): Sequential(\n",
       "        (0): Pad2D(padding=[1, 1, 1, 1], mode=constant, value=0.0, data_format=NCHW)\n",
       "        (1): Conv2D(32, 32, kernel_size=[3, 3], data_format=NCHW)\n",
       "        (2): BatchNorm2D(num_features=32, momentum=0.9, epsilon=1e-05)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (1): Conv3x3(\n",
       "      (seq): Sequential(\n",
       "        (0): Pad2D(padding=[1, 1, 1, 1], mode=constant, value=0.0, data_format=NCHW)\n",
       "        (1): Conv2D(32, 2, kernel_size=[3, 3], data_format=NCHW)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看组网信息\n",
    "# 在PaddleRS中，可通过ChangeDetector对象的net属性获取paddle.nn.Layer类型组网\n",
    "model.net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T08:49:43.670473Z",
     "iopub.status.busy": "2022-07-06T08:49:43.670131Z",
     "iopub.status.idle": "2022-07-06T08:49:43.698576Z",
     "shell.execute_reply": "2022-07-06T08:49:43.697887Z",
     "shell.execute_reply.started": "2022-07-06T08:49:43.670450Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-06 16:49:43 [INFO]\t627 samples in file /home/aistudio/data/data134796/dataset/train.txt\n",
      "2022-07-06 16:49:43 [INFO]\t10 samples in file /home/aistudio/data/data134796/dataset/val.txt\n"
     ]
    }
   ],
   "source": [
    "# 构建需要使用的数据变换（数据增强、预处理）\n",
    "# 使用Compose组合多种变换方式。Compose中包含的变换将按顺序串行执行\n",
    "train_transforms = T.Compose([\n",
    "    # 随机裁剪\n",
    "    T.RandomCrop(\n",
    "        # 裁剪区域将被缩放到此大小\n",
    "        crop_size=CROP_SIZE,\n",
    "        # 将裁剪区域的横纵比固定为1\n",
    "        aspect_ratio=[1.0, 1.0],\n",
    "        # 裁剪区域相对原始影像长宽比例在一定范围内变动，最小不低于原始长宽的1/5\n",
    "        scaling=[0.2, 1.0]\n",
    "    ),\n",
    "    # 以50%的概率实施随机水平翻转\n",
    "    T.RandomHorizontalFlip(prob=0.5),\n",
    "    # 以50%的概率实施随机垂直翻转\n",
    "    T.RandomVerticalFlip(prob=0.5),\n",
    "    T.RandomBlur(),\n",
    "    # 数据归一化到[-1,1]\n",
    "    T.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    ),\n",
    "    T.RandomSwap()\n",
    "])\n",
    "eval_transforms = T.Compose([\n",
    "    # 在验证阶段，输入原始尺寸影像，对输入影像仅进行归一化处理\n",
    "    # 验证阶段与训练阶段的数据归一化方式必须相同\n",
    "    T.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "])\n",
    "\n",
    "# 实例化数据集\n",
    "train_dataset = pdrs.datasets.CDDataset(\n",
    "    data_dir=DATA_DIR,\n",
    "    file_list=osp.join(DATA_DIR, 'train.txt'),\n",
    "    label_list=None,\n",
    "    transforms=train_transforms,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=True,\n",
    "    binarize_labels=True\n",
    ")\n",
    "eval_dataset = pdrs.datasets.CDDataset(\n",
    "    data_dir=DATA_DIR,\n",
    "    file_list=osp.join(DATA_DIR, 'val.txt'),\n",
    "    label_list=None,\n",
    "    transforms=eval_transforms,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    "    binarize_labels=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练\n",
    "\n",
    "使用AI Studio高级版硬件配置（16G V100）和默认的超参数，训练总时长约为50分钟，训练结束时验证集上最高的mIoU指标约为0.89（参考值，实际值可能存在波动）。\n",
    "\n",
    "如果在训练中启用了VisualDL日志记录的功能（默认开启），则可以在“数据模型可视化”页签中查看可视化结果，请将logdir设置为`EXP_DIR`目录下的vdl_log子目录。在notebook中使用VisualDL的相关教程可参考[此处](https://ai.baidu.com/ai-doc/AISTUDIO/Dk3e2vxg9#visualdl%E5%B7%A5%E5%85%B7)。\n",
    "\n",
    "需要注意的是，PaddleRS默认以mIoU评价验证集上的最优模型，而赛事官方则选用F1分数作为评价指标。\n",
    "\n",
    "**变化检测任务的mIoU与F1分数指标定义：**\n",
    "\n",
    "$$mIoU=\\frac{1}{2}\\left(\\frac{TP}{FN+FP+TP}+\\frac{TN}{FP+FN+TN}\\right)$$\n",
    "$$F1=\\frac{2 \\cdot TP}{2 \\cdot TP + FN + FP}$$\n",
    "\n",
    "式中，$TP$表示预测为变化且实际为变化的样本数，$TN$表示预测为不变且实际为不变的样本数，$FP$表示预测为变化但实际为不变的样本数，$FN$表示预测为不变但实际为变化的样本数。\n",
    "\n",
    "此外，PaddleRS在验证集上汇报针对每一类的指标，因此对于二类变化检测来说，category_acc、category_F1-score等指标均存在两个数据项，以列表形式体现。由于变化检测任务主要关注变化类，因此观察和比较每种指标的第二个数据项（即列表的第二个元素）是更有意义的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T08:49:43.702360Z",
     "iopub.status.busy": "2022-07-06T08:49:43.701664Z",
     "iopub.status.idle": "2022-07-06T08:49:43.705330Z",
     "shell.execute_reply": "2022-07-06T08:49:43.704671Z",
     "shell.execute_reply.started": "2022-07-06T08:49:43.702330Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 若实验目录不存在，则新建之（递归创建目录）\n",
    "if not osp.exists(EXP_DIR):\n",
    "    os.makedirs(EXP_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T08:49:43.706519Z",
     "iopub.status.busy": "2022-07-06T08:49:43.706196Z",
     "iopub.status.idle": "2022-07-06T08:49:43.711591Z",
     "shell.execute_reply": "2022-07-06T08:49:43.710946Z",
     "shell.execute_reply.started": "2022-07-06T08:49:43.706496Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr_scheduler = paddle.optimizer.lr.MultiStepDecay(\n",
    "    LR,\n",
    "    milestones=[7020,12870,16770,19500],\n",
    "    gamma=0.5\n",
    ")\n",
    "\n",
    "optimizer = paddle.optimizer.Momentum(\n",
    "    weight_decay=0.0005,\n",
    "    learning_rate=lr_scheduler,\n",
    "    momentum=0.99,\n",
    "    parameters=model.net.parameters()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T08:49:43.712760Z",
     "iopub.status.busy": "2022-07-06T08:49:43.712453Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-06 16:49:55 [INFO]\t[TRAIN] Epoch=1/500, Step=10/39, loss=0.297204, lr=0.001000, time_each_step=1.15s, eta=6:14:24\n",
      "2022-07-06 16:50:03 [INFO]\t[TRAIN] Epoch=1/500, Step=20/39, loss=0.210677, lr=0.001000, time_each_step=0.83s, eta=4:30:47\n",
      "2022-07-06 16:50:12 [INFO]\t[TRAIN] Epoch=1/500, Step=30/39, loss=0.230060, lr=0.001000, time_each_step=0.83s, eta=4:30:20\n",
      "2022-07-06 16:50:19 [INFO]\t[TRAIN] Epoch 1 finished, loss=0.27306288 .\n",
      "2022-07-06 16:50:22 [INFO]\t[TRAIN] Epoch=2/500, Step=1/39, loss=0.416035, lr=0.001000, time_each_step=1.07s, eta=5:46:38\n",
      "2022-07-06 16:50:31 [INFO]\t[TRAIN] Epoch=2/500, Step=11/39, loss=0.239012, lr=0.001000, time_each_step=0.85s, eta=4:34:14\n",
      "2022-07-06 16:50:39 [INFO]\t[TRAIN] Epoch=2/500, Step=21/39, loss=0.191302, lr=0.001000, time_each_step=0.86s, eta=4:39:37\n",
      "2022-07-06 16:50:48 [INFO]\t[TRAIN] Epoch=2/500, Step=31/39, loss=0.257939, lr=0.001000, time_each_step=0.84s, eta=4:32:23\n",
      "2022-07-06 16:50:55 [INFO]\t[TRAIN] Epoch 2 finished, loss=0.26549828 .\n",
      "2022-07-06 16:50:59 [INFO]\t[TRAIN] Epoch=3/500, Step=2/39, loss=0.273609, lr=0.001000, time_each_step=1.08s, eta=5:50:32\n",
      "2022-07-06 16:51:07 [INFO]\t[TRAIN] Epoch=3/500, Step=12/39, loss=0.170225, lr=0.001000, time_each_step=0.85s, eta=4:36:18\n",
      "2022-07-06 16:51:16 [INFO]\t[TRAIN] Epoch=3/500, Step=22/39, loss=0.130086, lr=0.001000, time_each_step=0.84s, eta=4:31:37\n",
      "2022-07-06 16:51:24 [INFO]\t[TRAIN] Epoch=3/500, Step=32/39, loss=0.166097, lr=0.001000, time_each_step=0.84s, eta=4:30:30\n",
      "2022-07-06 16:51:30 [INFO]\t[TRAIN] Epoch 3 finished, loss=0.16575588 .\n",
      "2022-07-06 16:51:35 [INFO]\t[TRAIN] Epoch=4/500, Step=3/39, loss=0.109032, lr=0.001000, time_each_step=1.08s, eta=5:49:36\n",
      "2022-07-06 16:51:44 [INFO]\t[TRAIN] Epoch=4/500, Step=13/39, loss=0.070934, lr=0.001000, time_each_step=0.89s, eta=4:45:47\n",
      "2022-07-06 16:51:52 [INFO]\t[TRAIN] Epoch=4/500, Step=23/39, loss=0.150199, lr=0.001000, time_each_step=0.85s, eta=4:34:40\n",
      "2022-07-06 16:52:01 [INFO]\t[TRAIN] Epoch=4/500, Step=33/39, loss=0.107177, lr=0.001000, time_each_step=0.83s, eta=4:28:29\n",
      "2022-07-06 16:52:06 [INFO]\t[TRAIN] Epoch 4 finished, loss=0.11773464 .\n",
      "2022-07-06 16:52:12 [INFO]\t[TRAIN] Epoch=5/500, Step=4/39, loss=0.094096, lr=0.001000, time_each_step=1.08s, eta=5:47:9\n",
      "2022-07-06 16:52:20 [INFO]\t[TRAIN] Epoch=5/500, Step=14/39, loss=0.098411, lr=0.001000, time_each_step=0.86s, eta=4:35:48\n",
      "2022-07-06 16:52:29 [INFO]\t[TRAIN] Epoch=5/500, Step=24/39, loss=0.123571, lr=0.001000, time_each_step=0.83s, eta=4:28:32\n",
      "2022-07-06 16:52:37 [INFO]\t[TRAIN] Epoch=5/500, Step=34/39, loss=0.082996, lr=0.001000, time_each_step=0.83s, eta=4:27:54\n",
      "2022-07-06 16:52:41 [INFO]\t[TRAIN] Epoch 5 finished, loss=0.10347803 .\n",
      "2022-07-06 16:52:48 [INFO]\t[TRAIN] Epoch=6/500, Step=5/39, loss=0.084373, lr=0.001000, time_each_step=1.1s, eta=5:53:7\n",
      "2022-07-06 16:52:57 [INFO]\t[TRAIN] Epoch=6/500, Step=15/39, loss=0.103648, lr=0.001000, time_each_step=0.88s, eta=4:41:37\n",
      "2022-07-06 16:53:05 [INFO]\t[TRAIN] Epoch=6/500, Step=25/39, loss=0.090792, lr=0.001000, time_each_step=0.84s, eta=4:30:2\n",
      "2022-07-06 16:53:13 [INFO]\t[TRAIN] Epoch=6/500, Step=35/39, loss=0.111808, lr=0.001000, time_each_step=0.83s, eta=4:27:21\n",
      "2022-07-06 16:53:17 [INFO]\t[TRAIN] Epoch 6 finished, loss=0.090599045 .\n",
      "2022-07-06 16:53:26 [INFO]\t[TRAIN] Epoch=7/500, Step=6/39, loss=0.086907, lr=0.001000, time_each_step=1.21s, eta=6:28:25\n",
      "2022-07-06 16:53:36 [INFO]\t[TRAIN] Epoch=7/500, Step=16/39, loss=0.118140, lr=0.001000, time_each_step=1.05s, eta=5:37:12\n",
      "2022-07-06 16:53:45 [INFO]\t[TRAIN] Epoch=7/500, Step=26/39, loss=0.058316, lr=0.001000, time_each_step=0.84s, eta=4:27:59\n",
      "2022-07-06 16:53:53 [INFO]\t[TRAIN] Epoch=7/500, Step=36/39, loss=0.160641, lr=0.001000, time_each_step=0.84s, eta=4:28:32\n",
      "2022-07-06 16:53:56 [INFO]\t[TRAIN] Epoch 7 finished, loss=0.08528902 .\n",
      "2022-07-06 16:54:04 [INFO]\t[TRAIN] Epoch=8/500, Step=7/39, loss=0.051160, lr=0.001000, time_each_step=1.09s, eta=5:48:1\n",
      "2022-07-06 16:54:12 [INFO]\t[TRAIN] Epoch=8/500, Step=17/39, loss=0.101804, lr=0.001000, time_each_step=0.84s, eta=4:29:56\n",
      "2022-07-06 16:54:21 [INFO]\t[TRAIN] Epoch=8/500, Step=27/39, loss=0.126350, lr=0.001000, time_each_step=0.84s, eta=4:27:48\n",
      "2022-07-06 16:54:29 [INFO]\t[TRAIN] Epoch=8/500, Step=37/39, loss=0.063716, lr=0.001000, time_each_step=0.83s, eta=4:25:56\n",
      "2022-07-06 16:54:31 [INFO]\t[TRAIN] Epoch 8 finished, loss=0.08165992 .\n",
      "2022-07-06 16:54:40 [INFO]\t[TRAIN] Epoch=9/500, Step=8/39, loss=0.069824, lr=0.001000, time_each_step=1.08s, eta=5:45:45\n",
      "2022-07-06 16:54:48 [INFO]\t[TRAIN] Epoch=9/500, Step=18/39, loss=0.081230, lr=0.001000, time_each_step=0.83s, eta=4:26:40\n",
      "2022-07-06 16:54:57 [INFO]\t[TRAIN] Epoch=9/500, Step=28/39, loss=0.088057, lr=0.001000, time_each_step=0.84s, eta=4:28:9\n",
      "2022-07-06 16:55:05 [INFO]\t[TRAIN] Epoch=9/500, Step=38/39, loss=0.096734, lr=0.001000, time_each_step=0.86s, eta=4:33:4\n",
      "2022-07-06 16:55:06 [INFO]\t[TRAIN] Epoch 9 finished, loss=0.07519216 .\n",
      "2022-07-06 16:55:17 [INFO]\t[TRAIN] Epoch=10/500, Step=9/39, loss=0.077738, lr=0.001000, time_each_step=1.11s, eta=5:54:53\n",
      "2022-07-06 16:55:25 [INFO]\t[TRAIN] Epoch=10/500, Step=19/39, loss=0.086184, lr=0.001000, time_each_step=0.84s, eta=4:28:19\n",
      "2022-07-06 16:55:33 [INFO]\t[TRAIN] Epoch=10/500, Step=29/39, loss=0.075270, lr=0.001000, time_each_step=0.83s, eta=4:25:23\n",
      "2022-07-06 16:55:42 [INFO]\t[TRAIN] Epoch=10/500, Step=39/39, loss=0.039483, lr=0.001000, time_each_step=0.83s, eta=4:25:39\n",
      "2022-07-06 16:55:42 [INFO]\t[TRAIN] Epoch 10 finished, loss=0.07331171 .\n",
      "2022-07-06 16:55:42 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 16:55:42 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 16:55:44 [INFO]\t[EVAL] Finished, Epoch=10, miou=0.790137, category_iou=[0.9771468  0.60312782], oacc=0.977914, category_acc=[0.98557276 0.80246246], kappa=0.740927, category_F1-score=[0.98844133 0.75243884] .\n",
      "2022-07-06 16:55:44 [INFO]\tModel saved in /home/aistudio/exp/best_model.\n",
      "2022-07-06 16:55:44 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_10, miou=0.7901373100329419\n",
      "2022-07-06 16:55:45 [INFO]\tModel saved in /home/aistudio/exp/epoch_10.\n",
      "2022-07-06 16:55:56 [INFO]\t[TRAIN] Epoch=11/500, Step=10/39, loss=0.054576, lr=0.001000, time_each_step=1.09s, eta=5:47:39\n",
      "2022-07-06 16:56:04 [INFO]\t[TRAIN] Epoch=11/500, Step=20/39, loss=0.081008, lr=0.001000, time_each_step=0.85s, eta=4:31:38\n",
      "2022-07-06 16:56:12 [INFO]\t[TRAIN] Epoch=11/500, Step=30/39, loss=0.053298, lr=0.001000, time_each_step=0.84s, eta=4:29:11\n",
      "2022-07-06 16:56:20 [INFO]\t[TRAIN] Epoch 11 finished, loss=0.07219459 .\n",
      "2022-07-06 16:56:24 [INFO]\t[TRAIN] Epoch=12/500, Step=1/39, loss=0.100445, lr=0.001000, time_each_step=1.12s, eta=5:57:26\n",
      "2022-07-06 16:56:32 [INFO]\t[TRAIN] Epoch=12/500, Step=11/39, loss=0.051917, lr=0.001000, time_each_step=0.85s, eta=4:31:17\n",
      "2022-07-06 16:56:41 [INFO]\t[TRAIN] Epoch=12/500, Step=21/39, loss=0.073039, lr=0.001000, time_each_step=0.83s, eta=4:26:32\n",
      "2022-07-06 16:56:49 [INFO]\t[TRAIN] Epoch=12/500, Step=31/39, loss=0.068655, lr=0.001000, time_each_step=0.83s, eta=4:26:25\n",
      "2022-07-06 16:56:56 [INFO]\t[TRAIN] Epoch 12 finished, loss=0.068113364 .\n",
      "2022-07-06 16:57:00 [INFO]\t[TRAIN] Epoch=13/500, Step=2/39, loss=0.044497, lr=0.001000, time_each_step=1.09s, eta=5:47:1\n",
      "2022-07-06 16:57:09 [INFO]\t[TRAIN] Epoch=13/500, Step=12/39, loss=0.067947, lr=0.001000, time_each_step=0.86s, eta=4:34:9\n",
      "2022-07-06 16:57:17 [INFO]\t[TRAIN] Epoch=13/500, Step=22/39, loss=0.078469, lr=0.001000, time_each_step=0.84s, eta=4:29:6\n",
      "2022-07-06 16:57:25 [INFO]\t[TRAIN] Epoch=13/500, Step=32/39, loss=0.081728, lr=0.001000, time_each_step=0.83s, eta=4:26:2\n",
      "2022-07-06 16:57:31 [INFO]\t[TRAIN] Epoch 13 finished, loss=0.063553065 .\n",
      "2022-07-06 16:57:36 [INFO]\t[TRAIN] Epoch=14/500, Step=3/39, loss=0.056664, lr=0.001000, time_each_step=1.08s, eta=5:43:35\n",
      "2022-07-06 16:57:45 [INFO]\t[TRAIN] Epoch=14/500, Step=13/39, loss=0.052319, lr=0.001000, time_each_step=0.85s, eta=4:30:11\n",
      "2022-07-06 16:57:53 [INFO]\t[TRAIN] Epoch=14/500, Step=23/39, loss=0.082538, lr=0.001000, time_each_step=0.83s, eta=4:25:34\n",
      "2022-07-06 16:58:01 [INFO]\t[TRAIN] Epoch=14/500, Step=33/39, loss=0.031185, lr=0.001000, time_each_step=0.84s, eta=4:26:13\n",
      "2022-07-06 16:58:06 [INFO]\t[TRAIN] Epoch 14 finished, loss=0.063563034 .\n",
      "2022-07-06 16:58:13 [INFO]\t[TRAIN] Epoch=15/500, Step=4/39, loss=0.044160, lr=0.001000, time_each_step=1.13s, eta=6:0:30\n",
      "2022-07-06 16:58:21 [INFO]\t[TRAIN] Epoch=15/500, Step=14/39, loss=0.031977, lr=0.001000, time_each_step=0.85s, eta=4:31:5\n",
      "2022-07-06 16:58:30 [INFO]\t[TRAIN] Epoch=15/500, Step=24/39, loss=0.067550, lr=0.001000, time_each_step=0.84s, eta=4:27:6\n",
      "2022-07-06 16:58:38 [INFO]\t[TRAIN] Epoch=15/500, Step=34/39, loss=0.048070, lr=0.001000, time_each_step=0.83s, eta=4:25:20\n",
      "2022-07-06 16:58:42 [INFO]\t[TRAIN] Epoch 15 finished, loss=0.0608828 .\n",
      "2022-07-06 16:58:49 [INFO]\t[TRAIN] Epoch=16/500, Step=5/39, loss=0.044954, lr=0.001000, time_each_step=1.08s, eta=5:43:45\n",
      "2022-07-06 16:58:57 [INFO]\t[TRAIN] Epoch=16/500, Step=15/39, loss=0.066671, lr=0.001000, time_each_step=0.84s, eta=4:26:26\n",
      "2022-07-06 16:59:06 [INFO]\t[TRAIN] Epoch=16/500, Step=25/39, loss=0.037973, lr=0.001000, time_each_step=0.84s, eta=4:25:38\n",
      "2022-07-06 16:59:14 [INFO]\t[TRAIN] Epoch=16/500, Step=35/39, loss=0.068329, lr=0.001000, time_each_step=0.83s, eta=4:23:48\n",
      "2022-07-06 16:59:18 [INFO]\t[TRAIN] Epoch 16 finished, loss=0.05851043 .\n",
      "2022-07-06 16:59:25 [INFO]\t[TRAIN] Epoch=17/500, Step=6/39, loss=0.065643, lr=0.001000, time_each_step=1.07s, eta=5:38:50\n",
      "2022-07-06 16:59:33 [INFO]\t[TRAIN] Epoch=17/500, Step=16/39, loss=0.049410, lr=0.001000, time_each_step=0.84s, eta=4:27:11\n",
      "2022-07-06 16:59:42 [INFO]\t[TRAIN] Epoch=17/500, Step=26/39, loss=0.055159, lr=0.001000, time_each_step=0.83s, eta=4:23:45\n",
      "2022-07-06 16:59:50 [INFO]\t[TRAIN] Epoch=17/500, Step=36/39, loss=0.054069, lr=0.001000, time_each_step=0.83s, eta=4:23:31\n",
      "2022-07-06 16:59:53 [INFO]\t[TRAIN] Epoch 17 finished, loss=0.06004985 .\n",
      "2022-07-06 17:00:01 [INFO]\t[TRAIN] Epoch=18/500, Step=7/39, loss=0.087628, lr=0.001000, time_each_step=1.08s, eta=5:41:25\n",
      "2022-07-06 17:00:09 [INFO]\t[TRAIN] Epoch=18/500, Step=17/39, loss=0.066501, lr=0.001000, time_each_step=0.85s, eta=4:27:17\n",
      "2022-07-06 17:00:18 [INFO]\t[TRAIN] Epoch=18/500, Step=27/39, loss=0.079514, lr=0.001000, time_each_step=0.84s, eta=4:25:2\n",
      "2022-07-06 17:00:26 [INFO]\t[TRAIN] Epoch=18/500, Step=37/39, loss=0.066602, lr=0.001000, time_each_step=0.84s, eta=4:26:16\n",
      "2022-07-06 17:00:28 [INFO]\t[TRAIN] Epoch 18 finished, loss=0.056737117 .\n",
      "2022-07-06 17:00:37 [INFO]\t[TRAIN] Epoch=19/500, Step=8/39, loss=0.068696, lr=0.001000, time_each_step=1.07s, eta=5:38:27\n",
      "2022-07-06 17:00:45 [INFO]\t[TRAIN] Epoch=19/500, Step=18/39, loss=0.108858, lr=0.001000, time_each_step=0.83s, eta=4:23:8\n",
      "2022-07-06 17:00:54 [INFO]\t[TRAIN] Epoch=19/500, Step=28/39, loss=0.045093, lr=0.001000, time_each_step=0.83s, eta=4:22:29\n",
      "2022-07-06 17:01:02 [INFO]\t[TRAIN] Epoch=19/500, Step=38/39, loss=0.066628, lr=0.001000, time_each_step=0.83s, eta=4:22:12\n",
      "2022-07-06 17:01:03 [INFO]\t[TRAIN] Epoch 19 finished, loss=0.055620473 .\n",
      "2022-07-06 17:01:13 [INFO]\t[TRAIN] Epoch=20/500, Step=9/39, loss=0.046969, lr=0.001000, time_each_step=1.1s, eta=5:44:52\n",
      "2022-07-06 17:01:21 [INFO]\t[TRAIN] Epoch=20/500, Step=19/39, loss=0.028210, lr=0.001000, time_each_step=0.84s, eta=4:24:26\n",
      "2022-07-06 17:01:30 [INFO]\t[TRAIN] Epoch=20/500, Step=29/39, loss=0.035335, lr=0.001000, time_each_step=0.85s, eta=4:27:15\n",
      "2022-07-06 17:01:38 [INFO]\t[TRAIN] Epoch=20/500, Step=39/39, loss=0.066976, lr=0.001000, time_each_step=0.83s, eta=4:21:33\n",
      "2022-07-06 17:01:38 [INFO]\t[TRAIN] Epoch 20 finished, loss=0.055250246 .\n",
      "2022-07-06 17:01:38 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 17:01:38 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 17:01:40 [INFO]\t[EVAL] Finished, Epoch=20, miou=0.829922, category_iou=[0.98070304 0.67914049], oacc=0.981460, category_acc=[0.99142806 0.79060639], kappa=0.799177, category_F1-score=[0.99025752 0.80891444] .\n",
      "2022-07-06 17:01:41 [INFO]\tModel saved in /home/aistudio/exp/best_model.\n",
      "2022-07-06 17:01:41 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_20, miou=0.8299217662268148\n",
      "2022-07-06 17:01:41 [INFO]\tModel saved in /home/aistudio/exp/epoch_20.\n",
      "2022-07-06 17:01:52 [INFO]\t[TRAIN] Epoch=21/500, Step=10/39, loss=0.042745, lr=0.001000, time_each_step=1.09s, eta=5:41:46\n",
      "2022-07-06 17:02:01 [INFO]\t[TRAIN] Epoch=21/500, Step=20/39, loss=0.045629, lr=0.001000, time_each_step=0.83s, eta=4:21:35\n",
      "2022-07-06 17:02:09 [INFO]\t[TRAIN] Epoch=21/500, Step=30/39, loss=0.075526, lr=0.001000, time_each_step=0.84s, eta=4:22:12\n",
      "2022-07-06 17:02:17 [INFO]\t[TRAIN] Epoch 21 finished, loss=0.056252137 .\n",
      "2022-07-06 17:02:20 [INFO]\t[TRAIN] Epoch=22/500, Step=1/39, loss=0.045100, lr=0.001000, time_each_step=1.07s, eta=5:34:21\n",
      "2022-07-06 17:02:28 [INFO]\t[TRAIN] Epoch=22/500, Step=11/39, loss=0.067119, lr=0.001000, time_each_step=0.86s, eta=4:29:28\n",
      "2022-07-06 17:02:37 [INFO]\t[TRAIN] Epoch=22/500, Step=21/39, loss=0.055176, lr=0.001000, time_each_step=0.86s, eta=4:28:3\n",
      "2022-07-06 17:02:45 [INFO]\t[TRAIN] Epoch=22/500, Step=31/39, loss=0.051554, lr=0.001000, time_each_step=0.84s, eta=4:22:18\n",
      "2022-07-06 17:02:52 [INFO]\t[TRAIN] Epoch 22 finished, loss=0.05241268 .\n",
      "2022-07-06 17:02:57 [INFO]\t[TRAIN] Epoch=23/500, Step=2/39, loss=0.035315, lr=0.001000, time_each_step=1.12s, eta=5:51:16\n",
      "2022-07-06 17:03:05 [INFO]\t[TRAIN] Epoch=23/500, Step=12/39, loss=0.074586, lr=0.001000, time_each_step=0.84s, eta=4:23:54\n",
      "2022-07-06 17:03:13 [INFO]\t[TRAIN] Epoch=23/500, Step=22/39, loss=0.063966, lr=0.001000, time_each_step=0.84s, eta=4:22:24\n",
      "2022-07-06 17:03:22 [INFO]\t[TRAIN] Epoch=23/500, Step=32/39, loss=0.070908, lr=0.001000, time_each_step=0.83s, eta=4:20:23\n",
      "2022-07-06 17:03:28 [INFO]\t[TRAIN] Epoch 23 finished, loss=0.051993873 .\n",
      "2022-07-06 17:03:33 [INFO]\t[TRAIN] Epoch=24/500, Step=3/39, loss=0.040112, lr=0.001000, time_each_step=1.13s, eta=5:52:13\n",
      "2022-07-06 17:03:42 [INFO]\t[TRAIN] Epoch=24/500, Step=13/39, loss=0.049423, lr=0.001000, time_each_step=0.86s, eta=4:28:59\n",
      "2022-07-06 17:03:50 [INFO]\t[TRAIN] Epoch=24/500, Step=23/39, loss=0.047888, lr=0.001000, time_each_step=0.84s, eta=4:21:22\n",
      "2022-07-06 17:03:59 [INFO]\t[TRAIN] Epoch=24/500, Step=33/39, loss=0.035432, lr=0.001000, time_each_step=0.83s, eta=4:19:58\n",
      "2022-07-06 17:04:04 [INFO]\t[TRAIN] Epoch 24 finished, loss=0.05099396 .\n",
      "2022-07-06 17:04:10 [INFO]\t[TRAIN] Epoch=25/500, Step=4/39, loss=0.054919, lr=0.001000, time_each_step=1.08s, eta=5:36:56\n",
      "2022-07-06 17:04:18 [INFO]\t[TRAIN] Epoch=25/500, Step=14/39, loss=0.059805, lr=0.001000, time_each_step=0.85s, eta=4:25:4\n",
      "2022-07-06 17:04:26 [INFO]\t[TRAIN] Epoch=25/500, Step=24/39, loss=0.034338, lr=0.001000, time_each_step=0.84s, eta=4:20:14\n",
      "2022-07-06 17:04:35 [INFO]\t[TRAIN] Epoch=25/500, Step=34/39, loss=0.062040, lr=0.001000, time_each_step=0.84s, eta=4:20:6\n",
      "2022-07-06 17:04:39 [INFO]\t[TRAIN] Epoch 25 finished, loss=0.054167483 .\n",
      "2022-07-06 17:04:46 [INFO]\t[TRAIN] Epoch=26/500, Step=5/39, loss=0.051373, lr=0.001000, time_each_step=1.08s, eta=5:35:22\n",
      "2022-07-06 17:04:54 [INFO]\t[TRAIN] Epoch=26/500, Step=15/39, loss=0.070784, lr=0.001000, time_each_step=0.85s, eta=4:23:17\n",
      "2022-07-06 17:05:03 [INFO]\t[TRAIN] Epoch=26/500, Step=25/39, loss=0.068308, lr=0.001000, time_each_step=0.83s, eta=4:18:51\n",
      "2022-07-06 17:05:11 [INFO]\t[TRAIN] Epoch=26/500, Step=35/39, loss=0.040706, lr=0.001000, time_each_step=0.83s, eta=4:18:32\n",
      "2022-07-06 17:05:14 [INFO]\t[TRAIN] Epoch 26 finished, loss=0.052201424 .\n",
      "2022-07-06 17:05:22 [INFO]\t[TRAIN] Epoch=27/500, Step=6/39, loss=0.034307, lr=0.001000, time_each_step=1.09s, eta=5:38:17\n",
      "2022-07-06 17:05:30 [INFO]\t[TRAIN] Epoch=27/500, Step=16/39, loss=0.055523, lr=0.001000, time_each_step=0.84s, eta=4:19:47\n",
      "2022-07-06 17:05:39 [INFO]\t[TRAIN] Epoch=27/500, Step=26/39, loss=0.054989, lr=0.001000, time_each_step=0.84s, eta=4:19:19\n",
      "2022-07-06 17:05:47 [INFO]\t[TRAIN] Epoch=27/500, Step=36/39, loss=0.027514, lr=0.001000, time_each_step=0.84s, eta=4:20:33\n",
      "2022-07-06 17:05:50 [INFO]\t[TRAIN] Epoch 27 finished, loss=0.05311185 .\n",
      "2022-07-06 17:05:58 [INFO]\t[TRAIN] Epoch=28/500, Step=7/39, loss=0.054051, lr=0.001000, time_each_step=1.08s, eta=5:33:10\n",
      "2022-07-06 17:06:06 [INFO]\t[TRAIN] Epoch=28/500, Step=17/39, loss=0.057943, lr=0.001000, time_each_step=0.84s, eta=4:19:41\n",
      "2022-07-06 17:06:15 [INFO]\t[TRAIN] Epoch=28/500, Step=27/39, loss=0.052012, lr=0.001000, time_each_step=0.83s, eta=4:17:42\n",
      "2022-07-06 17:06:23 [INFO]\t[TRAIN] Epoch=28/500, Step=37/39, loss=0.055645, lr=0.001000, time_each_step=0.84s, eta=4:18:33\n",
      "2022-07-06 17:06:25 [INFO]\t[TRAIN] Epoch 28 finished, loss=0.050335914 .\n",
      "2022-07-06 17:06:34 [INFO]\t[TRAIN] Epoch=29/500, Step=8/39, loss=0.067176, lr=0.001000, time_each_step=1.08s, eta=5:31:51\n",
      "2022-07-06 17:06:42 [INFO]\t[TRAIN] Epoch=29/500, Step=18/39, loss=0.072357, lr=0.001000, time_each_step=0.84s, eta=4:20:21\n",
      "2022-07-06 17:06:51 [INFO]\t[TRAIN] Epoch=29/500, Step=28/39, loss=0.045233, lr=0.001000, time_each_step=0.85s, eta=4:22:30\n",
      "2022-07-06 17:06:59 [INFO]\t[TRAIN] Epoch=29/500, Step=38/39, loss=0.067039, lr=0.001000, time_each_step=0.83s, eta=4:16:54\n",
      "2022-07-06 17:07:00 [INFO]\t[TRAIN] Epoch 29 finished, loss=0.053927757 .\n",
      "2022-07-06 17:07:10 [INFO]\t[TRAIN] Epoch=30/500, Step=9/39, loss=0.036942, lr=0.001000, time_each_step=1.09s, eta=5:34:59\n",
      "2022-07-06 17:07:19 [INFO]\t[TRAIN] Epoch=30/500, Step=19/39, loss=0.046767, lr=0.001000, time_each_step=0.84s, eta=4:18:58\n",
      "2022-07-06 17:07:27 [INFO]\t[TRAIN] Epoch=30/500, Step=29/39, loss=0.040863, lr=0.001000, time_each_step=0.84s, eta=4:17:20\n",
      "2022-07-06 17:07:35 [INFO]\t[TRAIN] Epoch=30/500, Step=39/39, loss=0.050299, lr=0.001000, time_each_step=0.83s, eta=4:16:18\n",
      "2022-07-06 17:07:35 [INFO]\t[TRAIN] Epoch 30 finished, loss=0.051348448 .\n",
      "2022-07-06 17:07:35 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 17:07:35 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 17:07:37 [INFO]\t[EVAL] Finished, Epoch=30, miou=0.842461, category_iou=[0.98280166 0.70212093], oacc=0.983472, category_acc=[0.99115392 0.82789957], kappa=0.816322, category_F1-score=[0.99132624 0.82499536] .\n",
      "2022-07-06 17:07:38 [INFO]\tModel saved in /home/aistudio/exp/best_model.\n",
      "2022-07-06 17:07:38 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_30, miou=0.8424612957417678\n",
      "2022-07-06 17:07:38 [INFO]\tModel saved in /home/aistudio/exp/epoch_30.\n",
      "2022-07-06 17:07:49 [INFO]\t[TRAIN] Epoch=31/500, Step=10/39, loss=0.050784, lr=0.001000, time_each_step=1.1s, eta=5:37:37\n",
      "2022-07-06 17:07:58 [INFO]\t[TRAIN] Epoch=31/500, Step=20/39, loss=0.058386, lr=0.001000, time_each_step=0.87s, eta=4:26:56\n",
      "2022-07-06 17:08:06 [INFO]\t[TRAIN] Epoch=31/500, Step=30/39, loss=0.041187, lr=0.001000, time_each_step=0.83s, eta=4:15:55\n",
      "2022-07-06 17:08:14 [INFO]\t[TRAIN] Epoch 31 finished, loss=0.04864041 .\n",
      "2022-07-06 17:08:17 [INFO]\t[TRAIN] Epoch=32/500, Step=1/39, loss=0.073784, lr=0.001000, time_each_step=1.07s, eta=5:27:47\n",
      "2022-07-06 17:08:26 [INFO]\t[TRAIN] Epoch=32/500, Step=11/39, loss=0.034190, lr=0.001000, time_each_step=0.86s, eta=4:22:29\n",
      "2022-07-06 17:08:34 [INFO]\t[TRAIN] Epoch=32/500, Step=21/39, loss=0.047974, lr=0.001000, time_each_step=0.83s, eta=4:15:49\n",
      "2022-07-06 17:08:42 [INFO]\t[TRAIN] Epoch=32/500, Step=31/39, loss=0.045354, lr=0.001000, time_each_step=0.83s, eta=4:15:26\n",
      "2022-07-06 17:08:49 [INFO]\t[TRAIN] Epoch 32 finished, loss=0.054464776 .\n",
      "2022-07-06 17:08:54 [INFO]\t[TRAIN] Epoch=33/500, Step=2/39, loss=0.036338, lr=0.001000, time_each_step=1.11s, eta=5:40:14\n",
      "2022-07-06 17:09:02 [INFO]\t[TRAIN] Epoch=33/500, Step=12/39, loss=0.031052, lr=0.001000, time_each_step=0.86s, eta=4:24:12\n",
      "2022-07-06 17:09:11 [INFO]\t[TRAIN] Epoch=33/500, Step=22/39, loss=0.070983, lr=0.001000, time_each_step=0.85s, eta=4:18:43\n",
      "2022-07-06 17:09:19 [INFO]\t[TRAIN] Epoch=33/500, Step=32/39, loss=0.047250, lr=0.001000, time_each_step=0.84s, eta=4:17:14\n",
      "2022-07-06 17:09:25 [INFO]\t[TRAIN] Epoch 33 finished, loss=0.049744613 .\n",
      "2022-07-06 17:09:30 [INFO]\t[TRAIN] Epoch=34/500, Step=3/39, loss=0.038545, lr=0.001000, time_each_step=1.1s, eta=5:35:38\n",
      "2022-07-06 17:09:39 [INFO]\t[TRAIN] Epoch=34/500, Step=13/39, loss=0.048073, lr=0.001000, time_each_step=0.84s, eta=4:18:0\n",
      "2022-07-06 17:09:47 [INFO]\t[TRAIN] Epoch=34/500, Step=23/39, loss=0.108864, lr=0.001000, time_each_step=0.84s, eta=4:16:23\n",
      "2022-07-06 17:09:56 [INFO]\t[TRAIN] Epoch=34/500, Step=33/39, loss=0.063261, lr=0.001000, time_each_step=0.84s, eta=4:16:14\n",
      "2022-07-06 17:10:01 [INFO]\t[TRAIN] Epoch 34 finished, loss=0.05121448 .\n",
      "2022-07-06 17:10:06 [INFO]\t[TRAIN] Epoch=35/500, Step=4/39, loss=0.043986, lr=0.001000, time_each_step=1.07s, eta=5:26:57\n",
      "2022-07-06 17:10:15 [INFO]\t[TRAIN] Epoch=35/500, Step=14/39, loss=0.053465, lr=0.001000, time_each_step=0.84s, eta=4:17:6\n",
      "2022-07-06 17:10:23 [INFO]\t[TRAIN] Epoch=35/500, Step=24/39, loss=0.020614, lr=0.001000, time_each_step=0.84s, eta=4:14:57\n",
      "2022-07-06 17:10:32 [INFO]\t[TRAIN] Epoch=35/500, Step=34/39, loss=0.020731, lr=0.001000, time_each_step=0.84s, eta=4:15:20\n",
      "2022-07-06 17:10:36 [INFO]\t[TRAIN] Epoch 35 finished, loss=0.047708157 .\n",
      "2022-07-06 17:10:42 [INFO]\t[TRAIN] Epoch=36/500, Step=5/39, loss=0.039915, lr=0.001000, time_each_step=1.07s, eta=5:25:52\n",
      "2022-07-06 17:10:51 [INFO]\t[TRAIN] Epoch=36/500, Step=15/39, loss=0.033245, lr=0.001000, time_each_step=0.84s, eta=4:15:37\n",
      "2022-07-06 17:10:59 [INFO]\t[TRAIN] Epoch=36/500, Step=25/39, loss=0.032502, lr=0.001000, time_each_step=0.84s, eta=4:15:36\n",
      "2022-07-06 17:11:08 [INFO]\t[TRAIN] Epoch=36/500, Step=35/39, loss=0.036450, lr=0.001000, time_each_step=0.84s, eta=4:15:34\n",
      "2022-07-06 17:11:11 [INFO]\t[TRAIN] Epoch 36 finished, loss=0.047348212 .\n",
      "2022-07-06 17:11:19 [INFO]\t[TRAIN] Epoch=37/500, Step=6/39, loss=0.042376, lr=0.001000, time_each_step=1.07s, eta=5:25:52\n",
      "2022-07-06 17:11:27 [INFO]\t[TRAIN] Epoch=37/500, Step=16/39, loss=0.051963, lr=0.001000, time_each_step=0.84s, eta=4:14:11\n",
      "2022-07-06 17:11:35 [INFO]\t[TRAIN] Epoch=37/500, Step=26/39, loss=0.039743, lr=0.001000, time_each_step=0.83s, eta=4:12:53\n",
      "2022-07-06 17:11:44 [INFO]\t[TRAIN] Epoch=37/500, Step=36/39, loss=0.071943, lr=0.001000, time_each_step=0.83s, eta=4:12:21\n",
      "2022-07-06 17:11:46 [INFO]\t[TRAIN] Epoch 37 finished, loss=0.048587363 .\n",
      "2022-07-06 17:11:55 [INFO]\t[TRAIN] Epoch=38/500, Step=7/39, loss=0.048278, lr=0.001000, time_each_step=1.08s, eta=5:26:45\n",
      "2022-07-06 17:12:03 [INFO]\t[TRAIN] Epoch=38/500, Step=17/39, loss=0.039633, lr=0.001000, time_each_step=0.85s, eta=4:16:13\n",
      "2022-07-06 17:12:11 [INFO]\t[TRAIN] Epoch=38/500, Step=27/39, loss=0.034496, lr=0.001000, time_each_step=0.84s, eta=4:15:29\n",
      "2022-07-06 17:12:20 [INFO]\t[TRAIN] Epoch=38/500, Step=37/39, loss=0.046435, lr=0.001000, time_each_step=0.83s, eta=4:11:55\n",
      "2022-07-06 17:12:22 [INFO]\t[TRAIN] Epoch 38 finished, loss=0.046372406 .\n",
      "2022-07-06 17:12:31 [INFO]\t[TRAIN] Epoch=39/500, Step=8/39, loss=0.060766, lr=0.001000, time_each_step=1.08s, eta=5:25:25\n",
      "2022-07-06 17:12:39 [INFO]\t[TRAIN] Epoch=39/500, Step=18/39, loss=0.060489, lr=0.001000, time_each_step=0.84s, eta=4:13:54\n",
      "2022-07-06 17:12:47 [INFO]\t[TRAIN] Epoch=39/500, Step=28/39, loss=0.050384, lr=0.001000, time_each_step=0.83s, eta=4:12:0\n",
      "2022-07-06 17:12:56 [INFO]\t[TRAIN] Epoch=39/500, Step=38/39, loss=0.048345, lr=0.001000, time_each_step=0.83s, eta=4:11:39\n",
      "2022-07-06 17:12:57 [INFO]\t[TRAIN] Epoch 39 finished, loss=0.047447484 .\n",
      "2022-07-06 17:13:07 [INFO]\t[TRAIN] Epoch=40/500, Step=9/39, loss=0.036629, lr=0.001000, time_each_step=1.09s, eta=5:29:24\n",
      "2022-07-06 17:13:15 [INFO]\t[TRAIN] Epoch=40/500, Step=19/39, loss=0.054075, lr=0.001000, time_each_step=0.86s, eta=4:18:10\n",
      "2022-07-06 17:13:24 [INFO]\t[TRAIN] Epoch=40/500, Step=29/39, loss=0.040482, lr=0.001000, time_each_step=0.84s, eta=4:12:13\n",
      "2022-07-06 17:13:32 [INFO]\t[TRAIN] Epoch=40/500, Step=39/39, loss=0.037254, lr=0.001000, time_each_step=0.84s, eta=4:12:11\n",
      "2022-07-06 17:13:32 [INFO]\t[TRAIN] Epoch 40 finished, loss=0.049072955 .\n",
      "2022-07-06 17:13:32 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 17:13:32 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 17:13:34 [INFO]\t[EVAL] Finished, Epoch=40, miou=0.839192, category_iou=[0.98353151 0.69485196], oacc=0.984127, category_acc=[0.98827882 0.88644996], kappa=0.811702, category_F1-score=[0.99169739 0.81995593] .\n",
      "2022-07-06 17:13:34 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_30, miou=0.8424612957417678\n",
      "2022-07-06 17:13:35 [INFO]\tModel saved in /home/aistudio/exp/epoch_40.\n",
      "2022-07-06 17:13:46 [INFO]\t[TRAIN] Epoch=41/500, Step=10/39, loss=0.039478, lr=0.001000, time_each_step=1.11s, eta=5:33:5\n",
      "2022-07-06 17:13:54 [INFO]\t[TRAIN] Epoch=41/500, Step=20/39, loss=0.044904, lr=0.001000, time_each_step=0.84s, eta=4:11:31\n",
      "2022-07-06 17:14:03 [INFO]\t[TRAIN] Epoch=41/500, Step=30/39, loss=0.041259, lr=0.001000, time_each_step=0.84s, eta=4:13:12\n",
      "2022-07-06 17:14:10 [INFO]\t[TRAIN] Epoch 41 finished, loss=0.045060914 .\n",
      "2022-07-06 17:14:14 [INFO]\t[TRAIN] Epoch=42/500, Step=1/39, loss=0.030071, lr=0.001000, time_each_step=1.09s, eta=5:27:20\n",
      "2022-07-06 17:14:22 [INFO]\t[TRAIN] Epoch=42/500, Step=11/39, loss=0.061150, lr=0.001000, time_each_step=0.86s, eta=4:17:3\n",
      "2022-07-06 17:14:30 [INFO]\t[TRAIN] Epoch=42/500, Step=21/39, loss=0.044347, lr=0.001000, time_each_step=0.84s, eta=4:10:43\n",
      "2022-07-06 17:14:39 [INFO]\t[TRAIN] Epoch=42/500, Step=31/39, loss=0.032030, lr=0.001000, time_each_step=0.84s, eta=4:10:29\n",
      "2022-07-06 17:14:46 [INFO]\t[TRAIN] Epoch 42 finished, loss=0.043402974 .\n",
      "2022-07-06 17:14:50 [INFO]\t[TRAIN] Epoch=43/500, Step=2/39, loss=0.050221, lr=0.001000, time_each_step=1.08s, eta=5:22:36\n",
      "2022-07-06 17:14:58 [INFO]\t[TRAIN] Epoch=43/500, Step=12/39, loss=0.029483, lr=0.001000, time_each_step=0.84s, eta=4:12:34\n",
      "2022-07-06 17:15:07 [INFO]\t[TRAIN] Epoch=43/500, Step=22/39, loss=0.044697, lr=0.001000, time_each_step=0.84s, eta=4:9:52\n",
      "2022-07-06 17:15:15 [INFO]\t[TRAIN] Epoch=43/500, Step=32/39, loss=0.060439, lr=0.001000, time_each_step=0.84s, eta=4:10:27\n",
      "2022-07-06 17:15:21 [INFO]\t[TRAIN] Epoch 43 finished, loss=0.044726893 .\n",
      "2022-07-06 17:15:27 [INFO]\t[TRAIN] Epoch=44/500, Step=3/39, loss=0.046093, lr=0.001000, time_each_step=1.17s, eta=5:49:55\n",
      "2022-07-06 17:15:35 [INFO]\t[TRAIN] Epoch=44/500, Step=13/39, loss=0.039480, lr=0.001000, time_each_step=0.84s, eta=4:10:43\n",
      "2022-07-06 17:15:44 [INFO]\t[TRAIN] Epoch=44/500, Step=23/39, loss=0.063639, lr=0.001000, time_each_step=0.84s, eta=4:9:16\n",
      "2022-07-06 17:15:52 [INFO]\t[TRAIN] Epoch=44/500, Step=33/39, loss=0.049584, lr=0.001000, time_each_step=0.83s, eta=4:8:44\n",
      "2022-07-06 17:15:57 [INFO]\t[TRAIN] Epoch 44 finished, loss=0.043339532 .\n",
      "2022-07-06 17:16:03 [INFO]\t[TRAIN] Epoch=45/500, Step=4/39, loss=0.061202, lr=0.001000, time_each_step=1.07s, eta=5:18:3\n",
      "2022-07-06 17:16:11 [INFO]\t[TRAIN] Epoch=45/500, Step=14/39, loss=0.049099, lr=0.001000, time_each_step=0.85s, eta=4:12:1\n",
      "2022-07-06 17:16:20 [INFO]\t[TRAIN] Epoch=45/500, Step=24/39, loss=0.088531, lr=0.001000, time_each_step=0.84s, eta=4:10:59\n",
      "2022-07-06 17:16:28 [INFO]\t[TRAIN] Epoch=45/500, Step=34/39, loss=0.022494, lr=0.001000, time_each_step=0.84s, eta=4:10:5\n",
      "2022-07-06 17:16:32 [INFO]\t[TRAIN] Epoch 45 finished, loss=0.04440686 .\n",
      "2022-07-06 17:16:39 [INFO]\t[TRAIN] Epoch=46/500, Step=5/39, loss=0.036481, lr=0.001000, time_each_step=1.1s, eta=5:27:54\n",
      "2022-07-06 17:16:48 [INFO]\t[TRAIN] Epoch=46/500, Step=15/39, loss=0.040699, lr=0.001000, time_each_step=0.84s, eta=4:10:53\n",
      "2022-07-06 17:16:56 [INFO]\t[TRAIN] Epoch=46/500, Step=25/39, loss=0.081680, lr=0.001000, time_each_step=0.83s, eta=4:7:41\n",
      "2022-07-06 17:17:04 [INFO]\t[TRAIN] Epoch=46/500, Step=35/39, loss=0.067211, lr=0.001000, time_each_step=0.83s, eta=4:7:46\n",
      "2022-07-06 17:17:08 [INFO]\t[TRAIN] Epoch 46 finished, loss=0.04514348 .\n",
      "2022-07-06 17:17:15 [INFO]\t[TRAIN] Epoch=47/500, Step=6/39, loss=0.051988, lr=0.001000, time_each_step=1.08s, eta=5:19:38\n",
      "2022-07-06 17:17:24 [INFO]\t[TRAIN] Epoch=47/500, Step=16/39, loss=0.050626, lr=0.001000, time_each_step=0.85s, eta=4:12:5\n",
      "2022-07-06 17:17:32 [INFO]\t[TRAIN] Epoch=47/500, Step=26/39, loss=0.079250, lr=0.001000, time_each_step=0.84s, eta=4:8:51\n",
      "2022-07-06 17:17:40 [INFO]\t[TRAIN] Epoch=47/500, Step=36/39, loss=0.047791, lr=0.001000, time_each_step=0.83s, eta=4:6:44\n",
      "2022-07-06 17:17:43 [INFO]\t[TRAIN] Epoch 47 finished, loss=0.04306017 .\n",
      "2022-07-06 17:17:52 [INFO]\t[TRAIN] Epoch=48/500, Step=7/39, loss=0.042660, lr=0.001000, time_each_step=1.11s, eta=5:28:18\n",
      "2022-07-06 17:18:00 [INFO]\t[TRAIN] Epoch=48/500, Step=17/39, loss=0.043865, lr=0.001000, time_each_step=0.84s, eta=4:8:25\n",
      "2022-07-06 17:18:08 [INFO]\t[TRAIN] Epoch=48/500, Step=27/39, loss=0.046358, lr=0.001000, time_each_step=0.83s, eta=4:6:18\n",
      "2022-07-06 17:18:17 [INFO]\t[TRAIN] Epoch=48/500, Step=37/39, loss=0.059430, lr=0.001000, time_each_step=0.83s, eta=4:5:56\n",
      "2022-07-06 17:18:18 [INFO]\t[TRAIN] Epoch 48 finished, loss=0.045009214 .\n",
      "2022-07-06 17:18:28 [INFO]\t[TRAIN] Epoch=49/500, Step=8/39, loss=0.044130, lr=0.001000, time_each_step=1.09s, eta=5:21:47\n",
      "2022-07-06 17:18:36 [INFO]\t[TRAIN] Epoch=49/500, Step=18/39, loss=0.037557, lr=0.001000, time_each_step=0.85s, eta=4:10:56\n",
      "2022-07-06 17:18:45 [INFO]\t[TRAIN] Epoch=49/500, Step=28/39, loss=0.040802, lr=0.001000, time_each_step=0.83s, eta=4:5:53\n",
      "2022-07-06 17:18:53 [INFO]\t[TRAIN] Epoch=49/500, Step=38/39, loss=0.038760, lr=0.001000, time_each_step=0.83s, eta=4:5:10\n",
      "2022-07-06 17:18:54 [INFO]\t[TRAIN] Epoch 49 finished, loss=0.04496239 .\n",
      "2022-07-06 17:19:04 [INFO]\t[TRAIN] Epoch=50/500, Step=9/39, loss=0.032918, lr=0.001000, time_each_step=1.09s, eta=5:19:31\n",
      "2022-07-06 17:19:12 [INFO]\t[TRAIN] Epoch=50/500, Step=19/39, loss=0.027672, lr=0.001000, time_each_step=0.84s, eta=4:6:47\n",
      "2022-07-06 17:19:21 [INFO]\t[TRAIN] Epoch=50/500, Step=29/39, loss=0.053049, lr=0.001000, time_each_step=0.84s, eta=4:5:54\n",
      "2022-07-06 17:19:29 [INFO]\t[TRAIN] Epoch=50/500, Step=39/39, loss=0.036144, lr=0.001000, time_each_step=0.83s, eta=4:4:42\n",
      "2022-07-06 17:19:29 [INFO]\t[TRAIN] Epoch 50 finished, loss=0.04022598 .\n",
      "2022-07-06 17:19:29 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 17:19:29 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 17:19:31 [INFO]\t[EVAL] Finished, Epoch=50, miou=0.857535, category_iou=[0.98478141 0.73028949], oacc=0.985384, category_acc=[0.99180813 0.85329279], kappa=0.836457, category_F1-score=[0.99233236 0.84412405] .\n",
      "2022-07-06 17:19:32 [INFO]\tModel saved in /home/aistudio/exp/best_model.\n",
      "2022-07-06 17:19:32 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_50, miou=0.8575354459065911\n",
      "2022-07-06 17:19:32 [INFO]\tModel saved in /home/aistudio/exp/epoch_50.\n",
      "2022-07-06 17:19:43 [INFO]\t[TRAIN] Epoch=51/500, Step=10/39, loss=0.048843, lr=0.001000, time_each_step=1.12s, eta=5:28:57\n",
      "2022-07-06 17:19:52 [INFO]\t[TRAIN] Epoch=51/500, Step=20/39, loss=0.039632, lr=0.001000, time_each_step=0.84s, eta=4:6:5\n",
      "2022-07-06 17:20:00 [INFO]\t[TRAIN] Epoch=51/500, Step=30/39, loss=0.037101, lr=0.001000, time_each_step=0.83s, eta=4:5:21\n",
      "2022-07-06 17:20:07 [INFO]\t[TRAIN] Epoch 51 finished, loss=0.042346496 .\n",
      "2022-07-06 17:20:11 [INFO]\t[TRAIN] Epoch=52/500, Step=1/39, loss=0.042950, lr=0.001000, time_each_step=1.08s, eta=5:16:53\n",
      "2022-07-06 17:20:19 [INFO]\t[TRAIN] Epoch=52/500, Step=11/39, loss=0.054783, lr=0.001000, time_each_step=0.85s, eta=4:9:39\n",
      "2022-07-06 17:20:28 [INFO]\t[TRAIN] Epoch=52/500, Step=21/39, loss=0.031363, lr=0.001000, time_each_step=0.85s, eta=4:8:25\n",
      "2022-07-06 17:20:36 [INFO]\t[TRAIN] Epoch=52/500, Step=31/39, loss=0.072385, lr=0.001000, time_each_step=0.84s, eta=4:5:50\n",
      "2022-07-06 17:20:43 [INFO]\t[TRAIN] Epoch 52 finished, loss=0.04354379 .\n",
      "2022-07-06 17:20:47 [INFO]\t[TRAIN] Epoch=53/500, Step=2/39, loss=0.048791, lr=0.001000, time_each_step=1.07s, eta=5:12:18\n",
      "2022-07-06 17:20:55 [INFO]\t[TRAIN] Epoch=53/500, Step=12/39, loss=0.037430, lr=0.001000, time_each_step=0.86s, eta=4:10:45\n",
      "2022-07-06 17:21:04 [INFO]\t[TRAIN] Epoch=53/500, Step=22/39, loss=0.055226, lr=0.001000, time_each_step=0.83s, eta=4:4:16\n",
      "2022-07-06 17:21:12 [INFO]\t[TRAIN] Epoch=53/500, Step=32/39, loss=0.037708, lr=0.001000, time_each_step=0.84s, eta=4:4:42\n",
      "2022-07-06 17:21:18 [INFO]\t[TRAIN] Epoch 53 finished, loss=0.043980855 .\n",
      "2022-07-06 17:21:23 [INFO]\t[TRAIN] Epoch=54/500, Step=3/39, loss=0.034541, lr=0.001000, time_each_step=1.08s, eta=5:16:23\n",
      "2022-07-06 17:21:32 [INFO]\t[TRAIN] Epoch=54/500, Step=13/39, loss=0.056722, lr=0.001000, time_each_step=0.85s, eta=4:7:34\n",
      "2022-07-06 17:21:40 [INFO]\t[TRAIN] Epoch=54/500, Step=23/39, loss=0.055357, lr=0.001000, time_each_step=0.84s, eta=4:4:38\n",
      "2022-07-06 17:21:48 [INFO]\t[TRAIN] Epoch=54/500, Step=33/39, loss=0.050596, lr=0.001000, time_each_step=0.84s, eta=4:5:22\n",
      "2022-07-06 17:21:53 [INFO]\t[TRAIN] Epoch 54 finished, loss=0.043053165 .\n",
      "2022-07-06 17:21:59 [INFO]\t[TRAIN] Epoch=55/500, Step=4/39, loss=0.038448, lr=0.001000, time_each_step=1.08s, eta=5:15:32\n",
      "2022-07-06 17:22:08 [INFO]\t[TRAIN] Epoch=55/500, Step=14/39, loss=0.024085, lr=0.001000, time_each_step=0.84s, eta=4:4:57\n",
      "2022-07-06 17:22:16 [INFO]\t[TRAIN] Epoch=55/500, Step=24/39, loss=0.040789, lr=0.001000, time_each_step=0.83s, eta=4:3:15\n",
      "2022-07-06 17:22:24 [INFO]\t[TRAIN] Epoch=55/500, Step=34/39, loss=0.037095, lr=0.001000, time_each_step=0.85s, eta=4:6:26\n",
      "2022-07-06 17:22:29 [INFO]\t[TRAIN] Epoch 55 finished, loss=0.041254323 .\n",
      "2022-07-06 17:22:35 [INFO]\t[TRAIN] Epoch=56/500, Step=5/39, loss=0.053184, lr=0.001000, time_each_step=1.08s, eta=5:14:0\n",
      "2022-07-06 17:22:44 [INFO]\t[TRAIN] Epoch=56/500, Step=15/39, loss=0.037868, lr=0.001000, time_each_step=0.85s, eta=4:6:42\n",
      "2022-07-06 17:22:52 [INFO]\t[TRAIN] Epoch=56/500, Step=25/39, loss=0.037823, lr=0.001000, time_each_step=0.84s, eta=4:5:27\n",
      "2022-07-06 17:23:01 [INFO]\t[TRAIN] Epoch=56/500, Step=35/39, loss=0.034060, lr=0.001000, time_each_step=0.83s, eta=4:2:17\n",
      "2022-07-06 17:23:04 [INFO]\t[TRAIN] Epoch 56 finished, loss=0.042521447 .\n",
      "2022-07-06 17:23:12 [INFO]\t[TRAIN] Epoch=57/500, Step=6/39, loss=0.030497, lr=0.001000, time_each_step=1.09s, eta=5:15:43\n",
      "2022-07-06 17:23:20 [INFO]\t[TRAIN] Epoch=57/500, Step=16/39, loss=0.045493, lr=0.001000, time_each_step=0.84s, eta=4:4:50\n",
      "2022-07-06 17:23:28 [INFO]\t[TRAIN] Epoch=57/500, Step=26/39, loss=0.026786, lr=0.001000, time_each_step=0.83s, eta=4:2:6\n",
      "2022-07-06 17:23:37 [INFO]\t[TRAIN] Epoch=57/500, Step=36/39, loss=0.050219, lr=0.001000, time_each_step=0.83s, eta=4:1:36\n",
      "2022-07-06 17:23:39 [INFO]\t[TRAIN] Epoch 57 finished, loss=0.042185057 .\n",
      "2022-07-06 17:23:48 [INFO]\t[TRAIN] Epoch=58/500, Step=7/39, loss=0.051598, lr=0.001000, time_each_step=1.1s, eta=5:18:23\n",
      "2022-07-06 17:23:56 [INFO]\t[TRAIN] Epoch=58/500, Step=17/39, loss=0.039719, lr=0.001000, time_each_step=0.86s, eta=4:9:12\n",
      "2022-07-06 17:24:05 [INFO]\t[TRAIN] Epoch=58/500, Step=27/39, loss=0.051430, lr=0.001000, time_each_step=0.84s, eta=4:2:46\n",
      "2022-07-06 17:24:13 [INFO]\t[TRAIN] Epoch=58/500, Step=37/39, loss=0.041150, lr=0.001000, time_each_step=0.84s, eta=4:2:30\n",
      "2022-07-06 17:24:15 [INFO]\t[TRAIN] Epoch 58 finished, loss=0.04026067 .\n",
      "2022-07-06 17:24:24 [INFO]\t[TRAIN] Epoch=59/500, Step=8/39, loss=0.065195, lr=0.001000, time_each_step=1.11s, eta=5:21:23\n",
      "2022-07-06 17:24:33 [INFO]\t[TRAIN] Epoch=59/500, Step=18/39, loss=0.053199, lr=0.001000, time_each_step=0.84s, eta=4:2:4\n",
      "2022-07-06 17:24:41 [INFO]\t[TRAIN] Epoch=59/500, Step=28/39, loss=0.055193, lr=0.001000, time_each_step=0.83s, eta=4:1:8\n",
      "2022-07-06 17:24:50 [INFO]\t[TRAIN] Epoch=59/500, Step=38/39, loss=0.025941, lr=0.001000, time_each_step=0.83s, eta=4:0:18\n",
      "2022-07-06 17:24:50 [INFO]\t[TRAIN] Epoch 59 finished, loss=0.04028232 .\n",
      "2022-07-06 17:25:01 [INFO]\t[TRAIN] Epoch=60/500, Step=9/39, loss=0.051714, lr=0.001000, time_each_step=1.13s, eta=5:25:55\n",
      "2022-07-06 17:25:09 [INFO]\t[TRAIN] Epoch=60/500, Step=19/39, loss=0.056344, lr=0.001000, time_each_step=0.84s, eta=4:3:29\n",
      "2022-07-06 17:25:18 [INFO]\t[TRAIN] Epoch=60/500, Step=29/39, loss=0.033936, lr=0.001000, time_each_step=0.83s, eta=4:0:14\n",
      "2022-07-06 17:25:26 [INFO]\t[TRAIN] Epoch=60/500, Step=39/39, loss=0.023027, lr=0.001000, time_each_step=0.83s, eta=3:59:49\n",
      "2022-07-06 17:25:26 [INFO]\t[TRAIN] Epoch 60 finished, loss=0.04155352 .\n",
      "2022-07-06 17:25:26 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 17:25:26 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 17:25:28 [INFO]\t[EVAL] Finished, Epoch=60, miou=0.861657, category_iou=[0.98554556 0.7377687 ], oacc=0.986110, category_acc=[0.99130073 0.87507208], kappa=0.841826, category_F1-score=[0.99272017 0.84909885] .\n",
      "2022-07-06 17:25:29 [INFO]\tModel saved in /home/aistudio/exp/best_model.\n",
      "2022-07-06 17:25:29 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_60, miou=0.8616571313749604\n",
      "2022-07-06 17:25:29 [INFO]\tModel saved in /home/aistudio/exp/epoch_60.\n",
      "2022-07-06 17:25:40 [INFO]\t[TRAIN] Epoch=61/500, Step=10/39, loss=0.043235, lr=0.001000, time_each_step=1.09s, eta=5:12:10\n",
      "2022-07-06 17:25:48 [INFO]\t[TRAIN] Epoch=61/500, Step=20/39, loss=0.042521, lr=0.001000, time_each_step=0.84s, eta=4:0:39\n",
      "2022-07-06 17:25:57 [INFO]\t[TRAIN] Epoch=61/500, Step=30/39, loss=0.044636, lr=0.001000, time_each_step=0.84s, eta=4:2:2\n",
      "2022-07-06 17:26:04 [INFO]\t[TRAIN] Epoch 61 finished, loss=0.042515576 .\n",
      "2022-07-06 17:26:08 [INFO]\t[TRAIN] Epoch=62/500, Step=1/39, loss=0.049953, lr=0.001000, time_each_step=1.08s, eta=5:10:15\n",
      "2022-07-06 17:26:16 [INFO]\t[TRAIN] Epoch=62/500, Step=11/39, loss=0.041992, lr=0.001000, time_each_step=0.85s, eta=4:4:9\n",
      "2022-07-06 17:26:24 [INFO]\t[TRAIN] Epoch=62/500, Step=21/39, loss=0.024264, lr=0.001000, time_each_step=0.83s, eta=3:59:15\n",
      "2022-07-06 17:26:33 [INFO]\t[TRAIN] Epoch=62/500, Step=31/39, loss=0.041812, lr=0.001000, time_each_step=0.84s, eta=3:59:53\n",
      "2022-07-06 17:26:40 [INFO]\t[TRAIN] Epoch 62 finished, loss=0.03970806 .\n",
      "2022-07-06 17:26:44 [INFO]\t[TRAIN] Epoch=63/500, Step=2/39, loss=0.033225, lr=0.001000, time_each_step=1.07s, eta=5:5:6\n",
      "2022-07-06 17:26:52 [INFO]\t[TRAIN] Epoch=63/500, Step=12/39, loss=0.044676, lr=0.001000, time_each_step=0.84s, eta=4:1:54\n",
      "2022-07-06 17:27:00 [INFO]\t[TRAIN] Epoch=63/500, Step=22/39, loss=0.025168, lr=0.001000, time_each_step=0.84s, eta=3:59:27\n",
      "2022-07-06 17:27:09 [INFO]\t[TRAIN] Epoch=63/500, Step=32/39, loss=0.031447, lr=0.001000, time_each_step=0.84s, eta=4:0:20\n",
      "2022-07-06 17:27:15 [INFO]\t[TRAIN] Epoch 63 finished, loss=0.039749615 .\n",
      "2022-07-06 17:27:20 [INFO]\t[TRAIN] Epoch=64/500, Step=3/39, loss=0.036661, lr=0.001000, time_each_step=1.13s, eta=5:22:21\n",
      "2022-07-06 17:27:29 [INFO]\t[TRAIN] Epoch=64/500, Step=13/39, loss=0.024813, lr=0.001000, time_each_step=0.84s, eta=4:0:9\n",
      "2022-07-06 17:27:37 [INFO]\t[TRAIN] Epoch=64/500, Step=23/39, loss=0.049252, lr=0.001000, time_each_step=0.83s, eta=3:57:57\n",
      "2022-07-06 17:27:45 [INFO]\t[TRAIN] Epoch=64/500, Step=33/39, loss=0.046984, lr=0.001000, time_each_step=0.84s, eta=3:59:10\n",
      "2022-07-06 17:27:50 [INFO]\t[TRAIN] Epoch 64 finished, loss=0.038695656 .\n",
      "2022-07-06 17:27:56 [INFO]\t[TRAIN] Epoch=65/500, Step=4/39, loss=0.045111, lr=0.001000, time_each_step=1.07s, eta=5:5:30\n",
      "2022-07-06 17:28:05 [INFO]\t[TRAIN] Epoch=65/500, Step=14/39, loss=0.033724, lr=0.001000, time_each_step=0.85s, eta=4:1:12\n",
      "2022-07-06 17:28:13 [INFO]\t[TRAIN] Epoch=65/500, Step=24/39, loss=0.030658, lr=0.001000, time_each_step=0.84s, eta=3:58:48\n",
      "2022-07-06 17:28:21 [INFO]\t[TRAIN] Epoch=65/500, Step=34/39, loss=0.028864, lr=0.001000, time_each_step=0.84s, eta=3:58:39\n",
      "2022-07-06 17:28:26 [INFO]\t[TRAIN] Epoch 65 finished, loss=0.04046511 .\n",
      "2022-07-06 17:28:32 [INFO]\t[TRAIN] Epoch=66/500, Step=5/39, loss=0.059862, lr=0.001000, time_each_step=1.09s, eta=5:10:12\n",
      "2022-07-06 17:28:41 [INFO]\t[TRAIN] Epoch=66/500, Step=15/39, loss=0.059121, lr=0.001000, time_each_step=0.85s, eta=4:0:48\n",
      "2022-07-06 17:28:49 [INFO]\t[TRAIN] Epoch=66/500, Step=25/39, loss=0.082495, lr=0.001000, time_each_step=0.85s, eta=4:1:8\n",
      "2022-07-06 17:28:58 [INFO]\t[TRAIN] Epoch=66/500, Step=35/39, loss=0.035224, lr=0.001000, time_each_step=0.83s, eta=3:57:19\n",
      "2022-07-06 17:29:01 [INFO]\t[TRAIN] Epoch 66 finished, loss=0.040275514 .\n",
      "2022-07-06 17:29:09 [INFO]\t[TRAIN] Epoch=67/500, Step=6/39, loss=0.032948, lr=0.001000, time_each_step=1.12s, eta=5:17:24\n",
      "2022-07-06 17:29:18 [INFO]\t[TRAIN] Epoch=67/500, Step=16/39, loss=0.041300, lr=0.001000, time_each_step=0.87s, eta=4:7:59\n",
      "2022-07-06 17:29:26 [INFO]\t[TRAIN] Epoch=67/500, Step=26/39, loss=0.029403, lr=0.001000, time_each_step=0.83s, eta=3:56:23\n",
      "2022-07-06 17:29:34 [INFO]\t[TRAIN] Epoch=67/500, Step=36/39, loss=0.062310, lr=0.001000, time_each_step=0.83s, eta=3:56:8\n",
      "2022-07-06 17:29:37 [INFO]\t[TRAIN] Epoch 67 finished, loss=0.037971046 .\n",
      "2022-07-06 17:29:45 [INFO]\t[TRAIN] Epoch=68/500, Step=7/39, loss=0.035672, lr=0.001000, time_each_step=1.08s, eta=5:6:13\n",
      "2022-07-06 17:29:54 [INFO]\t[TRAIN] Epoch=68/500, Step=17/39, loss=0.042362, lr=0.001000, time_each_step=0.84s, eta=3:58:7\n",
      "2022-07-06 17:30:02 [INFO]\t[TRAIN] Epoch=68/500, Step=27/39, loss=0.056668, lr=0.001000, time_each_step=0.83s, eta=3:55:59\n",
      "2022-07-06 17:30:11 [INFO]\t[TRAIN] Epoch=68/500, Step=37/39, loss=0.037500, lr=0.001000, time_each_step=0.83s, eta=3:55:41\n",
      "2022-07-06 17:30:12 [INFO]\t[TRAIN] Epoch 68 finished, loss=0.039091613 .\n",
      "2022-07-06 17:30:22 [INFO]\t[TRAIN] Epoch=69/500, Step=8/39, loss=0.054018, lr=0.001000, time_each_step=1.12s, eta=5:14:49\n",
      "2022-07-06 17:30:30 [INFO]\t[TRAIN] Epoch=69/500, Step=18/39, loss=0.047742, lr=0.001000, time_each_step=0.84s, eta=3:57:2\n",
      "2022-07-06 17:30:39 [INFO]\t[TRAIN] Epoch=69/500, Step=28/39, loss=0.041051, lr=0.001000, time_each_step=0.83s, eta=3:55:25\n",
      "2022-07-06 17:30:47 [INFO]\t[TRAIN] Epoch=69/500, Step=38/39, loss=0.044365, lr=0.001000, time_each_step=0.83s, eta=3:54:52\n",
      "2022-07-06 17:30:48 [INFO]\t[TRAIN] Epoch 69 finished, loss=0.039308995 .\n",
      "2022-07-06 17:30:58 [INFO]\t[TRAIN] Epoch=70/500, Step=9/39, loss=0.023113, lr=0.001000, time_each_step=1.1s, eta=5:8:45\n",
      "2022-07-06 17:31:06 [INFO]\t[TRAIN] Epoch=70/500, Step=19/39, loss=0.026672, lr=0.001000, time_each_step=0.85s, eta=3:58:38\n",
      "2022-07-06 17:31:15 [INFO]\t[TRAIN] Epoch=70/500, Step=29/39, loss=0.046219, lr=0.001000, time_each_step=0.83s, eta=3:55:2\n",
      "2022-07-06 17:31:23 [INFO]\t[TRAIN] Epoch=70/500, Step=39/39, loss=0.026620, lr=0.001000, time_each_step=0.83s, eta=3:54:58\n",
      "2022-07-06 17:31:23 [INFO]\t[TRAIN] Epoch 70 finished, loss=0.041535094 .\n",
      "2022-07-06 17:31:23 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 17:31:23 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 17:31:25 [INFO]\t[EVAL] Finished, Epoch=70, miou=0.864583, category_iou=[0.98587405 0.74329144], oacc=0.986429, category_acc=[0.99152652 0.87767118], kappa=0.845638, category_F1-score=[0.99288679 0.8527449 ] .\n",
      "2022-07-06 17:31:26 [INFO]\tModel saved in /home/aistudio/exp/best_model.\n",
      "2022-07-06 17:31:26 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_70, miou=0.8645827461339617\n",
      "2022-07-06 17:31:26 [INFO]\tModel saved in /home/aistudio/exp/epoch_70.\n",
      "2022-07-06 17:31:37 [INFO]\t[TRAIN] Epoch=71/500, Step=10/39, loss=0.035862, lr=0.001000, time_each_step=1.09s, eta=5:6:19\n",
      "2022-07-06 17:31:45 [INFO]\t[TRAIN] Epoch=71/500, Step=20/39, loss=0.045454, lr=0.001000, time_each_step=0.83s, eta=3:54:43\n",
      "2022-07-06 17:31:54 [INFO]\t[TRAIN] Epoch=71/500, Step=30/39, loss=0.046218, lr=0.001000, time_each_step=0.84s, eta=3:56:8\n",
      "2022-07-06 17:32:01 [INFO]\t[TRAIN] Epoch 71 finished, loss=0.040529273 .\n",
      "2022-07-06 17:32:05 [INFO]\t[TRAIN] Epoch=72/500, Step=1/39, loss=0.040345, lr=0.001000, time_each_step=1.08s, eta=5:2:1\n",
      "2022-07-06 17:32:13 [INFO]\t[TRAIN] Epoch=72/500, Step=11/39, loss=0.039689, lr=0.001000, time_each_step=0.86s, eta=4:1:21\n",
      "2022-07-06 17:32:22 [INFO]\t[TRAIN] Epoch=72/500, Step=21/39, loss=0.035863, lr=0.001000, time_each_step=0.84s, eta=3:55:54\n",
      "2022-07-06 17:32:30 [INFO]\t[TRAIN] Epoch=72/500, Step=31/39, loss=0.040086, lr=0.001000, time_each_step=0.85s, eta=3:57:16\n",
      "2022-07-06 17:32:37 [INFO]\t[TRAIN] Epoch 72 finished, loss=0.039559465 .\n",
      "2022-07-06 17:32:41 [INFO]\t[TRAIN] Epoch=73/500, Step=2/39, loss=0.048781, lr=0.001000, time_each_step=1.08s, eta=5:1:6\n",
      "2022-07-06 17:32:50 [INFO]\t[TRAIN] Epoch=73/500, Step=12/39, loss=0.044139, lr=0.001000, time_each_step=0.86s, eta=4:0:51\n",
      "2022-07-06 17:32:59 [INFO]\t[TRAIN] Epoch=73/500, Step=22/39, loss=0.042833, lr=0.001000, time_each_step=0.92s, eta=4:18:44\n",
      "2022-07-06 17:33:07 [INFO]\t[TRAIN] Epoch=73/500, Step=32/39, loss=0.048683, lr=0.001000, time_each_step=0.84s, eta=3:53:48\n",
      "2022-07-06 17:33:13 [INFO]\t[TRAIN] Epoch 73 finished, loss=0.039535154 .\n",
      "2022-07-06 17:33:18 [INFO]\t[TRAIN] Epoch=74/500, Step=3/39, loss=0.036916, lr=0.001000, time_each_step=1.08s, eta=5:1:6\n",
      "2022-07-06 17:33:27 [INFO]\t[TRAIN] Epoch=74/500, Step=13/39, loss=0.027611, lr=0.001000, time_each_step=0.88s, eta=4:4:53\n",
      "2022-07-06 17:33:35 [INFO]\t[TRAIN] Epoch=74/500, Step=23/39, loss=0.037958, lr=0.001000, time_each_step=0.84s, eta=3:54:36\n",
      "2022-07-06 17:33:44 [INFO]\t[TRAIN] Epoch=74/500, Step=33/39, loss=0.034264, lr=0.001000, time_each_step=0.83s, eta=3:52:42\n",
      "2022-07-06 17:33:49 [INFO]\t[TRAIN] Epoch 74 finished, loss=0.038408935 .\n",
      "2022-07-06 17:33:55 [INFO]\t[TRAIN] Epoch=75/500, Step=4/39, loss=0.044134, lr=0.001000, time_each_step=1.08s, eta=5:0:19\n",
      "2022-07-06 17:34:03 [INFO]\t[TRAIN] Epoch=75/500, Step=14/39, loss=0.032461, lr=0.001000, time_each_step=0.85s, eta=3:55:53\n",
      "2022-07-06 17:34:11 [INFO]\t[TRAIN] Epoch=75/500, Step=24/39, loss=0.019419, lr=0.001000, time_each_step=0.83s, eta=3:52:7\n",
      "2022-07-06 17:34:20 [INFO]\t[TRAIN] Epoch=75/500, Step=34/39, loss=0.038851, lr=0.001000, time_each_step=0.84s, eta=3:52:48\n",
      "2022-07-06 17:34:24 [INFO]\t[TRAIN] Epoch 75 finished, loss=0.03967576 .\n",
      "2022-07-06 17:34:31 [INFO]\t[TRAIN] Epoch=76/500, Step=5/39, loss=0.033778, lr=0.001000, time_each_step=1.09s, eta=5:1:35\n",
      "2022-07-06 17:34:39 [INFO]\t[TRAIN] Epoch=76/500, Step=15/39, loss=0.025936, lr=0.001000, time_each_step=0.87s, eta=4:2:51\n",
      "2022-07-06 17:34:48 [INFO]\t[TRAIN] Epoch=76/500, Step=25/39, loss=0.036879, lr=0.001000, time_each_step=0.84s, eta=3:52:25\n",
      "2022-07-06 17:34:56 [INFO]\t[TRAIN] Epoch=76/500, Step=35/39, loss=0.039202, lr=0.001000, time_each_step=0.83s, eta=3:51:23\n",
      "2022-07-06 17:35:00 [INFO]\t[TRAIN] Epoch 76 finished, loss=0.04045769 .\n",
      "2022-07-06 17:35:08 [INFO]\t[TRAIN] Epoch=77/500, Step=6/39, loss=0.047744, lr=0.001000, time_each_step=1.13s, eta=5:14:22\n",
      "2022-07-06 17:35:16 [INFO]\t[TRAIN] Epoch=77/500, Step=16/39, loss=0.026256, lr=0.001000, time_each_step=0.84s, eta=3:52:22\n",
      "2022-07-06 17:35:24 [INFO]\t[TRAIN] Epoch=77/500, Step=26/39, loss=0.040782, lr=0.001000, time_each_step=0.83s, eta=3:50:52\n",
      "2022-07-06 17:35:33 [INFO]\t[TRAIN] Epoch=77/500, Step=36/39, loss=0.022808, lr=0.001000, time_each_step=0.83s, eta=3:51:22\n",
      "2022-07-06 17:35:35 [INFO]\t[TRAIN] Epoch 77 finished, loss=0.039220165 .\n",
      "2022-07-06 17:35:44 [INFO]\t[TRAIN] Epoch=78/500, Step=7/39, loss=0.025926, lr=0.001000, time_each_step=1.1s, eta=5:5:0\n",
      "2022-07-06 17:35:52 [INFO]\t[TRAIN] Epoch=78/500, Step=17/39, loss=0.034511, lr=0.001000, time_each_step=0.84s, eta=3:52:56\n",
      "2022-07-06 17:36:01 [INFO]\t[TRAIN] Epoch=78/500, Step=27/39, loss=0.038154, lr=0.001000, time_each_step=0.83s, eta=3:50:39\n",
      "2022-07-06 17:36:09 [INFO]\t[TRAIN] Epoch=78/500, Step=37/39, loss=0.072128, lr=0.001000, time_each_step=0.84s, eta=3:50:59\n",
      "2022-07-06 17:36:11 [INFO]\t[TRAIN] Epoch 78 finished, loss=0.03700289 .\n",
      "2022-07-06 17:36:20 [INFO]\t[TRAIN] Epoch=79/500, Step=8/39, loss=0.034052, lr=0.001000, time_each_step=1.08s, eta=4:58:18\n",
      "2022-07-06 17:36:28 [INFO]\t[TRAIN] Epoch=79/500, Step=18/39, loss=0.032994, lr=0.001000, time_each_step=0.84s, eta=3:50:43\n",
      "2022-07-06 17:36:37 [INFO]\t[TRAIN] Epoch=79/500, Step=28/39, loss=0.057727, lr=0.001000, time_each_step=0.84s, eta=3:50:48\n",
      "2022-07-06 17:36:45 [INFO]\t[TRAIN] Epoch=79/500, Step=38/39, loss=0.046298, lr=0.001000, time_each_step=0.84s, eta=3:50:42\n",
      "2022-07-06 17:36:46 [INFO]\t[TRAIN] Epoch 79 finished, loss=0.037338555 .\n",
      "2022-07-06 17:36:56 [INFO]\t[TRAIN] Epoch=80/500, Step=9/39, loss=0.041779, lr=0.001000, time_each_step=1.09s, eta=4:59:2\n",
      "2022-07-06 17:37:04 [INFO]\t[TRAIN] Epoch=80/500, Step=19/39, loss=0.034262, lr=0.001000, time_each_step=0.84s, eta=3:50:54\n",
      "2022-07-06 17:37:13 [INFO]\t[TRAIN] Epoch=80/500, Step=29/39, loss=0.044081, lr=0.001000, time_each_step=0.84s, eta=3:50:18\n",
      "2022-07-06 17:37:21 [INFO]\t[TRAIN] Epoch=80/500, Step=39/39, loss=0.028409, lr=0.001000, time_each_step=0.83s, eta=3:49:14\n",
      "2022-07-06 17:37:21 [INFO]\t[TRAIN] Epoch 80 finished, loss=0.03986602 .\n",
      "2022-07-06 17:37:21 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 17:37:21 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 17:37:23 [INFO]\t[EVAL] Finished, Epoch=80, miou=0.858946, category_iou=[0.98564769 0.73224452], oacc=0.986190, category_acc=[0.9899581  0.90014411], kappa=0.838229, category_F1-score=[0.99277198 0.84542859] .\n",
      "2022-07-06 17:37:23 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_70, miou=0.8645827461339617\n",
      "2022-07-06 17:37:23 [INFO]\tModel saved in /home/aistudio/exp/epoch_80.\n",
      "2022-07-06 17:37:34 [INFO]\t[TRAIN] Epoch=81/500, Step=10/39, loss=0.024348, lr=0.001000, time_each_step=1.09s, eta=4:57:25\n",
      "2022-07-06 17:37:43 [INFO]\t[TRAIN] Epoch=81/500, Step=20/39, loss=0.040035, lr=0.001000, time_each_step=0.84s, eta=3:50:17\n",
      "2022-07-06 17:37:51 [INFO]\t[TRAIN] Epoch=81/500, Step=30/39, loss=0.048387, lr=0.001000, time_each_step=0.84s, eta=3:49:26\n",
      "2022-07-06 17:37:59 [INFO]\t[TRAIN] Epoch 81 finished, loss=0.038321957 .\n",
      "2022-07-06 17:38:02 [INFO]\t[TRAIN] Epoch=82/500, Step=1/39, loss=0.026229, lr=0.001000, time_each_step=1.07s, eta=4:51:45\n",
      "2022-07-06 17:38:10 [INFO]\t[TRAIN] Epoch=82/500, Step=11/39, loss=0.024744, lr=0.001000, time_each_step=0.86s, eta=3:54:20\n",
      "2022-07-06 17:38:19 [INFO]\t[TRAIN] Epoch=82/500, Step=21/39, loss=0.037123, lr=0.001000, time_each_step=0.83s, eta=3:48:15\n",
      "2022-07-06 17:38:27 [INFO]\t[TRAIN] Epoch=82/500, Step=31/39, loss=0.040254, lr=0.001000, time_each_step=0.84s, eta=3:49:10\n",
      "2022-07-06 17:38:34 [INFO]\t[TRAIN] Epoch 82 finished, loss=0.03994405 .\n",
      "2022-07-06 17:38:38 [INFO]\t[TRAIN] Epoch=83/500, Step=2/39, loss=0.030975, lr=0.001000, time_each_step=1.08s, eta=4:54:29\n",
      "2022-07-06 17:38:47 [INFO]\t[TRAIN] Epoch=83/500, Step=12/39, loss=0.040331, lr=0.001000, time_each_step=0.86s, eta=3:54:52\n",
      "2022-07-06 17:38:55 [INFO]\t[TRAIN] Epoch=83/500, Step=22/39, loss=0.040128, lr=0.001000, time_each_step=0.84s, eta=3:49:38\n",
      "2022-07-06 17:39:03 [INFO]\t[TRAIN] Epoch=83/500, Step=32/39, loss=0.048132, lr=0.001000, time_each_step=0.84s, eta=3:48:0\n",
      "2022-07-06 17:39:09 [INFO]\t[TRAIN] Epoch 83 finished, loss=0.03894512 .\n",
      "2022-07-06 17:39:14 [INFO]\t[TRAIN] Epoch=84/500, Step=3/39, loss=0.038496, lr=0.001000, time_each_step=1.08s, eta=4:52:50\n",
      "2022-07-06 17:39:23 [INFO]\t[TRAIN] Epoch=84/500, Step=13/39, loss=0.060258, lr=0.001000, time_each_step=0.84s, eta=3:49:54\n",
      "2022-07-06 17:39:31 [INFO]\t[TRAIN] Epoch=84/500, Step=23/39, loss=0.036199, lr=0.001000, time_each_step=0.83s, eta=3:47:14\n",
      "2022-07-06 17:39:39 [INFO]\t[TRAIN] Epoch=84/500, Step=33/39, loss=0.049605, lr=0.001000, time_each_step=0.84s, eta=3:47:13\n",
      "2022-07-06 17:39:45 [INFO]\t[TRAIN] Epoch 84 finished, loss=0.037834495 .\n",
      "2022-07-06 17:39:51 [INFO]\t[TRAIN] Epoch=85/500, Step=4/39, loss=0.024640, lr=0.001000, time_each_step=1.13s, eta=5:7:50\n",
      "2022-07-06 17:39:59 [INFO]\t[TRAIN] Epoch=85/500, Step=14/39, loss=0.049966, lr=0.001000, time_each_step=0.85s, eta=3:51:55\n",
      "2022-07-06 17:40:08 [INFO]\t[TRAIN] Epoch=85/500, Step=24/39, loss=0.022134, lr=0.001000, time_each_step=0.84s, eta=3:46:56\n",
      "2022-07-06 17:40:16 [INFO]\t[TRAIN] Epoch=85/500, Step=34/39, loss=0.035099, lr=0.001000, time_each_step=0.83s, eta=3:46:34\n",
      "2022-07-06 17:40:20 [INFO]\t[TRAIN] Epoch 85 finished, loss=0.038028304 .\n",
      "2022-07-06 17:40:27 [INFO]\t[TRAIN] Epoch=86/500, Step=5/39, loss=0.016347, lr=0.001000, time_each_step=1.07s, eta=4:49:49\n",
      "2022-07-06 17:40:35 [INFO]\t[TRAIN] Epoch=86/500, Step=15/39, loss=0.053697, lr=0.001000, time_each_step=0.84s, eta=3:47:33\n",
      "2022-07-06 17:40:44 [INFO]\t[TRAIN] Epoch=86/500, Step=25/39, loss=0.047597, lr=0.001000, time_each_step=0.83s, eta=3:46:9\n",
      "2022-07-06 17:40:52 [INFO]\t[TRAIN] Epoch=86/500, Step=35/39, loss=0.032732, lr=0.001000, time_each_step=0.83s, eta=3:45:39\n",
      "2022-07-06 17:40:56 [INFO]\t[TRAIN] Epoch 86 finished, loss=0.03629763 .\n",
      "2022-07-06 17:41:03 [INFO]\t[TRAIN] Epoch=87/500, Step=6/39, loss=0.030415, lr=0.001000, time_each_step=1.11s, eta=4:58:53\n",
      "2022-07-06 17:41:12 [INFO]\t[TRAIN] Epoch=87/500, Step=16/39, loss=0.069025, lr=0.001000, time_each_step=0.85s, eta=3:48:55\n",
      "2022-07-06 17:41:20 [INFO]\t[TRAIN] Epoch=87/500, Step=26/39, loss=0.037166, lr=0.001000, time_each_step=0.84s, eta=3:45:53\n",
      "2022-07-06 17:41:29 [INFO]\t[TRAIN] Epoch=87/500, Step=36/39, loss=0.033197, lr=0.001000, time_each_step=0.84s, eta=3:46:9\n",
      "2022-07-06 17:41:31 [INFO]\t[TRAIN] Epoch 87 finished, loss=0.038604885 .\n",
      "2022-07-06 17:41:40 [INFO]\t[TRAIN] Epoch=88/500, Step=7/39, loss=0.029780, lr=0.001000, time_each_step=1.08s, eta=4:51:38\n",
      "2022-07-06 17:41:48 [INFO]\t[TRAIN] Epoch=88/500, Step=17/39, loss=0.044952, lr=0.001000, time_each_step=0.85s, eta=3:49:28\n",
      "2022-07-06 17:41:56 [INFO]\t[TRAIN] Epoch=88/500, Step=27/39, loss=0.041934, lr=0.001000, time_each_step=0.84s, eta=3:45:25\n",
      "2022-07-06 17:42:05 [INFO]\t[TRAIN] Epoch=88/500, Step=37/39, loss=0.039850, lr=0.001000, time_each_step=0.84s, eta=3:45:21\n",
      "2022-07-06 17:42:07 [INFO]\t[TRAIN] Epoch 88 finished, loss=0.03773748 .\n",
      "2022-07-06 17:42:16 [INFO]\t[TRAIN] Epoch=89/500, Step=8/39, loss=0.045770, lr=0.001000, time_each_step=1.09s, eta=4:52:8\n",
      "2022-07-06 17:42:24 [INFO]\t[TRAIN] Epoch=89/500, Step=18/39, loss=0.032173, lr=0.001000, time_each_step=0.84s, eta=3:45:2\n",
      "2022-07-06 17:42:33 [INFO]\t[TRAIN] Epoch=89/500, Step=28/39, loss=0.025735, lr=0.001000, time_each_step=0.83s, eta=3:44:9\n",
      "2022-07-06 17:42:41 [INFO]\t[TRAIN] Epoch=89/500, Step=38/39, loss=0.049475, lr=0.001000, time_each_step=0.83s, eta=3:43:59\n",
      "2022-07-06 17:42:42 [INFO]\t[TRAIN] Epoch 89 finished, loss=0.036861207 .\n",
      "2022-07-06 17:42:52 [INFO]\t[TRAIN] Epoch=90/500, Step=9/39, loss=0.037283, lr=0.001000, time_each_step=1.09s, eta=4:52:34\n",
      "2022-07-06 17:43:00 [INFO]\t[TRAIN] Epoch=90/500, Step=19/39, loss=0.029255, lr=0.001000, time_each_step=0.84s, eta=3:45:0\n",
      "2022-07-06 17:43:09 [INFO]\t[TRAIN] Epoch=90/500, Step=29/39, loss=0.023249, lr=0.001000, time_each_step=0.84s, eta=3:45:33\n",
      "2022-07-06 17:43:17 [INFO]\t[TRAIN] Epoch=90/500, Step=39/39, loss=0.062020, lr=0.001000, time_each_step=0.83s, eta=3:43:2\n",
      "2022-07-06 17:43:17 [INFO]\t[TRAIN] Epoch 90 finished, loss=0.036224954 .\n",
      "2022-07-06 17:43:17 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 17:43:17 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 17:43:19 [INFO]\t[EVAL] Finished, Epoch=90, miou=0.867943, category_iou=[0.98614887 0.74973754], oacc=0.986701, category_acc=[0.99209336 0.87382138], kappa=0.850000, category_F1-score=[0.99302614 0.85697143] .\n",
      "2022-07-06 17:43:20 [INFO]\tModel saved in /home/aistudio/exp/best_model.\n",
      "2022-07-06 17:43:20 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_90, miou=0.8679432039710966\n",
      "2022-07-06 17:43:20 [INFO]\tModel saved in /home/aistudio/exp/epoch_90.\n",
      "2022-07-06 17:43:31 [INFO]\t[TRAIN] Epoch=91/500, Step=10/39, loss=0.033157, lr=0.001000, time_each_step=1.08s, eta=4:49:15\n",
      "2022-07-06 17:43:39 [INFO]\t[TRAIN] Epoch=91/500, Step=20/39, loss=0.033325, lr=0.001000, time_each_step=0.84s, eta=3:44:14\n",
      "2022-07-06 17:43:47 [INFO]\t[TRAIN] Epoch=91/500, Step=30/39, loss=0.046747, lr=0.001000, time_each_step=0.83s, eta=3:43:10\n",
      "2022-07-06 17:43:55 [INFO]\t[TRAIN] Epoch 91 finished, loss=0.03608817 .\n",
      "2022-07-06 17:43:58 [INFO]\t[TRAIN] Epoch=92/500, Step=1/39, loss=0.025506, lr=0.001000, time_each_step=1.08s, eta=4:49:49\n",
      "2022-07-06 17:44:07 [INFO]\t[TRAIN] Epoch=92/500, Step=11/39, loss=0.041801, lr=0.001000, time_each_step=0.86s, eta=3:50:0\n",
      "2022-07-06 17:44:15 [INFO]\t[TRAIN] Epoch=92/500, Step=21/39, loss=0.023295, lr=0.001000, time_each_step=0.84s, eta=3:45:19\n",
      "2022-07-06 17:44:24 [INFO]\t[TRAIN] Epoch=92/500, Step=31/39, loss=0.024923, lr=0.001000, time_each_step=0.84s, eta=3:43:19\n",
      "2022-07-06 17:44:31 [INFO]\t[TRAIN] Epoch 92 finished, loss=0.038206395 .\n",
      "2022-07-06 17:44:35 [INFO]\t[TRAIN] Epoch=93/500, Step=2/39, loss=0.059091, lr=0.001000, time_each_step=1.06s, eta=4:44:1\n",
      "2022-07-06 17:44:43 [INFO]\t[TRAIN] Epoch=93/500, Step=12/39, loss=0.044115, lr=0.001000, time_each_step=0.85s, eta=3:45:54\n",
      "2022-07-06 17:44:51 [INFO]\t[TRAIN] Epoch=93/500, Step=22/39, loss=0.015218, lr=0.001000, time_each_step=0.83s, eta=3:42:29\n",
      "2022-07-06 17:45:00 [INFO]\t[TRAIN] Epoch=93/500, Step=32/39, loss=0.040547, lr=0.001000, time_each_step=0.83s, eta=3:42:9\n",
      "2022-07-06 17:45:06 [INFO]\t[TRAIN] Epoch 93 finished, loss=0.035100054 .\n",
      "2022-07-06 17:45:11 [INFO]\t[TRAIN] Epoch=94/500, Step=3/39, loss=0.031233, lr=0.001000, time_each_step=1.11s, eta=4:55:15\n",
      "2022-07-06 17:45:19 [INFO]\t[TRAIN] Epoch=94/500, Step=13/39, loss=0.032364, lr=0.001000, time_each_step=0.85s, eta=3:46:22\n",
      "2022-07-06 17:45:28 [INFO]\t[TRAIN] Epoch=94/500, Step=23/39, loss=0.062820, lr=0.001000, time_each_step=0.85s, eta=3:46:46\n",
      "2022-07-06 17:45:36 [INFO]\t[TRAIN] Epoch=94/500, Step=33/39, loss=0.056670, lr=0.001000, time_each_step=0.84s, eta=3:42:8\n",
      "2022-07-06 17:45:42 [INFO]\t[TRAIN] Epoch 94 finished, loss=0.038048424 .\n",
      "2022-07-06 17:45:47 [INFO]\t[TRAIN] Epoch=95/500, Step=4/39, loss=0.027312, lr=0.001000, time_each_step=1.08s, eta=4:46:36\n",
      "2022-07-06 17:45:56 [INFO]\t[TRAIN] Epoch=95/500, Step=14/39, loss=0.035104, lr=0.001000, time_each_step=0.85s, eta=3:45:3\n",
      "2022-07-06 17:46:04 [INFO]\t[TRAIN] Epoch=95/500, Step=24/39, loss=0.036700, lr=0.001000, time_each_step=0.84s, eta=3:42:57\n",
      "2022-07-06 17:46:13 [INFO]\t[TRAIN] Epoch=95/500, Step=34/39, loss=0.039056, lr=0.001000, time_each_step=0.84s, eta=3:42:51\n",
      "2022-07-06 17:46:17 [INFO]\t[TRAIN] Epoch 95 finished, loss=0.036926135 .\n",
      "2022-07-06 17:46:24 [INFO]\t[TRAIN] Epoch=96/500, Step=5/39, loss=0.038598, lr=0.001000, time_each_step=1.14s, eta=5:1:49\n",
      "2022-07-06 17:46:33 [INFO]\t[TRAIN] Epoch=96/500, Step=15/39, loss=0.083156, lr=0.001000, time_each_step=0.84s, eta=3:43:40\n",
      "2022-07-06 17:46:41 [INFO]\t[TRAIN] Epoch=96/500, Step=25/39, loss=0.033168, lr=0.001000, time_each_step=0.83s, eta=3:40:44\n",
      "2022-07-06 17:46:49 [INFO]\t[TRAIN] Epoch=96/500, Step=35/39, loss=0.022749, lr=0.001000, time_each_step=0.83s, eta=3:40:20\n",
      "2022-07-06 17:46:53 [INFO]\t[TRAIN] Epoch 96 finished, loss=0.03803283 .\n",
      "2022-07-06 17:47:01 [INFO]\t[TRAIN] Epoch=97/500, Step=6/39, loss=0.035283, lr=0.001000, time_each_step=1.12s, eta=4:56:29\n",
      "2022-07-06 17:47:09 [INFO]\t[TRAIN] Epoch=97/500, Step=16/39, loss=0.042587, lr=0.001000, time_each_step=0.84s, eta=3:41:0\n",
      "2022-07-06 17:47:17 [INFO]\t[TRAIN] Epoch=97/500, Step=26/39, loss=0.038521, lr=0.001000, time_each_step=0.84s, eta=3:40:42\n",
      "2022-07-06 17:47:26 [INFO]\t[TRAIN] Epoch=97/500, Step=36/39, loss=0.029773, lr=0.001000, time_each_step=0.83s, eta=3:40:11\n",
      "2022-07-06 17:47:28 [INFO]\t[TRAIN] Epoch 97 finished, loss=0.035868507 .\n",
      "2022-07-06 17:47:37 [INFO]\t[TRAIN] Epoch=98/500, Step=7/39, loss=0.028798, lr=0.001000, time_each_step=1.09s, eta=4:46:22\n",
      "2022-07-06 17:47:45 [INFO]\t[TRAIN] Epoch=98/500, Step=17/39, loss=0.027973, lr=0.001000, time_each_step=0.84s, eta=3:41:26\n",
      "2022-07-06 17:47:53 [INFO]\t[TRAIN] Epoch=98/500, Step=27/39, loss=0.035648, lr=0.001000, time_each_step=0.83s, eta=3:39:41\n",
      "2022-07-06 17:48:02 [INFO]\t[TRAIN] Epoch=98/500, Step=37/39, loss=0.043023, lr=0.001000, time_each_step=0.83s, eta=3:39:26\n",
      "2022-07-06 17:48:04 [INFO]\t[TRAIN] Epoch 98 finished, loss=0.036568813 .\n",
      "2022-07-06 17:48:13 [INFO]\t[TRAIN] Epoch=99/500, Step=8/39, loss=0.064512, lr=0.001000, time_each_step=1.16s, eta=5:4:6\n",
      "2022-07-06 17:48:22 [INFO]\t[TRAIN] Epoch=99/500, Step=18/39, loss=0.029232, lr=0.001000, time_each_step=0.84s, eta=3:41:20\n",
      "2022-07-06 17:48:30 [INFO]\t[TRAIN] Epoch=99/500, Step=28/39, loss=0.054276, lr=0.001000, time_each_step=0.84s, eta=3:40:48\n",
      "2022-07-06 17:48:39 [INFO]\t[TRAIN] Epoch=99/500, Step=38/39, loss=0.031596, lr=0.001000, time_each_step=0.83s, eta=3:38:12\n",
      "2022-07-06 17:48:40 [INFO]\t[TRAIN] Epoch 99 finished, loss=0.036192007 .\n",
      "2022-07-06 17:48:49 [INFO]\t[TRAIN] Epoch=100/500, Step=9/39, loss=0.054512, lr=0.001000, time_each_step=1.08s, eta=4:42:5\n",
      "2022-07-06 17:48:58 [INFO]\t[TRAIN] Epoch=100/500, Step=19/39, loss=0.044914, lr=0.001000, time_each_step=0.84s, eta=3:39:9\n",
      "2022-07-06 17:49:06 [INFO]\t[TRAIN] Epoch=100/500, Step=29/39, loss=0.041723, lr=0.001000, time_each_step=0.83s, eta=3:38:42\n",
      "2022-07-06 17:49:15 [INFO]\t[TRAIN] Epoch=100/500, Step=39/39, loss=0.061177, lr=0.001000, time_each_step=0.83s, eta=3:37:56\n",
      "2022-07-06 17:49:15 [INFO]\t[TRAIN] Epoch 100 finished, loss=0.035832193 .\n",
      "2022-07-06 17:49:15 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 17:49:15 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 17:49:17 [INFO]\t[EVAL] Finished, Epoch=100, miou=0.873059, category_iou=[0.98655011 0.75956778], oacc=0.987098, category_acc=[0.99304336 0.86663625], kappa=0.856587, category_F1-score=[0.99322953 0.86335722] .\n",
      "2022-07-06 17:49:17 [INFO]\tModel saved in /home/aistudio/exp/best_model.\n",
      "2022-07-06 17:49:17 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_100, miou=0.8730589437232252\n",
      "2022-07-06 17:49:18 [INFO]\tModel saved in /home/aistudio/exp/epoch_100.\n",
      "2022-07-06 17:49:29 [INFO]\t[TRAIN] Epoch=101/500, Step=10/39, loss=0.045894, lr=0.001000, time_each_step=1.1s, eta=4:48:29\n",
      "2022-07-06 17:49:37 [INFO]\t[TRAIN] Epoch=101/500, Step=20/39, loss=0.033132, lr=0.001000, time_each_step=0.86s, eta=3:44:58\n",
      "2022-07-06 17:49:46 [INFO]\t[TRAIN] Epoch=101/500, Step=30/39, loss=0.027192, lr=0.001000, time_each_step=0.83s, eta=3:37:50\n",
      "2022-07-06 17:49:53 [INFO]\t[TRAIN] Epoch 101 finished, loss=0.03628039 .\n",
      "2022-07-06 17:49:56 [INFO]\t[TRAIN] Epoch=102/500, Step=1/39, loss=0.062388, lr=0.001000, time_each_step=1.07s, eta=4:39:43\n",
      "2022-07-06 17:50:05 [INFO]\t[TRAIN] Epoch=102/500, Step=11/39, loss=0.042553, lr=0.001000, time_each_step=0.85s, eta=3:42:43\n",
      "2022-07-06 17:50:13 [INFO]\t[TRAIN] Epoch=102/500, Step=21/39, loss=0.039209, lr=0.001000, time_each_step=0.84s, eta=3:39:57\n",
      "2022-07-06 17:50:22 [INFO]\t[TRAIN] Epoch=102/500, Step=31/39, loss=0.034591, lr=0.001000, time_each_step=0.84s, eta=3:37:49\n",
      "2022-07-06 17:50:28 [INFO]\t[TRAIN] Epoch 102 finished, loss=0.036274847 .\n",
      "2022-07-06 17:50:33 [INFO]\t[TRAIN] Epoch=103/500, Step=2/39, loss=0.036806, lr=0.001000, time_each_step=1.13s, eta=4:54:29\n",
      "2022-07-06 17:50:42 [INFO]\t[TRAIN] Epoch=103/500, Step=12/39, loss=0.038525, lr=0.001000, time_each_step=0.86s, eta=3:44:58\n",
      "2022-07-06 17:50:50 [INFO]\t[TRAIN] Epoch=103/500, Step=22/39, loss=0.034341, lr=0.001000, time_each_step=0.84s, eta=3:38:40\n",
      "2022-07-06 17:50:59 [INFO]\t[TRAIN] Epoch=103/500, Step=32/39, loss=0.035574, lr=0.001000, time_each_step=0.84s, eta=3:37:20\n",
      "2022-07-06 17:51:04 [INFO]\t[TRAIN] Epoch 103 finished, loss=0.035265133 .\n",
      "2022-07-06 17:51:10 [INFO]\t[TRAIN] Epoch=104/500, Step=3/39, loss=0.036555, lr=0.001000, time_each_step=1.17s, eta=5:2:34\n",
      "2022-07-06 17:51:19 [INFO]\t[TRAIN] Epoch=104/500, Step=13/39, loss=0.061662, lr=0.001000, time_each_step=0.84s, eta=3:38:44\n",
      "2022-07-06 17:51:27 [INFO]\t[TRAIN] Epoch=104/500, Step=23/39, loss=0.034232, lr=0.001000, time_each_step=0.84s, eta=3:36:47\n",
      "2022-07-06 17:51:35 [INFO]\t[TRAIN] Epoch=104/500, Step=33/39, loss=0.018510, lr=0.001000, time_each_step=0.84s, eta=3:37:1\n",
      "2022-07-06 17:51:41 [INFO]\t[TRAIN] Epoch 104 finished, loss=0.035316963 .\n",
      "2022-07-06 17:51:46 [INFO]\t[TRAIN] Epoch=105/500, Step=4/39, loss=0.038875, lr=0.001000, time_each_step=1.06s, eta=4:34:50\n",
      "2022-07-06 17:51:55 [INFO]\t[TRAIN] Epoch=105/500, Step=14/39, loss=0.041438, lr=0.001000, time_each_step=0.85s, eta=3:38:59\n",
      "2022-07-06 17:52:03 [INFO]\t[TRAIN] Epoch=105/500, Step=24/39, loss=0.024526, lr=0.001000, time_each_step=0.83s, eta=3:35:53\n",
      "2022-07-06 17:52:11 [INFO]\t[TRAIN] Epoch=105/500, Step=34/39, loss=0.017096, lr=0.001000, time_each_step=0.84s, eta=3:36:48\n",
      "2022-07-06 17:52:16 [INFO]\t[TRAIN] Epoch 105 finished, loss=0.033901367 .\n",
      "2022-07-06 17:52:22 [INFO]\t[TRAIN] Epoch=106/500, Step=5/39, loss=0.035571, lr=0.001000, time_each_step=1.08s, eta=4:39:8\n",
      "2022-07-06 17:52:31 [INFO]\t[TRAIN] Epoch=106/500, Step=15/39, loss=0.043212, lr=0.001000, time_each_step=0.85s, eta=3:39:16\n",
      "2022-07-06 17:52:39 [INFO]\t[TRAIN] Epoch=106/500, Step=25/39, loss=0.035068, lr=0.001000, time_each_step=0.84s, eta=3:36:54\n",
      "2022-07-06 17:52:48 [INFO]\t[TRAIN] Epoch=106/500, Step=35/39, loss=0.038179, lr=0.001000, time_each_step=0.84s, eta=3:37:26\n",
      "2022-07-06 17:52:51 [INFO]\t[TRAIN] Epoch 106 finished, loss=0.034928102 .\n",
      "2022-07-06 17:52:59 [INFO]\t[TRAIN] Epoch=107/500, Step=6/39, loss=0.066440, lr=0.001000, time_each_step=1.09s, eta=4:40:54\n",
      "2022-07-06 17:53:07 [INFO]\t[TRAIN] Epoch=107/500, Step=16/39, loss=0.034758, lr=0.001000, time_each_step=0.84s, eta=3:35:51\n",
      "2022-07-06 17:53:15 [INFO]\t[TRAIN] Epoch=107/500, Step=26/39, loss=0.033207, lr=0.001000, time_each_step=0.83s, eta=3:34:54\n",
      "2022-07-06 17:53:24 [INFO]\t[TRAIN] Epoch=107/500, Step=36/39, loss=0.026065, lr=0.001000, time_each_step=0.84s, eta=3:35:17\n",
      "2022-07-06 17:53:26 [INFO]\t[TRAIN] Epoch 107 finished, loss=0.035022367 .\n",
      "2022-07-06 17:53:37 [INFO]\t[TRAIN] Epoch=108/500, Step=7/39, loss=0.037393, lr=0.001000, time_each_step=1.29s, eta=5:30:25\n",
      "2022-07-06 17:53:45 [INFO]\t[TRAIN] Epoch=108/500, Step=17/39, loss=0.030564, lr=0.001000, time_each_step=0.84s, eta=3:36:54\n",
      "2022-07-06 17:53:54 [INFO]\t[TRAIN] Epoch=108/500, Step=27/39, loss=0.038518, lr=0.001000, time_each_step=0.84s, eta=3:35:27\n",
      "2022-07-06 17:54:02 [INFO]\t[TRAIN] Epoch=108/500, Step=37/39, loss=0.033577, lr=0.001000, time_each_step=0.83s, eta=3:33:48\n",
      "2022-07-06 17:54:04 [INFO]\t[TRAIN] Epoch 108 finished, loss=0.034864184 .\n",
      "2022-07-06 17:54:13 [INFO]\t[TRAIN] Epoch=109/500, Step=8/39, loss=0.013746, lr=0.001000, time_each_step=1.09s, eta=4:38:27\n",
      "2022-07-06 17:54:21 [INFO]\t[TRAIN] Epoch=109/500, Step=18/39, loss=0.035742, lr=0.001000, time_each_step=0.85s, eta=3:36:55\n",
      "2022-07-06 17:54:30 [INFO]\t[TRAIN] Epoch=109/500, Step=28/39, loss=0.039429, lr=0.001000, time_each_step=0.83s, eta=3:33:23\n",
      "2022-07-06 17:54:38 [INFO]\t[TRAIN] Epoch=109/500, Step=38/39, loss=0.033515, lr=0.001000, time_each_step=0.83s, eta=3:33:19\n",
      "2022-07-06 17:54:39 [INFO]\t[TRAIN] Epoch 109 finished, loss=0.032881986 .\n",
      "2022-07-06 17:54:49 [INFO]\t[TRAIN] Epoch=110/500, Step=9/39, loss=0.027694, lr=0.001000, time_each_step=1.1s, eta=4:40:22\n",
      "2022-07-06 17:54:58 [INFO]\t[TRAIN] Epoch=110/500, Step=19/39, loss=0.043331, lr=0.001000, time_each_step=0.86s, eta=3:38:54\n",
      "2022-07-06 17:55:06 [INFO]\t[TRAIN] Epoch=110/500, Step=29/39, loss=0.039391, lr=0.001000, time_each_step=0.84s, eta=3:35:51\n",
      "2022-07-06 17:55:14 [INFO]\t[TRAIN] Epoch=110/500, Step=39/39, loss=0.049912, lr=0.001000, time_each_step=0.83s, eta=3:32:52\n",
      "2022-07-06 17:55:15 [INFO]\t[TRAIN] Epoch 110 finished, loss=0.034775242 .\n",
      "2022-07-06 17:55:15 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 17:55:15 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 17:55:17 [INFO]\t[EVAL] Finished, Epoch=110, miou=0.867618, category_iou=[0.98670957 0.74852556], oacc=0.987215, category_acc=[0.99026183 0.91686083], kappa=0.849520, category_F1-score=[0.99331033 0.85617915] .\n",
      "2022-07-06 17:55:17 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_100, miou=0.8730589437232252\n",
      "2022-07-06 17:55:17 [INFO]\tModel saved in /home/aistudio/exp/epoch_110.\n",
      "2022-07-06 17:55:28 [INFO]\t[TRAIN] Epoch=111/500, Step=10/39, loss=0.023020, lr=0.001000, time_each_step=1.09s, eta=4:36:24\n",
      "2022-07-06 17:55:36 [INFO]\t[TRAIN] Epoch=111/500, Step=20/39, loss=0.039455, lr=0.001000, time_each_step=0.83s, eta=3:32:6\n",
      "2022-07-06 17:55:44 [INFO]\t[TRAIN] Epoch=111/500, Step=30/39, loss=0.042602, lr=0.001000, time_each_step=0.83s, eta=3:32:12\n",
      "2022-07-06 17:55:52 [INFO]\t[TRAIN] Epoch 111 finished, loss=0.035244416 .\n",
      "2022-07-06 17:55:56 [INFO]\t[TRAIN] Epoch=112/500, Step=1/39, loss=0.037761, lr=0.001000, time_each_step=1.1s, eta=4:39:43\n",
      "2022-07-06 17:56:04 [INFO]\t[TRAIN] Epoch=112/500, Step=11/39, loss=0.032783, lr=0.001000, time_each_step=0.86s, eta=3:37:31\n",
      "2022-07-06 17:56:13 [INFO]\t[TRAIN] Epoch=112/500, Step=21/39, loss=0.043431, lr=0.001000, time_each_step=0.83s, eta=3:31:52\n",
      "2022-07-06 17:56:21 [INFO]\t[TRAIN] Epoch=112/500, Step=31/39, loss=0.036606, lr=0.001000, time_each_step=0.83s, eta=3:31:38\n",
      "2022-07-06 17:56:28 [INFO]\t[TRAIN] Epoch 112 finished, loss=0.038530402 .\n",
      "2022-07-06 17:56:32 [INFO]\t[TRAIN] Epoch=113/500, Step=2/39, loss=0.034160, lr=0.001000, time_each_step=1.08s, eta=4:32:29\n",
      "2022-07-06 17:56:40 [INFO]\t[TRAIN] Epoch=113/500, Step=12/39, loss=0.024967, lr=0.001000, time_each_step=0.85s, eta=3:34:41\n",
      "2022-07-06 17:56:49 [INFO]\t[TRAIN] Epoch=113/500, Step=22/39, loss=0.062829, lr=0.001000, time_each_step=0.83s, eta=3:31:31\n",
      "2022-07-06 17:56:57 [INFO]\t[TRAIN] Epoch=113/500, Step=32/39, loss=0.027387, lr=0.001000, time_each_step=0.84s, eta=3:31:43\n",
      "2022-07-06 17:57:03 [INFO]\t[TRAIN] Epoch 113 finished, loss=0.03718963 .\n",
      "2022-07-06 17:57:08 [INFO]\t[TRAIN] Epoch=114/500, Step=3/39, loss=0.033963, lr=0.001000, time_each_step=1.08s, eta=4:32:37\n",
      "2022-07-06 17:57:16 [INFO]\t[TRAIN] Epoch=114/500, Step=13/39, loss=0.050757, lr=0.001000, time_each_step=0.85s, eta=3:34:21\n",
      "2022-07-06 17:57:25 [INFO]\t[TRAIN] Epoch=114/500, Step=23/39, loss=0.039929, lr=0.001000, time_each_step=0.83s, eta=3:30:13\n",
      "2022-07-06 17:57:33 [INFO]\t[TRAIN] Epoch=114/500, Step=33/39, loss=0.053025, lr=0.001000, time_each_step=0.83s, eta=3:30:18\n",
      "2022-07-06 17:57:38 [INFO]\t[TRAIN] Epoch 114 finished, loss=0.03719759 .\n",
      "2022-07-06 17:57:44 [INFO]\t[TRAIN] Epoch=115/500, Step=4/39, loss=0.038404, lr=0.001000, time_each_step=1.08s, eta=4:31:16\n",
      "2022-07-06 17:57:52 [INFO]\t[TRAIN] Epoch=115/500, Step=14/39, loss=0.058196, lr=0.001000, time_each_step=0.84s, eta=3:32:36\n",
      "2022-07-06 17:58:01 [INFO]\t[TRAIN] Epoch=115/500, Step=24/39, loss=0.036708, lr=0.001000, time_each_step=0.84s, eta=3:30:49\n",
      "2022-07-06 17:58:09 [INFO]\t[TRAIN] Epoch=115/500, Step=34/39, loss=0.028851, lr=0.001000, time_each_step=0.84s, eta=3:31:43\n",
      "2022-07-06 17:58:13 [INFO]\t[TRAIN] Epoch 115 finished, loss=0.035146207 .\n",
      "2022-07-06 17:58:21 [INFO]\t[TRAIN] Epoch=116/500, Step=5/39, loss=0.040302, lr=0.001000, time_each_step=1.15s, eta=4:49:9\n",
      "2022-07-06 17:58:29 [INFO]\t[TRAIN] Epoch=116/500, Step=15/39, loss=0.022281, lr=0.001000, time_each_step=0.84s, eta=3:30:23\n",
      "2022-07-06 17:58:37 [INFO]\t[TRAIN] Epoch=116/500, Step=25/39, loss=0.035844, lr=0.001000, time_each_step=0.83s, eta=3:29:36\n",
      "2022-07-06 17:58:46 [INFO]\t[TRAIN] Epoch=116/500, Step=35/39, loss=0.024497, lr=0.001000, time_each_step=0.83s, eta=3:29:2\n",
      "2022-07-06 17:58:49 [INFO]\t[TRAIN] Epoch 116 finished, loss=0.034943257 .\n",
      "2022-07-06 17:58:57 [INFO]\t[TRAIN] Epoch=117/500, Step=6/39, loss=0.043634, lr=0.001000, time_each_step=1.08s, eta=4:30:42\n",
      "2022-07-06 17:59:05 [INFO]\t[TRAIN] Epoch=117/500, Step=16/39, loss=0.058937, lr=0.001000, time_each_step=0.86s, eta=3:36:11\n",
      "2022-07-06 17:59:14 [INFO]\t[TRAIN] Epoch=117/500, Step=26/39, loss=0.032005, lr=0.001000, time_each_step=0.84s, eta=3:30:40\n",
      "2022-07-06 17:59:22 [INFO]\t[TRAIN] Epoch=117/500, Step=36/39, loss=0.052004, lr=0.001000, time_each_step=0.83s, eta=3:28:22\n",
      "2022-07-06 17:59:25 [INFO]\t[TRAIN] Epoch 117 finished, loss=0.03586728 .\n",
      "2022-07-06 17:59:33 [INFO]\t[TRAIN] Epoch=118/500, Step=7/39, loss=0.028582, lr=0.001000, time_each_step=1.12s, eta=4:40:55\n",
      "2022-07-06 17:59:42 [INFO]\t[TRAIN] Epoch=118/500, Step=17/39, loss=0.030329, lr=0.001000, time_each_step=0.84s, eta=3:30:1\n",
      "2022-07-06 17:59:50 [INFO]\t[TRAIN] Epoch=118/500, Step=27/39, loss=0.039484, lr=0.001000, time_each_step=0.83s, eta=3:28:20\n",
      "2022-07-06 17:59:58 [INFO]\t[TRAIN] Epoch=118/500, Step=37/39, loss=0.032159, lr=0.001000, time_each_step=0.83s, eta=3:27:50\n",
      "2022-07-06 18:00:00 [INFO]\t[TRAIN] Epoch 118 finished, loss=0.035553765 .\n",
      "2022-07-06 18:00:10 [INFO]\t[TRAIN] Epoch=119/500, Step=8/39, loss=0.023420, lr=0.001000, time_each_step=1.13s, eta=4:40:45\n",
      "2022-07-06 18:00:18 [INFO]\t[TRAIN] Epoch=119/500, Step=18/39, loss=0.028262, lr=0.001000, time_each_step=0.84s, eta=3:29:50\n",
      "2022-07-06 18:00:26 [INFO]\t[TRAIN] Epoch=119/500, Step=28/39, loss=0.041399, lr=0.001000, time_each_step=0.83s, eta=3:27:34\n",
      "2022-07-06 18:00:35 [INFO]\t[TRAIN] Epoch=119/500, Step=38/39, loss=0.050802, lr=0.001000, time_each_step=0.83s, eta=3:27:43\n",
      "2022-07-06 18:00:36 [INFO]\t[TRAIN] Epoch 119 finished, loss=0.03450104 .\n",
      "2022-07-06 18:00:46 [INFO]\t[TRAIN] Epoch=120/500, Step=9/39, loss=0.012455, lr=0.001000, time_each_step=1.09s, eta=4:31:2\n",
      "2022-07-06 18:00:54 [INFO]\t[TRAIN] Epoch=120/500, Step=19/39, loss=0.036738, lr=0.001000, time_each_step=0.84s, eta=3:27:54\n",
      "2022-07-06 18:01:03 [INFO]\t[TRAIN] Epoch=120/500, Step=29/39, loss=0.029627, lr=0.001000, time_each_step=0.83s, eta=3:27:31\n",
      "2022-07-06 18:01:11 [INFO]\t[TRAIN] Epoch=120/500, Step=39/39, loss=0.039233, lr=0.001000, time_each_step=0.83s, eta=3:26:43\n",
      "2022-07-06 18:01:11 [INFO]\t[TRAIN] Epoch 120 finished, loss=0.03382368 .\n",
      "2022-07-06 18:01:11 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 18:01:11 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 18:01:13 [INFO]\t[EVAL] Finished, Epoch=120, miou=0.872959, category_iou=[0.98705302 0.75886483], oacc=0.987560, category_acc=[0.99138816 0.90308005], kappa=0.856401, category_F1-score=[0.99348433 0.86290295] .\n",
      "2022-07-06 18:01:13 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_100, miou=0.8730589437232252\n",
      "2022-07-06 18:01:14 [INFO]\tModel saved in /home/aistudio/exp/epoch_120.\n",
      "2022-07-06 18:01:25 [INFO]\t[TRAIN] Epoch=121/500, Step=10/39, loss=0.032722, lr=0.001000, time_each_step=1.13s, eta=4:39:24\n",
      "2022-07-06 18:01:33 [INFO]\t[TRAIN] Epoch=121/500, Step=20/39, loss=0.025999, lr=0.001000, time_each_step=0.85s, eta=3:31:12\n",
      "2022-07-06 18:01:42 [INFO]\t[TRAIN] Epoch=121/500, Step=30/39, loss=0.026686, lr=0.001000, time_each_step=0.83s, eta=3:26:29\n",
      "2022-07-06 18:01:49 [INFO]\t[TRAIN] Epoch 121 finished, loss=0.034992237 .\n",
      "2022-07-06 18:01:52 [INFO]\t[TRAIN] Epoch=122/500, Step=1/39, loss=0.040615, lr=0.001000, time_each_step=1.06s, eta=4:22:48\n",
      "2022-07-06 18:02:01 [INFO]\t[TRAIN] Epoch=122/500, Step=11/39, loss=0.048831, lr=0.001000, time_each_step=0.85s, eta=3:29:59\n",
      "2022-07-06 18:02:09 [INFO]\t[TRAIN] Epoch=122/500, Step=21/39, loss=0.034147, lr=0.001000, time_each_step=0.84s, eta=3:27:2\n",
      "2022-07-06 18:02:18 [INFO]\t[TRAIN] Epoch=122/500, Step=31/39, loss=0.023923, lr=0.001000, time_each_step=0.84s, eta=3:27:55\n",
      "2022-07-06 18:02:24 [INFO]\t[TRAIN] Epoch 122 finished, loss=0.031093707 .\n",
      "2022-07-06 18:02:29 [INFO]\t[TRAIN] Epoch=123/500, Step=2/39, loss=0.027952, lr=0.001000, time_each_step=1.08s, eta=4:26:12\n",
      "2022-07-06 18:02:37 [INFO]\t[TRAIN] Epoch=123/500, Step=12/39, loss=0.041187, lr=0.001000, time_each_step=0.87s, eta=3:34:0\n",
      "2022-07-06 18:02:46 [INFO]\t[TRAIN] Epoch=123/500, Step=22/39, loss=0.034091, lr=0.001000, time_each_step=0.83s, eta=3:25:52\n",
      "2022-07-06 18:02:54 [INFO]\t[TRAIN] Epoch=123/500, Step=32/39, loss=0.027687, lr=0.001000, time_each_step=0.83s, eta=3:25:33\n",
      "2022-07-06 18:03:00 [INFO]\t[TRAIN] Epoch 123 finished, loss=0.032606207 .\n",
      "2022-07-06 18:03:05 [INFO]\t[TRAIN] Epoch=124/500, Step=3/39, loss=0.025901, lr=0.001000, time_each_step=1.07s, eta=4:23:56\n",
      "2022-07-06 18:03:13 [INFO]\t[TRAIN] Epoch=124/500, Step=13/39, loss=0.033290, lr=0.001000, time_each_step=0.85s, eta=3:30:12\n",
      "2022-07-06 18:03:22 [INFO]\t[TRAIN] Epoch=124/500, Step=23/39, loss=0.046943, lr=0.001000, time_each_step=0.84s, eta=3:26:54\n",
      "2022-07-06 18:03:30 [INFO]\t[TRAIN] Epoch=124/500, Step=33/39, loss=0.019338, lr=0.001000, time_each_step=0.85s, eta=3:28:28\n",
      "2022-07-06 18:03:35 [INFO]\t[TRAIN] Epoch 124 finished, loss=0.032110486 .\n",
      "2022-07-06 18:03:41 [INFO]\t[TRAIN] Epoch=125/500, Step=4/39, loss=0.032640, lr=0.001000, time_each_step=1.11s, eta=4:31:58\n",
      "2022-07-06 18:03:50 [INFO]\t[TRAIN] Epoch=125/500, Step=14/39, loss=0.028677, lr=0.001000, time_each_step=0.85s, eta=3:29:13\n",
      "2022-07-06 18:03:58 [INFO]\t[TRAIN] Epoch=125/500, Step=24/39, loss=0.040680, lr=0.001000, time_each_step=0.84s, eta=3:26:7\n",
      "2022-07-06 18:04:07 [INFO]\t[TRAIN] Epoch=125/500, Step=34/39, loss=0.026607, lr=0.001000, time_each_step=0.84s, eta=3:25:6\n",
      "2022-07-06 18:04:11 [INFO]\t[TRAIN] Epoch 125 finished, loss=0.031519007 .\n",
      "2022-07-06 18:04:18 [INFO]\t[TRAIN] Epoch=126/500, Step=5/39, loss=0.036217, lr=0.001000, time_each_step=1.08s, eta=4:25:0\n",
      "2022-07-06 18:04:43 [INFO]\t[TRAIN] Epoch=126/500, Step=35/39, loss=0.028325, lr=0.001000, time_each_step=0.83s, eta=3:24:12\n",
      "2022-07-06 18:04:47 [INFO]\t[TRAIN] Epoch 126 finished, loss=0.03263734 .\n",
      "2022-07-06 18:04:54 [INFO]\t[TRAIN] Epoch=127/500, Step=6/39, loss=0.026520, lr=0.001000, time_each_step=1.08s, eta=4:23:0\n",
      "2022-07-06 18:05:02 [INFO]\t[TRAIN] Epoch=127/500, Step=16/39, loss=0.029814, lr=0.001000, time_each_step=0.84s, eta=3:24:45\n",
      "2022-07-06 18:05:11 [INFO]\t[TRAIN] Epoch=127/500, Step=26/39, loss=0.069704, lr=0.001000, time_each_step=0.84s, eta=3:24:14\n",
      "2022-07-06 18:05:19 [INFO]\t[TRAIN] Epoch=127/500, Step=36/39, loss=0.030006, lr=0.001000, time_each_step=0.84s, eta=3:24:35\n",
      "2022-07-06 18:05:22 [INFO]\t[TRAIN] Epoch 127 finished, loss=0.032197364 .\n",
      "2022-07-06 18:05:31 [INFO]\t[TRAIN] Epoch=128/500, Step=7/39, loss=0.030951, lr=0.001000, time_each_step=1.15s, eta=4:40:57\n",
      "2022-07-06 18:05:39 [INFO]\t[TRAIN] Epoch=128/500, Step=17/39, loss=0.040911, lr=0.001000, time_each_step=0.85s, eta=3:27:39\n",
      "2022-07-06 18:05:48 [INFO]\t[TRAIN] Epoch=128/500, Step=27/39, loss=0.019530, lr=0.001000, time_each_step=0.84s, eta=3:23:42\n",
      "2022-07-06 18:05:56 [INFO]\t[TRAIN] Epoch=128/500, Step=37/39, loss=0.017905, lr=0.001000, time_each_step=0.83s, eta=3:22:31\n",
      "2022-07-06 18:05:58 [INFO]\t[TRAIN] Epoch 128 finished, loss=0.032960143 .\n",
      "2022-07-06 18:06:07 [INFO]\t[TRAIN] Epoch=129/500, Step=8/39, loss=0.047745, lr=0.001000, time_each_step=1.08s, eta=4:21:14\n",
      "2022-07-06 18:06:16 [INFO]\t[TRAIN] Epoch=129/500, Step=18/39, loss=0.026918, lr=0.001000, time_each_step=0.87s, eta=3:30:55\n",
      "2022-07-06 18:06:24 [INFO]\t[TRAIN] Epoch=129/500, Step=28/39, loss=0.015998, lr=0.001000, time_each_step=0.84s, eta=3:22:58\n",
      "2022-07-06 18:06:32 [INFO]\t[TRAIN] Epoch=129/500, Step=38/39, loss=0.036141, lr=0.001000, time_each_step=0.83s, eta=3:22:24\n",
      "2022-07-06 18:06:33 [INFO]\t[TRAIN] Epoch 129 finished, loss=0.0334627 .\n",
      "2022-07-06 18:06:44 [INFO]\t[TRAIN] Epoch=130/500, Step=9/39, loss=0.032757, lr=0.001000, time_each_step=1.15s, eta=4:38:46\n",
      "2022-07-06 18:06:52 [INFO]\t[TRAIN] Epoch=130/500, Step=19/39, loss=0.040369, lr=0.001000, time_each_step=0.83s, eta=3:21:58\n",
      "2022-07-06 18:07:01 [INFO]\t[TRAIN] Epoch=130/500, Step=29/39, loss=0.034326, lr=0.001000, time_each_step=0.84s, eta=3:22:36\n",
      "2022-07-06 18:07:09 [INFO]\t[TRAIN] Epoch=130/500, Step=39/39, loss=0.036388, lr=0.001000, time_each_step=0.83s, eta=3:21:6\n",
      "2022-07-06 18:07:09 [INFO]\t[TRAIN] Epoch 130 finished, loss=0.031317398 .\n",
      "2022-07-06 18:07:09 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 18:07:09 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 18:07:11 [INFO]\t[EVAL] Finished, Epoch=130, miou=0.877401, category_iou=[0.98725677 0.76754553], oacc=0.987771, category_acc=[0.99265501 0.8855487 ], kappa=0.862077, category_F1-score=[0.99358753 0.86848742] .\n",
      "2022-07-06 18:07:12 [INFO]\tModel saved in /home/aistudio/exp/best_model.\n",
      "2022-07-06 18:07:12 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_130, miou=0.8774011512502358\n",
      "2022-07-06 18:07:12 [INFO]\tModel saved in /home/aistudio/exp/epoch_130.\n",
      "2022-07-06 18:07:24 [INFO]\t[TRAIN] Epoch=131/500, Step=10/39, loss=0.023787, lr=0.001000, time_each_step=1.23s, eta=4:58:16\n",
      "2022-07-06 18:07:33 [INFO]\t[TRAIN] Epoch=131/500, Step=20/39, loss=0.030614, lr=0.001000, time_each_step=0.83s, eta=3:21:41\n",
      "2022-07-06 18:07:41 [INFO]\t[TRAIN] Epoch=131/500, Step=30/39, loss=0.025809, lr=0.001000, time_each_step=0.85s, eta=3:25:16\n",
      "2022-07-06 18:07:49 [INFO]\t[TRAIN] Epoch 131 finished, loss=0.031307843 .\n",
      "2022-07-06 18:07:52 [INFO]\t[TRAIN] Epoch=132/500, Step=1/39, loss=0.035034, lr=0.001000, time_each_step=1.07s, eta=4:18:44\n",
      "2022-07-06 18:08:00 [INFO]\t[TRAIN] Epoch=132/500, Step=11/39, loss=0.026291, lr=0.001000, time_each_step=0.84s, eta=3:23:55\n",
      "2022-07-06 18:08:09 [INFO]\t[TRAIN] Epoch=132/500, Step=21/39, loss=0.041156, lr=0.001000, time_each_step=0.84s, eta=3:21:36\n",
      "2022-07-06 18:08:17 [INFO]\t[TRAIN] Epoch=132/500, Step=31/39, loss=0.027487, lr=0.001000, time_each_step=0.84s, eta=3:21:34\n",
      "2022-07-06 18:08:24 [INFO]\t[TRAIN] Epoch 132 finished, loss=0.03232727 .\n",
      "2022-07-06 18:08:28 [INFO]\t[TRAIN] Epoch=133/500, Step=2/39, loss=0.035056, lr=0.001000, time_each_step=1.09s, eta=4:21:25\n",
      "2022-07-06 18:08:37 [INFO]\t[TRAIN] Epoch=133/500, Step=12/39, loss=0.024612, lr=0.001000, time_each_step=0.85s, eta=3:24:22\n",
      "2022-07-06 18:08:45 [INFO]\t[TRAIN] Epoch=133/500, Step=22/39, loss=0.020363, lr=0.001000, time_each_step=0.84s, eta=3:22:26\n",
      "2022-07-06 18:08:53 [INFO]\t[TRAIN] Epoch=133/500, Step=32/39, loss=0.048068, lr=0.001000, time_each_step=0.84s, eta=3:21:36\n",
      "2022-07-06 18:08:59 [INFO]\t[TRAIN] Epoch 133 finished, loss=0.03367967 .\n",
      "2022-07-06 18:09:05 [INFO]\t[TRAIN] Epoch=134/500, Step=3/39, loss=0.031086, lr=0.001000, time_each_step=1.1s, eta=4:24:43\n",
      "2022-07-06 18:09:13 [INFO]\t[TRAIN] Epoch=134/500, Step=13/39, loss=0.037571, lr=0.001000, time_each_step=0.85s, eta=3:23:14\n",
      "2022-07-06 18:09:21 [INFO]\t[TRAIN] Epoch=134/500, Step=23/39, loss=0.027703, lr=0.001000, time_each_step=0.84s, eta=3:20:42\n",
      "2022-07-06 18:09:30 [INFO]\t[TRAIN] Epoch=134/500, Step=33/39, loss=0.033632, lr=0.001000, time_each_step=0.83s, eta=3:19:37\n",
      "2022-07-06 18:09:35 [INFO]\t[TRAIN] Epoch 134 finished, loss=0.032102425 .\n",
      "2022-07-06 18:09:41 [INFO]\t[TRAIN] Epoch=135/500, Step=4/39, loss=0.027533, lr=0.001000, time_each_step=1.08s, eta=4:18:13\n",
      "2022-07-06 18:09:49 [INFO]\t[TRAIN] Epoch=135/500, Step=14/39, loss=0.035950, lr=0.001000, time_each_step=0.87s, eta=3:29:16\n",
      "2022-07-06 18:09:58 [INFO]\t[TRAIN] Epoch=135/500, Step=24/39, loss=0.037003, lr=0.001000, time_each_step=0.85s, eta=3:22:24\n",
      "2022-07-06 18:10:06 [INFO]\t[TRAIN] Epoch=135/500, Step=34/39, loss=0.031739, lr=0.001000, time_each_step=0.84s, eta=3:19:50\n",
      "2022-07-06 18:10:11 [INFO]\t[TRAIN] Epoch 135 finished, loss=0.032008708 .\n",
      "2022-07-06 18:10:17 [INFO]\t[TRAIN] Epoch=136/500, Step=5/39, loss=0.030110, lr=0.001000, time_each_step=1.1s, eta=4:21:38\n",
      "2022-07-06 18:10:26 [INFO]\t[TRAIN] Epoch=136/500, Step=15/39, loss=0.038028, lr=0.001000, time_each_step=0.85s, eta=3:23:34\n",
      "2022-07-06 18:10:34 [INFO]\t[TRAIN] Epoch=136/500, Step=25/39, loss=0.030313, lr=0.001000, time_each_step=0.84s, eta=3:19:16\n",
      "2022-07-06 18:10:43 [INFO]\t[TRAIN] Epoch=136/500, Step=35/39, loss=0.028870, lr=0.001000, time_each_step=0.84s, eta=3:19:33\n",
      "2022-07-06 18:10:46 [INFO]\t[TRAIN] Epoch 136 finished, loss=0.032005895 .\n",
      "2022-07-06 18:10:54 [INFO]\t[TRAIN] Epoch=137/500, Step=6/39, loss=0.026588, lr=0.001000, time_each_step=1.12s, eta=4:25:41\n",
      "2022-07-06 18:11:02 [INFO]\t[TRAIN] Epoch=137/500, Step=16/39, loss=0.027814, lr=0.001000, time_each_step=0.86s, eta=3:23:41\n",
      "2022-07-06 18:11:11 [INFO]\t[TRAIN] Epoch=137/500, Step=26/39, loss=0.025647, lr=0.001000, time_each_step=0.83s, eta=3:18:40\n",
      "2022-07-06 18:11:19 [INFO]\t[TRAIN] Epoch=137/500, Step=36/39, loss=0.024712, lr=0.001000, time_each_step=0.83s, eta=3:18:4\n",
      "2022-07-06 18:11:22 [INFO]\t[TRAIN] Epoch 137 finished, loss=0.032431405 .\n",
      "2022-07-06 18:11:30 [INFO]\t[TRAIN] Epoch=138/500, Step=7/39, loss=0.033412, lr=0.001000, time_each_step=1.09s, eta=4:17:26\n",
      "2022-07-06 18:11:39 [INFO]\t[TRAIN] Epoch=138/500, Step=17/39, loss=0.039388, lr=0.001000, time_each_step=0.84s, eta=3:20:27\n",
      "2022-07-06 18:11:47 [INFO]\t[TRAIN] Epoch=138/500, Step=27/39, loss=0.039782, lr=0.001000, time_each_step=0.84s, eta=3:19:52\n",
      "2022-07-06 18:11:55 [INFO]\t[TRAIN] Epoch=138/500, Step=37/39, loss=0.024199, lr=0.001000, time_each_step=0.84s, eta=3:18:33\n",
      "2022-07-06 18:11:57 [INFO]\t[TRAIN] Epoch 138 finished, loss=0.033197112 .\n",
      "2022-07-06 18:12:06 [INFO]\t[TRAIN] Epoch=139/500, Step=8/39, loss=0.052662, lr=0.001000, time_each_step=1.1s, eta=4:21:12\n",
      "2022-07-06 18:12:15 [INFO]\t[TRAIN] Epoch=139/500, Step=18/39, loss=0.046730, lr=0.001000, time_each_step=0.84s, eta=3:18:55\n",
      "2022-07-06 18:12:23 [INFO]\t[TRAIN] Epoch=139/500, Step=28/39, loss=0.026337, lr=0.001000, time_each_step=0.84s, eta=3:18:7\n",
      "2022-07-06 18:12:32 [INFO]\t[TRAIN] Epoch=139/500, Step=38/39, loss=0.031176, lr=0.001000, time_each_step=0.84s, eta=3:17:47\n",
      "2022-07-06 18:12:33 [INFO]\t[TRAIN] Epoch 139 finished, loss=0.032429535 .\n",
      "2022-07-06 18:12:43 [INFO]\t[TRAIN] Epoch=140/500, Step=9/39, loss=0.026685, lr=0.001000, time_each_step=1.09s, eta=4:16:54\n",
      "2022-07-06 18:12:51 [INFO]\t[TRAIN] Epoch=140/500, Step=19/39, loss=0.045438, lr=0.001000, time_each_step=0.83s, eta=3:16:55\n",
      "2022-07-06 18:12:59 [INFO]\t[TRAIN] Epoch=140/500, Step=29/39, loss=0.024973, lr=0.001000, time_each_step=0.84s, eta=3:18:2\n",
      "2022-07-06 18:13:08 [INFO]\t[TRAIN] Epoch=140/500, Step=39/39, loss=0.033355, lr=0.001000, time_each_step=0.83s, eta=3:16:51\n",
      "2022-07-06 18:13:08 [INFO]\t[TRAIN] Epoch 140 finished, loss=0.032107882 .\n",
      "2022-07-06 18:13:08 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 18:13:08 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 18:13:10 [INFO]\t[EVAL] Finished, Epoch=140, miou=0.873170, category_iou=[0.98720579 0.75913401], oacc=0.987702, category_acc=[0.9909899  0.91349456], kappa=0.856659, category_F1-score=[0.99356171 0.86307695] .\n",
      "2022-07-06 18:13:10 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_130, miou=0.8774011512502358\n",
      "2022-07-06 18:13:10 [INFO]\tModel saved in /home/aistudio/exp/epoch_140.\n",
      "2022-07-06 18:13:21 [INFO]\t[TRAIN] Epoch=141/500, Step=10/39, loss=0.021373, lr=0.001000, time_each_step=1.08s, eta=4:14:42\n",
      "2022-07-06 18:13:29 [INFO]\t[TRAIN] Epoch=141/500, Step=20/39, loss=0.025170, lr=0.001000, time_each_step=0.84s, eta=3:17:4\n",
      "2022-07-06 18:13:38 [INFO]\t[TRAIN] Epoch=141/500, Step=30/39, loss=0.036260, lr=0.001000, time_each_step=0.83s, eta=3:15:48\n",
      "2022-07-06 18:13:45 [INFO]\t[TRAIN] Epoch 141 finished, loss=0.03126892 .\n",
      "2022-07-06 18:13:49 [INFO]\t[TRAIN] Epoch=142/500, Step=1/39, loss=0.043133, lr=0.001000, time_each_step=1.12s, eta=4:21:30\n",
      "2022-07-06 18:13:58 [INFO]\t[TRAIN] Epoch=142/500, Step=11/39, loss=0.046548, lr=0.001000, time_each_step=0.84s, eta=3:17:55\n",
      "2022-07-06 18:14:06 [INFO]\t[TRAIN] Epoch=142/500, Step=21/39, loss=0.032955, lr=0.001000, time_each_step=0.86s, eta=3:20:34\n",
      "2022-07-06 18:14:14 [INFO]\t[TRAIN] Epoch=142/500, Step=31/39, loss=0.025687, lr=0.001000, time_each_step=0.84s, eta=3:16:9\n",
      "2022-07-06 18:14:21 [INFO]\t[TRAIN] Epoch 142 finished, loss=0.03324236 .\n",
      "2022-07-06 18:14:25 [INFO]\t[TRAIN] Epoch=143/500, Step=2/39, loss=0.028863, lr=0.001000, time_each_step=1.07s, eta=4:10:16\n",
      "2022-07-06 18:14:34 [INFO]\t[TRAIN] Epoch=143/500, Step=12/39, loss=0.034312, lr=0.001000, time_each_step=0.85s, eta=3:19:46\n",
      "2022-07-06 18:14:42 [INFO]\t[TRAIN] Epoch=143/500, Step=22/39, loss=0.035409, lr=0.001000, time_each_step=0.84s, eta=3:16:25\n",
      "2022-07-06 18:14:51 [INFO]\t[TRAIN] Epoch=143/500, Step=32/39, loss=0.023446, lr=0.001000, time_each_step=0.83s, eta=3:14:29\n",
      "2022-07-06 18:14:57 [INFO]\t[TRAIN] Epoch 143 finished, loss=0.032643188 .\n",
      "2022-07-06 18:15:02 [INFO]\t[TRAIN] Epoch=144/500, Step=3/39, loss=0.035952, lr=0.001000, time_each_step=1.08s, eta=4:12:30\n",
      "2022-07-06 18:15:10 [INFO]\t[TRAIN] Epoch=144/500, Step=13/39, loss=0.040832, lr=0.001000, time_each_step=0.88s, eta=3:25:27\n",
      "2022-07-06 18:15:19 [INFO]\t[TRAIN] Epoch=144/500, Step=23/39, loss=0.032353, lr=0.001000, time_each_step=0.84s, eta=3:16:30\n",
      "2022-07-06 18:15:27 [INFO]\t[TRAIN] Epoch=144/500, Step=33/39, loss=0.020035, lr=0.001000, time_each_step=0.84s, eta=3:14:49\n",
      "2022-07-06 18:15:32 [INFO]\t[TRAIN] Epoch 144 finished, loss=0.03070285 .\n",
      "2022-07-06 18:15:38 [INFO]\t[TRAIN] Epoch=145/500, Step=4/39, loss=0.019191, lr=0.001000, time_each_step=1.11s, eta=4:17:1\n",
      "2022-07-06 18:15:47 [INFO]\t[TRAIN] Epoch=145/500, Step=14/39, loss=0.029461, lr=0.001000, time_each_step=0.85s, eta=3:17:8\n",
      "2022-07-06 18:15:55 [INFO]\t[TRAIN] Epoch=145/500, Step=24/39, loss=0.045943, lr=0.001000, time_each_step=0.84s, eta=3:14:3\n",
      "2022-07-06 18:16:04 [INFO]\t[TRAIN] Epoch=145/500, Step=34/39, loss=0.023747, lr=0.001000, time_each_step=0.83s, eta=3:13:39\n",
      "2022-07-06 18:16:08 [INFO]\t[TRAIN] Epoch 145 finished, loss=0.030797277 .\n",
      "2022-07-06 18:16:15 [INFO]\t[TRAIN] Epoch=146/500, Step=5/39, loss=0.039119, lr=0.001000, time_each_step=1.09s, eta=4:13:19\n",
      "2022-07-06 18:16:23 [INFO]\t[TRAIN] Epoch=146/500, Step=15/39, loss=0.034816, lr=0.001000, time_each_step=0.86s, eta=3:19:4\n",
      "2022-07-06 18:16:32 [INFO]\t[TRAIN] Epoch=146/500, Step=25/39, loss=0.026394, lr=0.001000, time_each_step=0.84s, eta=3:14:8\n",
      "2022-07-06 18:16:40 [INFO]\t[TRAIN] Epoch=146/500, Step=35/39, loss=0.021253, lr=0.001000, time_each_step=0.83s, eta=3:12:58\n",
      "2022-07-06 18:16:43 [INFO]\t[TRAIN] Epoch 146 finished, loss=0.032154996 .\n",
      "2022-07-06 18:16:51 [INFO]\t[TRAIN] Epoch=147/500, Step=6/39, loss=0.020637, lr=0.001000, time_each_step=1.08s, eta=4:9:21\n",
      "2022-07-06 18:16:59 [INFO]\t[TRAIN] Epoch=147/500, Step=16/39, loss=0.029086, lr=0.001000, time_each_step=0.85s, eta=3:15:36\n",
      "2022-07-06 18:17:08 [INFO]\t[TRAIN] Epoch=147/500, Step=26/39, loss=0.028239, lr=0.001000, time_each_step=0.84s, eta=3:13:13\n",
      "2022-07-06 18:17:16 [INFO]\t[TRAIN] Epoch=147/500, Step=36/39, loss=0.010999, lr=0.001000, time_each_step=0.84s, eta=3:13:44\n",
      "2022-07-06 18:17:19 [INFO]\t[TRAIN] Epoch 147 finished, loss=0.031504713 .\n",
      "2022-07-06 18:17:27 [INFO]\t[TRAIN] Epoch=148/500, Step=7/39, loss=0.027437, lr=0.001000, time_each_step=1.08s, eta=4:8:58\n",
      "2022-07-06 18:17:35 [INFO]\t[TRAIN] Epoch=148/500, Step=17/39, loss=0.028260, lr=0.001000, time_each_step=0.84s, eta=3:13:10\n",
      "2022-07-06 18:17:44 [INFO]\t[TRAIN] Epoch=148/500, Step=27/39, loss=0.040106, lr=0.001000, time_each_step=0.84s, eta=3:12:34\n",
      "2022-07-06 18:17:52 [INFO]\t[TRAIN] Epoch=148/500, Step=37/39, loss=0.023790, lr=0.001000, time_each_step=0.83s, eta=3:11:38\n",
      "2022-07-06 18:17:54 [INFO]\t[TRAIN] Epoch 148 finished, loss=0.031670954 .\n",
      "2022-07-06 18:18:03 [INFO]\t[TRAIN] Epoch=149/500, Step=8/39, loss=0.050499, lr=0.001000, time_each_step=1.07s, eta=4:6:40\n",
      "2022-07-06 18:18:11 [INFO]\t[TRAIN] Epoch=149/500, Step=18/39, loss=0.021686, lr=0.001000, time_each_step=0.85s, eta=3:15:23\n",
      "2022-07-06 18:18:20 [INFO]\t[TRAIN] Epoch=149/500, Step=28/39, loss=0.032048, lr=0.001000, time_each_step=0.84s, eta=3:12:10\n",
      "2022-07-06 18:18:28 [INFO]\t[TRAIN] Epoch=149/500, Step=38/39, loss=0.013653, lr=0.001000, time_each_step=0.83s, eta=3:11:29\n",
      "2022-07-06 18:18:29 [INFO]\t[TRAIN] Epoch 149 finished, loss=0.03063244 .\n",
      "2022-07-06 18:18:39 [INFO]\t[TRAIN] Epoch=150/500, Step=9/39, loss=0.037992, lr=0.001000, time_each_step=1.09s, eta=4:10:16\n",
      "2022-07-06 18:18:48 [INFO]\t[TRAIN] Epoch=150/500, Step=19/39, loss=0.036244, lr=0.001000, time_each_step=0.84s, eta=3:11:55\n",
      "2022-07-06 18:18:56 [INFO]\t[TRAIN] Epoch=150/500, Step=29/39, loss=0.033322, lr=0.001000, time_each_step=0.84s, eta=3:12:4\n",
      "2022-07-06 18:19:04 [INFO]\t[TRAIN] Epoch=150/500, Step=39/39, loss=0.037340, lr=0.001000, time_each_step=0.84s, eta=3:11:8\n",
      "2022-07-06 18:19:05 [INFO]\t[TRAIN] Epoch 150 finished, loss=0.0320757 .\n",
      "2022-07-06 18:19:05 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 18:19:05 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 18:19:06 [INFO]\t[EVAL] Finished, Epoch=150, miou=0.877896, category_iou=[0.98756862 0.76822364], oacc=0.988061, category_acc=[0.99182802 0.90561212], kappa=0.862678, category_F1-score=[0.99374543 0.86892136] .\n",
      "2022-07-06 18:19:07 [INFO]\tModel saved in /home/aistudio/exp/best_model.\n",
      "2022-07-06 18:19:07 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_150, miou=0.8778961303650099\n",
      "2022-07-06 18:19:07 [INFO]\tModel saved in /home/aistudio/exp/epoch_150.\n",
      "2022-07-06 18:19:18 [INFO]\t[TRAIN] Epoch=151/500, Step=10/39, loss=0.082571, lr=0.001000, time_each_step=1.11s, eta=4:13:32\n",
      "2022-07-06 18:19:27 [INFO]\t[TRAIN] Epoch=151/500, Step=20/39, loss=0.028719, lr=0.001000, time_each_step=0.85s, eta=3:13:35\n",
      "2022-07-06 18:19:35 [INFO]\t[TRAIN] Epoch=151/500, Step=30/39, loss=0.042315, lr=0.001000, time_each_step=0.83s, eta=3:10:50\n",
      "2022-07-06 18:19:43 [INFO]\t[TRAIN] Epoch 151 finished, loss=0.032780368 .\n",
      "2022-07-06 18:19:46 [INFO]\t[TRAIN] Epoch=152/500, Step=1/39, loss=0.017549, lr=0.001000, time_each_step=1.09s, eta=4:9:0\n",
      "2022-07-06 18:19:55 [INFO]\t[TRAIN] Epoch=152/500, Step=11/39, loss=0.029585, lr=0.001000, time_each_step=0.85s, eta=3:13:35\n",
      "2022-07-06 18:20:03 [INFO]\t[TRAIN] Epoch=152/500, Step=21/39, loss=0.040884, lr=0.001000, time_each_step=0.83s, eta=3:10:2\n",
      "2022-07-06 18:20:12 [INFO]\t[TRAIN] Epoch=152/500, Step=31/39, loss=0.035009, lr=0.001000, time_each_step=0.83s, eta=3:10:8\n",
      "2022-07-06 18:20:18 [INFO]\t[TRAIN] Epoch 152 finished, loss=0.03218064 .\n",
      "2022-07-06 18:20:23 [INFO]\t[TRAIN] Epoch=153/500, Step=2/39, loss=0.053440, lr=0.001000, time_each_step=1.1s, eta=4:10:41\n",
      "2022-07-06 18:20:31 [INFO]\t[TRAIN] Epoch=153/500, Step=12/39, loss=0.023057, lr=0.001000, time_each_step=0.88s, eta=3:19:57\n",
      "2022-07-06 18:20:40 [INFO]\t[TRAIN] Epoch=153/500, Step=22/39, loss=0.029462, lr=0.001000, time_each_step=0.85s, eta=3:14:23\n",
      "2022-07-06 18:20:49 [INFO]\t[TRAIN] Epoch=153/500, Step=32/39, loss=0.042655, lr=0.001000, time_each_step=0.86s, eta=3:16:6\n",
      "2022-07-06 18:20:55 [INFO]\t[TRAIN] Epoch 153 finished, loss=0.032936275 .\n",
      "2022-07-06 18:21:00 [INFO]\t[TRAIN] Epoch=154/500, Step=3/39, loss=0.024730, lr=0.001000, time_each_step=1.1s, eta=4:8:25\n",
      "2022-07-06 18:21:08 [INFO]\t[TRAIN] Epoch=154/500, Step=13/39, loss=0.044554, lr=0.001000, time_each_step=0.84s, eta=3:11:25\n",
      "2022-07-06 18:21:16 [INFO]\t[TRAIN] Epoch=154/500, Step=23/39, loss=0.039738, lr=0.001000, time_each_step=0.83s, eta=3:9:1\n",
      "2022-07-06 18:21:25 [INFO]\t[TRAIN] Epoch=154/500, Step=33/39, loss=0.027738, lr=0.001000, time_each_step=0.84s, eta=3:9:32\n",
      "2022-07-06 18:21:30 [INFO]\t[TRAIN] Epoch 154 finished, loss=0.03233477 .\n",
      "2022-07-06 18:21:36 [INFO]\t[TRAIN] Epoch=155/500, Step=4/39, loss=0.036077, lr=0.001000, time_each_step=1.12s, eta=4:13:58\n",
      "2022-07-06 18:21:45 [INFO]\t[TRAIN] Epoch=155/500, Step=14/39, loss=0.027274, lr=0.001000, time_each_step=0.85s, eta=3:11:51\n",
      "2022-07-06 18:21:54 [INFO]\t[TRAIN] Epoch=155/500, Step=24/39, loss=0.034173, lr=0.001000, time_each_step=0.9s, eta=3:23:17\n",
      "2022-07-06 18:22:02 [INFO]\t[TRAIN] Epoch=155/500, Step=34/39, loss=0.040924, lr=0.001000, time_each_step=0.84s, eta=3:10:29\n",
      "2022-07-06 18:22:07 [INFO]\t[TRAIN] Epoch 155 finished, loss=0.031441405 .\n",
      "2022-07-06 18:22:14 [INFO]\t[TRAIN] Epoch=156/500, Step=5/39, loss=0.027553, lr=0.001000, time_each_step=1.12s, eta=4:12:56\n",
      "2022-07-06 18:22:22 [INFO]\t[TRAIN] Epoch=156/500, Step=15/39, loss=0.029317, lr=0.001000, time_each_step=0.84s, eta=3:9:23\n",
      "2022-07-06 18:22:30 [INFO]\t[TRAIN] Epoch=156/500, Step=25/39, loss=0.062642, lr=0.001000, time_each_step=0.84s, eta=3:8:57\n",
      "2022-07-06 18:22:39 [INFO]\t[TRAIN] Epoch=156/500, Step=35/39, loss=0.035947, lr=0.001000, time_each_step=0.83s, eta=3:8:2\n",
      "2022-07-06 18:22:42 [INFO]\t[TRAIN] Epoch 156 finished, loss=0.0329065 .\n",
      "2022-07-06 18:22:50 [INFO]\t[TRAIN] Epoch=157/500, Step=6/39, loss=0.043643, lr=0.001000, time_each_step=1.08s, eta=4:2:44\n",
      "2022-07-06 18:22:58 [INFO]\t[TRAIN] Epoch=157/500, Step=16/39, loss=0.038331, lr=0.001000, time_each_step=0.84s, eta=3:8:59\n",
      "2022-07-06 18:23:06 [INFO]\t[TRAIN] Epoch=157/500, Step=26/39, loss=0.034338, lr=0.001000, time_each_step=0.83s, eta=3:7:41\n",
      "2022-07-06 18:23:15 [INFO]\t[TRAIN] Epoch=157/500, Step=36/39, loss=0.030150, lr=0.001000, time_each_step=0.83s, eta=3:7:25\n",
      "2022-07-06 18:23:17 [INFO]\t[TRAIN] Epoch 157 finished, loss=0.031571954 .\n",
      "2022-07-06 18:23:26 [INFO]\t[TRAIN] Epoch=158/500, Step=7/39, loss=0.028747, lr=0.001000, time_each_step=1.1s, eta=4:7:9\n",
      "2022-07-06 18:23:34 [INFO]\t[TRAIN] Epoch=158/500, Step=17/39, loss=0.037915, lr=0.001000, time_each_step=0.84s, eta=3:8:28\n",
      "2022-07-06 18:23:43 [INFO]\t[TRAIN] Epoch=158/500, Step=27/39, loss=0.022234, lr=0.001000, time_each_step=0.85s, eta=3:10:2\n",
      "2022-07-06 18:23:51 [INFO]\t[TRAIN] Epoch=158/500, Step=37/39, loss=0.021812, lr=0.001000, time_each_step=0.83s, eta=3:6:30\n",
      "2022-07-06 18:23:53 [INFO]\t[TRAIN] Epoch 158 finished, loss=0.030733647 .\n",
      "2022-07-06 18:24:02 [INFO]\t[TRAIN] Epoch=159/500, Step=8/39, loss=0.020654, lr=0.001000, time_each_step=1.11s, eta=4:7:44\n",
      "2022-07-06 18:24:11 [INFO]\t[TRAIN] Epoch=159/500, Step=18/39, loss=0.016273, lr=0.001000, time_each_step=0.84s, eta=3:8:35\n",
      "2022-07-06 18:24:19 [INFO]\t[TRAIN] Epoch=159/500, Step=28/39, loss=0.034234, lr=0.001000, time_each_step=0.84s, eta=3:6:56\n",
      "2022-07-06 18:24:27 [INFO]\t[TRAIN] Epoch=159/500, Step=38/39, loss=0.028556, lr=0.001000, time_each_step=0.83s, eta=3:5:43\n",
      "2022-07-06 18:24:28 [INFO]\t[TRAIN] Epoch 159 finished, loss=0.030518357 .\n",
      "2022-07-06 18:24:39 [INFO]\t[TRAIN] Epoch=160/500, Step=9/39, loss=0.039919, lr=0.001000, time_each_step=1.1s, eta=4:5:3\n",
      "2022-07-06 18:24:47 [INFO]\t[TRAIN] Epoch=160/500, Step=19/39, loss=0.028923, lr=0.001000, time_each_step=0.85s, eta=3:9:30\n",
      "2022-07-06 18:24:55 [INFO]\t[TRAIN] Epoch=160/500, Step=29/39, loss=0.025691, lr=0.001000, time_each_step=0.83s, eta=3:5:51\n",
      "2022-07-06 18:25:04 [INFO]\t[TRAIN] Epoch=160/500, Step=39/39, loss=0.029333, lr=0.001000, time_each_step=0.83s, eta=3:4:59\n",
      "2022-07-06 18:25:04 [INFO]\t[TRAIN] Epoch 160 finished, loss=0.031266846 .\n",
      "2022-07-06 18:25:04 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 18:25:04 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 18:25:06 [INFO]\t[EVAL] Finished, Epoch=160, miou=0.876440, category_iou=[0.98750442 0.76537483], oacc=0.987994, category_acc=[0.99140842 0.91190505], kappa=0.860825, category_F1-score=[0.99371293 0.86709612] .\n",
      "2022-07-06 18:25:06 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_150, miou=0.8778961303650099\n",
      "2022-07-06 18:25:06 [INFO]\tModel saved in /home/aistudio/exp/epoch_160.\n",
      "2022-07-06 18:25:17 [INFO]\t[TRAIN] Epoch=161/500, Step=10/39, loss=0.028111, lr=0.001000, time_each_step=1.1s, eta=4:4:2\n",
      "2022-07-06 18:25:26 [INFO]\t[TRAIN] Epoch=161/500, Step=20/39, loss=0.038220, lr=0.001000, time_each_step=0.84s, eta=3:5:27\n",
      "2022-07-06 18:25:34 [INFO]\t[TRAIN] Epoch=161/500, Step=30/39, loss=0.022136, lr=0.001000, time_each_step=0.83s, eta=3:5:1\n",
      "2022-07-06 18:25:41 [INFO]\t[TRAIN] Epoch 161 finished, loss=0.031237923 .\n",
      "2022-07-06 18:25:45 [INFO]\t[TRAIN] Epoch=162/500, Step=1/39, loss=0.018468, lr=0.001000, time_each_step=1.12s, eta=4:7:36\n",
      "2022-07-06 18:25:54 [INFO]\t[TRAIN] Epoch=162/500, Step=11/39, loss=0.023172, lr=0.001000, time_each_step=0.88s, eta=3:13:44\n",
      "2022-07-06 18:26:02 [INFO]\t[TRAIN] Epoch=162/500, Step=21/39, loss=0.025716, lr=0.001000, time_each_step=0.84s, eta=3:5:22\n",
      "2022-07-06 18:26:11 [INFO]\t[TRAIN] Epoch=162/500, Step=31/39, loss=0.026696, lr=0.001000, time_each_step=0.84s, eta=3:4:41\n",
      "2022-07-06 18:26:17 [INFO]\t[TRAIN] Epoch 162 finished, loss=0.029873854 .\n",
      "2022-07-06 18:26:22 [INFO]\t[TRAIN] Epoch=163/500, Step=2/39, loss=0.029169, lr=0.001000, time_each_step=1.09s, eta=3:59:25\n",
      "2022-07-06 18:26:30 [INFO]\t[TRAIN] Epoch=163/500, Step=12/39, loss=0.025874, lr=0.001000, time_each_step=0.84s, eta=3:6:23\n",
      "2022-07-06 18:26:38 [INFO]\t[TRAIN] Epoch=163/500, Step=22/39, loss=0.034175, lr=0.001000, time_each_step=0.83s, eta=3:3:47\n",
      "2022-07-06 18:26:47 [INFO]\t[TRAIN] Epoch=163/500, Step=32/39, loss=0.023755, lr=0.001000, time_each_step=0.84s, eta=3:4:18\n",
      "2022-07-06 18:26:53 [INFO]\t[TRAIN] Epoch 163 finished, loss=0.030434495 .\n",
      "2022-07-06 18:26:58 [INFO]\t[TRAIN] Epoch=164/500, Step=3/39, loss=0.041739, lr=0.001000, time_each_step=1.12s, eta=4:6:57\n",
      "2022-07-06 18:27:07 [INFO]\t[TRAIN] Epoch=164/500, Step=13/39, loss=0.015133, lr=0.001000, time_each_step=0.85s, eta=3:8:0\n",
      "2022-07-06 18:27:15 [INFO]\t[TRAIN] Epoch=164/500, Step=23/39, loss=0.019350, lr=0.001000, time_each_step=0.83s, eta=3:3:13\n",
      "2022-07-06 18:27:23 [INFO]\t[TRAIN] Epoch=164/500, Step=33/39, loss=0.023726, lr=0.001000, time_each_step=0.83s, eta=3:3:15\n",
      "2022-07-06 18:27:28 [INFO]\t[TRAIN] Epoch 164 finished, loss=0.030141171 .\n",
      "2022-07-06 18:27:34 [INFO]\t[TRAIN] Epoch=165/500, Step=4/39, loss=0.023418, lr=0.001000, time_each_step=1.1s, eta=4:1:30\n",
      "2022-07-06 18:27:43 [INFO]\t[TRAIN] Epoch=165/500, Step=14/39, loss=0.039425, lr=0.001000, time_each_step=0.84s, eta=3:4:46\n",
      "2022-07-06 18:27:51 [INFO]\t[TRAIN] Epoch=165/500, Step=24/39, loss=0.024848, lr=0.001000, time_each_step=0.84s, eta=3:3:46\n",
      "2022-07-06 18:28:00 [INFO]\t[TRAIN] Epoch=165/500, Step=34/39, loss=0.022960, lr=0.001000, time_each_step=0.83s, eta=3:2:26\n",
      "2022-07-06 18:28:04 [INFO]\t[TRAIN] Epoch 165 finished, loss=0.030954933 .\n",
      "2022-07-06 18:28:11 [INFO]\t[TRAIN] Epoch=166/500, Step=5/39, loss=0.028278, lr=0.001000, time_each_step=1.08s, eta=3:56:48\n",
      "2022-07-06 18:28:19 [INFO]\t[TRAIN] Epoch=166/500, Step=15/39, loss=0.052351, lr=0.001000, time_each_step=0.84s, eta=3:2:48\n",
      "2022-07-06 18:28:27 [INFO]\t[TRAIN] Epoch=166/500, Step=25/39, loss=0.034809, lr=0.001000, time_each_step=0.84s, eta=3:2:44\n",
      "2022-07-06 18:28:36 [INFO]\t[TRAIN] Epoch=166/500, Step=35/39, loss=0.045191, lr=0.001000, time_each_step=0.84s, eta=3:4:27\n",
      "2022-07-06 18:28:39 [INFO]\t[TRAIN] Epoch 166 finished, loss=0.031198474 .\n",
      "2022-07-06 18:28:47 [INFO]\t[TRAIN] Epoch=167/500, Step=6/39, loss=0.025773, lr=0.001000, time_each_step=1.08s, eta=3:56:24\n",
      "2022-07-06 18:28:55 [INFO]\t[TRAIN] Epoch=167/500, Step=16/39, loss=0.042913, lr=0.001000, time_each_step=0.84s, eta=3:4:14\n",
      "2022-07-06 18:29:04 [INFO]\t[TRAIN] Epoch=167/500, Step=26/39, loss=0.027657, lr=0.001000, time_each_step=0.84s, eta=3:2:8\n",
      "2022-07-06 18:29:12 [INFO]\t[TRAIN] Epoch=167/500, Step=36/39, loss=0.033984, lr=0.001000, time_each_step=0.84s, eta=3:3:52\n",
      "2022-07-06 18:29:15 [INFO]\t[TRAIN] Epoch 167 finished, loss=0.029200925 .\n",
      "2022-07-06 18:29:23 [INFO]\t[TRAIN] Epoch=168/500, Step=7/39, loss=0.021397, lr=0.001000, time_each_step=1.08s, eta=3:54:3\n",
      "2022-07-06 18:29:31 [INFO]\t[TRAIN] Epoch=168/500, Step=17/39, loss=0.025333, lr=0.001000, time_each_step=0.84s, eta=3:2:5\n",
      "2022-07-06 18:29:40 [INFO]\t[TRAIN] Epoch=168/500, Step=27/39, loss=0.030097, lr=0.001000, time_each_step=0.85s, eta=3:3:55\n",
      "2022-07-06 18:29:48 [INFO]\t[TRAIN] Epoch=168/500, Step=37/39, loss=0.053367, lr=0.001000, time_each_step=0.84s, eta=3:1:31\n",
      "2022-07-06 18:29:50 [INFO]\t[TRAIN] Epoch 168 finished, loss=0.02933443 .\n",
      "2022-07-06 18:29:59 [INFO]\t[TRAIN] Epoch=169/500, Step=8/39, loss=0.029748, lr=0.001000, time_each_step=1.1s, eta=3:59:20\n",
      "2022-07-06 18:30:08 [INFO]\t[TRAIN] Epoch=169/500, Step=18/39, loss=0.031636, lr=0.001000, time_each_step=0.84s, eta=3:3:5\n",
      "2022-07-06 18:30:16 [INFO]\t[TRAIN] Epoch=169/500, Step=28/39, loss=0.032615, lr=0.001000, time_each_step=0.84s, eta=3:2:6\n",
      "2022-07-06 18:30:24 [INFO]\t[TRAIN] Epoch=169/500, Step=38/39, loss=0.038673, lr=0.001000, time_each_step=0.83s, eta=3:0:6\n",
      "2022-07-06 18:30:25 [INFO]\t[TRAIN] Epoch 169 finished, loss=0.0297375 .\n",
      "2022-07-06 18:30:35 [INFO]\t[TRAIN] Epoch=170/500, Step=9/39, loss=0.036594, lr=0.001000, time_each_step=1.08s, eta=3:54:1\n",
      "2022-07-06 18:30:44 [INFO]\t[TRAIN] Epoch=170/500, Step=19/39, loss=0.033751, lr=0.001000, time_each_step=0.84s, eta=3:0:36\n",
      "2022-07-06 18:30:52 [INFO]\t[TRAIN] Epoch=170/500, Step=29/39, loss=0.042462, lr=0.001000, time_each_step=0.83s, eta=3:0:9\n",
      "2022-07-06 18:31:00 [INFO]\t[TRAIN] Epoch=170/500, Step=39/39, loss=0.030548, lr=0.001000, time_each_step=0.83s, eta=2:59:38\n",
      "2022-07-06 18:31:01 [INFO]\t[TRAIN] Epoch 170 finished, loss=0.030960893 .\n",
      "2022-07-06 18:31:01 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 18:31:01 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 18:31:03 [INFO]\t[EVAL] Finished, Epoch=170, miou=0.881677, category_iou=[0.98797768 0.77537598], oacc=0.988457, category_acc=[0.992112   0.90874805], kappa=0.867440, category_F1-score=[0.99395249 0.87347806] .\n",
      "2022-07-06 18:31:03 [INFO]\tModel saved in /home/aistudio/exp/best_model.\n",
      "2022-07-06 18:31:03 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_170, miou=0.8816768330651846\n",
      "2022-07-06 18:31:04 [INFO]\tModel saved in /home/aistudio/exp/epoch_170.\n",
      "2022-07-06 18:31:15 [INFO]\t[TRAIN] Epoch=171/500, Step=10/39, loss=0.025758, lr=0.001000, time_each_step=1.11s, eta=3:59:29\n",
      "2022-07-06 18:31:23 [INFO]\t[TRAIN] Epoch=171/500, Step=20/39, loss=0.044515, lr=0.001000, time_each_step=0.84s, eta=3:2:0\n",
      "2022-07-06 18:31:31 [INFO]\t[TRAIN] Epoch=171/500, Step=30/39, loss=0.018165, lr=0.001000, time_each_step=0.84s, eta=3:0:11\n",
      "2022-07-06 18:31:39 [INFO]\t[TRAIN] Epoch 171 finished, loss=0.030861381 .\n",
      "2022-07-06 18:31:42 [INFO]\t[TRAIN] Epoch=172/500, Step=1/39, loss=0.022402, lr=0.001000, time_each_step=1.07s, eta=3:50:50\n",
      "2022-07-06 18:31:51 [INFO]\t[TRAIN] Epoch=172/500, Step=11/39, loss=0.015184, lr=0.001000, time_each_step=0.86s, eta=3:4:13\n",
      "2022-07-06 18:31:59 [INFO]\t[TRAIN] Epoch=172/500, Step=21/39, loss=0.026017, lr=0.001000, time_each_step=0.83s, eta=2:59:29\n",
      "2022-07-06 18:32:08 [INFO]\t[TRAIN] Epoch=172/500, Step=31/39, loss=0.016493, lr=0.001000, time_each_step=0.84s, eta=3:1:19\n",
      "2022-07-06 18:32:15 [INFO]\t[TRAIN] Epoch 172 finished, loss=0.031386502 .\n",
      "2022-07-06 18:32:19 [INFO]\t[TRAIN] Epoch=173/500, Step=2/39, loss=0.028781, lr=0.001000, time_each_step=1.13s, eta=4:1:31\n",
      "2022-07-06 18:32:28 [INFO]\t[TRAIN] Epoch=173/500, Step=12/39, loss=0.040603, lr=0.001000, time_each_step=0.85s, eta=3:1:57\n",
      "2022-07-06 18:32:36 [INFO]\t[TRAIN] Epoch=173/500, Step=22/39, loss=0.027263, lr=0.001000, time_each_step=0.84s, eta=2:59:12\n",
      "2022-07-06 18:32:44 [INFO]\t[TRAIN] Epoch=173/500, Step=32/39, loss=0.042195, lr=0.001000, time_each_step=0.83s, eta=2:58:40\n",
      "2022-07-06 18:32:50 [INFO]\t[TRAIN] Epoch 173 finished, loss=0.030858865 .\n",
      "2022-07-06 18:32:55 [INFO]\t[TRAIN] Epoch=174/500, Step=3/39, loss=0.034676, lr=0.001000, time_each_step=1.08s, eta=3:51:0\n",
      "2022-07-06 18:33:04 [INFO]\t[TRAIN] Epoch=174/500, Step=13/39, loss=0.024160, lr=0.001000, time_each_step=0.85s, eta=3:1:2\n",
      "2022-07-06 18:33:12 [INFO]\t[TRAIN] Epoch=174/500, Step=23/39, loss=0.025985, lr=0.001000, time_each_step=0.86s, eta=3:4:38\n",
      "2022-07-06 18:33:21 [INFO]\t[TRAIN] Epoch=174/500, Step=33/39, loss=0.024223, lr=0.001000, time_each_step=0.84s, eta=2:58:39\n",
      "2022-07-06 18:33:26 [INFO]\t[TRAIN] Epoch 174 finished, loss=0.029522562 .\n",
      "2022-07-06 18:33:32 [INFO]\t[TRAIN] Epoch=175/500, Step=4/39, loss=0.038759, lr=0.001000, time_each_step=1.12s, eta=3:57:56\n",
      "2022-07-06 18:33:41 [INFO]\t[TRAIN] Epoch=175/500, Step=14/39, loss=0.014999, lr=0.001000, time_each_step=0.84s, eta=2:59:12\n",
      "2022-07-06 18:33:49 [INFO]\t[TRAIN] Epoch=175/500, Step=24/39, loss=0.037185, lr=0.001000, time_each_step=0.84s, eta=2:58:8\n",
      "2022-07-06 18:33:57 [INFO]\t[TRAIN] Epoch=175/500, Step=34/39, loss=0.041562, lr=0.001000, time_each_step=0.83s, eta=2:57:42\n",
      "2022-07-06 18:34:02 [INFO]\t[TRAIN] Epoch 175 finished, loss=0.028626548 .\n",
      "2022-07-06 18:34:08 [INFO]\t[TRAIN] Epoch=176/500, Step=5/39, loss=0.038103, lr=0.001000, time_each_step=1.08s, eta=3:48:58\n",
      "2022-07-06 18:34:17 [INFO]\t[TRAIN] Epoch=176/500, Step=15/39, loss=0.031169, lr=0.001000, time_each_step=0.84s, eta=2:58:53\n",
      "2022-07-06 18:34:25 [INFO]\t[TRAIN] Epoch=176/500, Step=25/39, loss=0.015550, lr=0.001000, time_each_step=0.84s, eta=2:58:18\n",
      "2022-07-06 18:34:33 [INFO]\t[TRAIN] Epoch=176/500, Step=35/39, loss=0.024517, lr=0.001000, time_each_step=0.83s, eta=2:56:46\n",
      "2022-07-06 18:34:37 [INFO]\t[TRAIN] Epoch 176 finished, loss=0.030067906 .\n",
      "2022-07-06 18:34:44 [INFO]\t[TRAIN] Epoch=177/500, Step=6/39, loss=0.040310, lr=0.001000, time_each_step=1.08s, eta=3:48:45\n",
      "2022-07-06 18:34:53 [INFO]\t[TRAIN] Epoch=177/500, Step=16/39, loss=0.082851, lr=0.001000, time_each_step=0.84s, eta=2:58:42\n",
      "2022-07-06 18:35:01 [INFO]\t[TRAIN] Epoch=177/500, Step=26/39, loss=0.019326, lr=0.001000, time_each_step=0.84s, eta=2:57:12\n",
      "2022-07-06 18:35:09 [INFO]\t[TRAIN] Epoch=177/500, Step=36/39, loss=0.025240, lr=0.001000, time_each_step=0.83s, eta=2:56:6\n",
      "2022-07-06 18:35:12 [INFO]\t[TRAIN] Epoch 177 finished, loss=0.029940272 .\n",
      "2022-07-06 18:35:20 [INFO]\t[TRAIN] Epoch=178/500, Step=7/39, loss=0.043084, lr=0.001000, time_each_step=1.09s, eta=3:51:2\n",
      "2022-07-06 18:35:29 [INFO]\t[TRAIN] Epoch=178/500, Step=17/39, loss=0.033504, lr=0.001000, time_each_step=0.85s, eta=3:0:34\n",
      "2022-07-06 18:35:37 [INFO]\t[TRAIN] Epoch=178/500, Step=27/39, loss=0.031020, lr=0.001000, time_each_step=0.83s, eta=2:55:59\n",
      "2022-07-06 18:35:46 [INFO]\t[TRAIN] Epoch=178/500, Step=37/39, loss=0.031847, lr=0.001000, time_each_step=0.83s, eta=2:55:31\n",
      "2022-07-06 18:35:47 [INFO]\t[TRAIN] Epoch 178 finished, loss=0.029270044 .\n",
      "2022-07-06 18:35:57 [INFO]\t[TRAIN] Epoch=179/500, Step=8/39, loss=0.041440, lr=0.001000, time_each_step=1.09s, eta=3:49:45\n",
      "2022-07-06 18:36:05 [INFO]\t[TRAIN] Epoch=179/500, Step=18/39, loss=0.032740, lr=0.001000, time_each_step=0.84s, eta=2:57:14\n",
      "2022-07-06 18:36:13 [INFO]\t[TRAIN] Epoch=179/500, Step=28/39, loss=0.027142, lr=0.001000, time_each_step=0.83s, eta=2:55:19\n",
      "2022-07-06 18:36:22 [INFO]\t[TRAIN] Epoch=179/500, Step=38/39, loss=0.020543, lr=0.001000, time_each_step=0.83s, eta=2:55:3\n",
      "2022-07-06 18:36:23 [INFO]\t[TRAIN] Epoch 179 finished, loss=0.029018426 .\n",
      "2022-07-06 18:36:33 [INFO]\t[TRAIN] Epoch=180/500, Step=9/39, loss=0.043604, lr=0.001000, time_each_step=1.11s, eta=3:52:27\n",
      "2022-07-06 18:36:41 [INFO]\t[TRAIN] Epoch=180/500, Step=19/39, loss=0.032279, lr=0.001000, time_each_step=0.84s, eta=2:57:3\n",
      "2022-07-06 18:36:50 [INFO]\t[TRAIN] Epoch=180/500, Step=29/39, loss=0.025078, lr=0.001000, time_each_step=0.84s, eta=2:55:31\n",
      "2022-07-06 18:36:58 [INFO]\t[TRAIN] Epoch=180/500, Step=39/39, loss=0.045341, lr=0.001000, time_each_step=0.83s, eta=2:54:40\n",
      "2022-07-06 18:36:58 [INFO]\t[TRAIN] Epoch 180 finished, loss=0.030663138 .\n",
      "2022-07-06 18:36:58 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 18:36:58 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 18:37:00 [INFO]\t[EVAL] Finished, Epoch=180, miou=0.886239, category_iou=[0.98812541 0.78435202], oacc=0.988617, category_acc=[0.99371989 0.88468169], kappa=0.873172, category_F1-score=[0.99402724 0.87914494] .\n",
      "2022-07-06 18:37:01 [INFO]\tModel saved in /home/aistudio/exp/best_model.\n",
      "2022-07-06 18:37:01 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_180, miou=0.8862387140739285\n",
      "2022-07-06 18:37:01 [INFO]\tModel saved in /home/aistudio/exp/epoch_180.\n",
      "2022-07-06 18:37:12 [INFO]\t[TRAIN] Epoch=181/500, Step=10/39, loss=0.037142, lr=0.000500, time_each_step=1.1s, eta=3:50:33\n",
      "2022-07-06 18:37:20 [INFO]\t[TRAIN] Epoch=181/500, Step=20/39, loss=0.035286, lr=0.000500, time_each_step=0.84s, eta=2:54:56\n",
      "2022-07-06 18:37:29 [INFO]\t[TRAIN] Epoch=181/500, Step=30/39, loss=0.041791, lr=0.000500, time_each_step=0.86s, eta=2:59:44\n",
      "2022-07-06 18:37:37 [INFO]\t[TRAIN] Epoch 181 finished, loss=0.029831868 .\n",
      "2022-07-06 18:37:40 [INFO]\t[TRAIN] Epoch=182/500, Step=1/39, loss=0.023570, lr=0.000500, time_each_step=1.07s, eta=3:43:41\n",
      "2022-07-06 18:37:49 [INFO]\t[TRAIN] Epoch=182/500, Step=11/39, loss=0.027860, lr=0.000500, time_each_step=0.96s, eta=3:20:2\n",
      "2022-07-06 18:37:58 [INFO]\t[TRAIN] Epoch=182/500, Step=21/39, loss=0.019448, lr=0.000500, time_each_step=0.85s, eta=2:56:24\n",
      "2022-07-06 18:38:06 [INFO]\t[TRAIN] Epoch=182/500, Step=31/39, loss=0.034478, lr=0.000500, time_each_step=0.84s, eta=2:54:26\n",
      "2022-07-06 18:38:13 [INFO]\t[TRAIN] Epoch 182 finished, loss=0.027702227 .\n",
      "2022-07-06 18:38:17 [INFO]\t[TRAIN] Epoch=183/500, Step=2/39, loss=0.046536, lr=0.000500, time_each_step=1.08s, eta=3:45:17\n",
      "2022-07-06 18:38:26 [INFO]\t[TRAIN] Epoch=183/500, Step=12/39, loss=0.022491, lr=0.000500, time_each_step=0.85s, eta=2:56:42\n",
      "2022-07-06 18:38:34 [INFO]\t[TRAIN] Epoch=183/500, Step=22/39, loss=0.028344, lr=0.000500, time_each_step=0.86s, eta=2:57:59\n",
      "2022-07-06 18:38:43 [INFO]\t[TRAIN] Epoch=183/500, Step=32/39, loss=0.015969, lr=0.000500, time_each_step=0.84s, eta=2:55:15\n",
      "2022-07-06 18:38:49 [INFO]\t[TRAIN] Epoch 183 finished, loss=0.02878405 .\n",
      "2022-07-06 18:38:54 [INFO]\t[TRAIN] Epoch=184/500, Step=3/39, loss=0.044578, lr=0.000500, time_each_step=1.1s, eta=3:47:23\n",
      "2022-07-06 18:39:02 [INFO]\t[TRAIN] Epoch=184/500, Step=13/39, loss=0.016948, lr=0.000500, time_each_step=0.85s, eta=2:56:0\n",
      "2022-07-06 18:39:11 [INFO]\t[TRAIN] Epoch=184/500, Step=23/39, loss=0.044721, lr=0.000500, time_each_step=0.84s, eta=2:54:0\n",
      "2022-07-06 18:39:19 [INFO]\t[TRAIN] Epoch=184/500, Step=33/39, loss=0.029968, lr=0.000500, time_each_step=0.84s, eta=2:52:56\n",
      "2022-07-06 18:39:24 [INFO]\t[TRAIN] Epoch 184 finished, loss=0.02931656 .\n",
      "2022-07-06 18:39:31 [INFO]\t[TRAIN] Epoch=185/500, Step=4/39, loss=0.017017, lr=0.000500, time_each_step=1.22s, eta=4:11:25\n",
      "2022-07-06 18:39:40 [INFO]\t[TRAIN] Epoch=185/500, Step=14/39, loss=0.032357, lr=0.000500, time_each_step=0.85s, eta=2:56:25\n",
      "2022-07-06 18:39:48 [INFO]\t[TRAIN] Epoch=185/500, Step=24/39, loss=0.042896, lr=0.000500, time_each_step=0.85s, eta=2:56:1\n",
      "2022-07-06 18:39:57 [INFO]\t[TRAIN] Epoch=185/500, Step=34/39, loss=0.042698, lr=0.000500, time_each_step=0.84s, eta=2:52:21\n",
      "2022-07-06 18:40:01 [INFO]\t[TRAIN] Epoch 185 finished, loss=0.03084427 .\n",
      "2022-07-06 18:40:08 [INFO]\t[TRAIN] Epoch=186/500, Step=5/39, loss=0.041015, lr=0.000500, time_each_step=1.11s, eta=3:48:12\n",
      "2022-07-06 18:40:16 [INFO]\t[TRAIN] Epoch=186/500, Step=15/39, loss=0.025905, lr=0.000500, time_each_step=0.84s, eta=2:52:31\n",
      "2022-07-06 18:40:25 [INFO]\t[TRAIN] Epoch=186/500, Step=25/39, loss=0.027485, lr=0.000500, time_each_step=0.84s, eta=2:52:17\n",
      "2022-07-06 18:40:33 [INFO]\t[TRAIN] Epoch=186/500, Step=35/39, loss=0.020209, lr=0.000500, time_each_step=0.83s, eta=2:51:16\n",
      "2022-07-06 18:40:37 [INFO]\t[TRAIN] Epoch 186 finished, loss=0.029400906 .\n",
      "2022-07-06 18:40:44 [INFO]\t[TRAIN] Epoch=187/500, Step=6/39, loss=0.029520, lr=0.000500, time_each_step=1.11s, eta=3:47:48\n",
      "2022-07-06 18:40:53 [INFO]\t[TRAIN] Epoch=187/500, Step=16/39, loss=0.017483, lr=0.000500, time_each_step=0.85s, eta=2:55:21\n",
      "2022-07-06 18:41:01 [INFO]\t[TRAIN] Epoch=187/500, Step=26/39, loss=0.035809, lr=0.000500, time_each_step=0.83s, eta=2:51:5\n",
      "2022-07-06 18:41:10 [INFO]\t[TRAIN] Epoch=187/500, Step=36/39, loss=0.030846, lr=0.000500, time_each_step=0.84s, eta=2:52:3\n",
      "2022-07-06 18:41:12 [INFO]\t[TRAIN] Epoch 187 finished, loss=0.029406099 .\n",
      "2022-07-06 18:41:21 [INFO]\t[TRAIN] Epoch=188/500, Step=7/39, loss=0.019972, lr=0.000500, time_each_step=1.08s, eta=3:40:55\n",
      "2022-07-06 18:41:29 [INFO]\t[TRAIN] Epoch=188/500, Step=17/39, loss=0.032482, lr=0.000500, time_each_step=0.84s, eta=2:51:31\n",
      "2022-07-06 18:41:37 [INFO]\t[TRAIN] Epoch=188/500, Step=27/39, loss=0.028001, lr=0.000500, time_each_step=0.84s, eta=2:51:5\n",
      "2022-07-06 18:41:46 [INFO]\t[TRAIN] Epoch=188/500, Step=37/39, loss=0.045872, lr=0.000500, time_each_step=0.83s, eta=2:50:35\n",
      "2022-07-06 18:41:47 [INFO]\t[TRAIN] Epoch 188 finished, loss=0.029601332 .\n",
      "2022-07-06 18:41:57 [INFO]\t[TRAIN] Epoch=189/500, Step=8/39, loss=0.035489, lr=0.000500, time_each_step=1.16s, eta=3:55:59\n",
      "2022-07-06 18:42:06 [INFO]\t[TRAIN] Epoch=189/500, Step=18/39, loss=0.018862, lr=0.000500, time_each_step=0.83s, eta=2:50:17\n",
      "2022-07-06 18:42:14 [INFO]\t[TRAIN] Epoch=189/500, Step=28/39, loss=0.018837, lr=0.000500, time_each_step=0.84s, eta=2:51:49\n",
      "2022-07-06 18:42:22 [INFO]\t[TRAIN] Epoch=189/500, Step=38/39, loss=0.026771, lr=0.000500, time_each_step=0.83s, eta=2:49:33\n",
      "2022-07-06 18:42:23 [INFO]\t[TRAIN] Epoch 189 finished, loss=0.029468155 .\n",
      "2022-07-06 18:42:33 [INFO]\t[TRAIN] Epoch=190/500, Step=9/39, loss=0.012964, lr=0.000500, time_each_step=1.08s, eta=3:40:23\n",
      "2022-07-06 18:42:42 [INFO]\t[TRAIN] Epoch=190/500, Step=19/39, loss=0.022688, lr=0.000500, time_each_step=0.87s, eta=2:57:37\n",
      "2022-07-06 18:42:51 [INFO]\t[TRAIN] Epoch=190/500, Step=29/39, loss=0.019170, lr=0.000500, time_each_step=0.84s, eta=2:50:36\n",
      "2022-07-06 18:42:59 [INFO]\t[TRAIN] Epoch=190/500, Step=39/39, loss=0.026092, lr=0.000500, time_each_step=0.84s, eta=2:49:36\n",
      "2022-07-06 18:42:59 [INFO]\t[TRAIN] Epoch 190 finished, loss=0.02903202 .\n",
      "2022-07-06 18:42:59 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 18:42:59 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 18:43:01 [INFO]\t[EVAL] Finished, Epoch=190, miou=0.884436, category_iou=[0.98815706 0.78071448], oacc=0.988636, category_acc=[0.99274421 0.90123533], kappa=0.870903, category_F1-score=[0.99404326 0.87685531] .\n",
      "2022-07-06 18:43:01 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_180, miou=0.8862387140739285\n",
      "2022-07-06 18:43:01 [INFO]\tModel saved in /home/aistudio/exp/epoch_190.\n",
      "2022-07-06 18:43:13 [INFO]\t[TRAIN] Epoch=191/500, Step=10/39, loss=0.033582, lr=0.000500, time_each_step=1.17s, eta=3:55:36\n",
      "2022-07-06 18:43:21 [INFO]\t[TRAIN] Epoch=191/500, Step=20/39, loss=0.053941, lr=0.000500, time_each_step=0.83s, eta=2:48:22\n",
      "2022-07-06 18:43:30 [INFO]\t[TRAIN] Epoch=191/500, Step=30/39, loss=0.031664, lr=0.000500, time_each_step=0.84s, eta=2:48:52\n",
      "2022-07-06 18:43:37 [INFO]\t[TRAIN] Epoch 191 finished, loss=0.028778534 .\n",
      "2022-07-06 18:43:41 [INFO]\t[TRAIN] Epoch=192/500, Step=1/39, loss=0.026359, lr=0.000500, time_each_step=1.07s, eta=3:35:31\n",
      "2022-07-06 18:43:49 [INFO]\t[TRAIN] Epoch=192/500, Step=11/39, loss=0.023128, lr=0.000500, time_each_step=0.86s, eta=2:53:34\n",
      "2022-07-06 18:43:58 [INFO]\t[TRAIN] Epoch=192/500, Step=21/39, loss=0.036529, lr=0.000500, time_each_step=0.84s, eta=2:50:5\n",
      "2022-07-06 18:44:06 [INFO]\t[TRAIN] Epoch=192/500, Step=31/39, loss=0.036461, lr=0.000500, time_each_step=0.84s, eta=2:48:31\n",
      "2022-07-06 18:44:13 [INFO]\t[TRAIN] Epoch 192 finished, loss=0.027620936 .\n",
      "2022-07-06 18:44:17 [INFO]\t[TRAIN] Epoch=193/500, Step=2/39, loss=0.038539, lr=0.000500, time_each_step=1.07s, eta=3:35:45\n",
      "2022-07-06 18:44:25 [INFO]\t[TRAIN] Epoch=193/500, Step=12/39, loss=0.030168, lr=0.000500, time_each_step=0.84s, eta=2:49:55\n",
      "2022-07-06 18:44:34 [INFO]\t[TRAIN] Epoch=193/500, Step=22/39, loss=0.041411, lr=0.000500, time_each_step=0.84s, eta=2:48:39\n",
      "2022-07-06 18:44:42 [INFO]\t[TRAIN] Epoch=193/500, Step=32/39, loss=0.013835, lr=0.000500, time_each_step=0.84s, eta=2:47:55\n",
      "2022-07-06 18:44:48 [INFO]\t[TRAIN] Epoch 193 finished, loss=0.030207261 .\n",
      "2022-07-06 18:44:53 [INFO]\t[TRAIN] Epoch=194/500, Step=3/39, loss=0.024879, lr=0.000500, time_each_step=1.09s, eta=3:38:5\n",
      "2022-07-06 18:45:02 [INFO]\t[TRAIN] Epoch=194/500, Step=13/39, loss=0.045296, lr=0.000500, time_each_step=0.85s, eta=2:50:25\n",
      "2022-07-06 18:45:10 [INFO]\t[TRAIN] Epoch=194/500, Step=23/39, loss=0.014834, lr=0.000500, time_each_step=0.84s, eta=2:48:29\n",
      "2022-07-06 18:45:18 [INFO]\t[TRAIN] Epoch=194/500, Step=33/39, loss=0.008125, lr=0.000500, time_each_step=0.83s, eta=2:46:56\n",
      "2022-07-06 18:45:23 [INFO]\t[TRAIN] Epoch 194 finished, loss=0.029398352 .\n",
      "2022-07-06 18:45:29 [INFO]\t[TRAIN] Epoch=195/500, Step=4/39, loss=0.039557, lr=0.000500, time_each_step=1.08s, eta=3:35:43\n",
      "2022-07-06 18:45:38 [INFO]\t[TRAIN] Epoch=195/500, Step=14/39, loss=0.031123, lr=0.000500, time_each_step=0.84s, eta=2:47:59\n",
      "2022-07-06 18:45:46 [INFO]\t[TRAIN] Epoch=195/500, Step=24/39, loss=0.029632, lr=0.000500, time_each_step=0.83s, eta=2:46:28\n",
      "2022-07-06 18:45:54 [INFO]\t[TRAIN] Epoch=195/500, Step=34/39, loss=0.037073, lr=0.000500, time_each_step=0.83s, eta=2:46:14\n",
      "2022-07-06 18:45:59 [INFO]\t[TRAIN] Epoch 195 finished, loss=0.029540362 .\n",
      "2022-07-06 18:46:05 [INFO]\t[TRAIN] Epoch=196/500, Step=5/39, loss=0.042201, lr=0.000500, time_each_step=1.09s, eta=3:37:1\n",
      "2022-07-06 18:46:14 [INFO]\t[TRAIN] Epoch=196/500, Step=15/39, loss=0.017760, lr=0.000500, time_each_step=0.86s, eta=2:50:50\n",
      "2022-07-06 18:46:22 [INFO]\t[TRAIN] Epoch=196/500, Step=25/39, loss=0.033752, lr=0.000500, time_each_step=0.84s, eta=2:46:44\n",
      "2022-07-06 18:46:31 [INFO]\t[TRAIN] Epoch=196/500, Step=35/39, loss=0.028081, lr=0.000500, time_each_step=0.83s, eta=2:45:52\n",
      "2022-07-06 18:46:34 [INFO]\t[TRAIN] Epoch 196 finished, loss=0.02920846 .\n",
      "2022-07-06 18:46:42 [INFO]\t[TRAIN] Epoch=197/500, Step=6/39, loss=0.029054, lr=0.000500, time_each_step=1.09s, eta=3:35:32\n",
      "2022-07-06 18:46:50 [INFO]\t[TRAIN] Epoch=197/500, Step=16/39, loss=0.029478, lr=0.000500, time_each_step=0.84s, eta=2:46:14\n",
      "2022-07-06 18:46:58 [INFO]\t[TRAIN] Epoch=197/500, Step=26/39, loss=0.017257, lr=0.000500, time_each_step=0.84s, eta=2:46:2\n",
      "2022-07-06 18:47:07 [INFO]\t[TRAIN] Epoch=197/500, Step=36/39, loss=0.013235, lr=0.000500, time_each_step=0.84s, eta=2:46:4\n",
      "2022-07-06 18:47:09 [INFO]\t[TRAIN] Epoch 197 finished, loss=0.028741399 .\n",
      "2022-07-06 18:47:18 [INFO]\t[TRAIN] Epoch=198/500, Step=7/39, loss=0.025081, lr=0.000500, time_each_step=1.13s, eta=3:44:2\n",
      "2022-07-06 18:47:27 [INFO]\t[TRAIN] Epoch=198/500, Step=17/39, loss=0.030551, lr=0.000500, time_each_step=0.85s, eta=2:48:49\n",
      "2022-07-06 18:47:35 [INFO]\t[TRAIN] Epoch=198/500, Step=27/39, loss=0.022392, lr=0.000500, time_each_step=0.84s, eta=2:45:59\n",
      "2022-07-06 18:47:44 [INFO]\t[TRAIN] Epoch=198/500, Step=37/39, loss=0.015385, lr=0.000500, time_each_step=0.84s, eta=2:45:35\n",
      "2022-07-06 18:47:45 [INFO]\t[TRAIN] Epoch 198 finished, loss=0.02949925 .\n",
      "2022-07-06 18:47:54 [INFO]\t[TRAIN] Epoch=199/500, Step=8/39, loss=0.029295, lr=0.000500, time_each_step=1.08s, eta=3:32:48\n",
      "2022-07-06 18:48:03 [INFO]\t[TRAIN] Epoch=199/500, Step=18/39, loss=0.023460, lr=0.000500, time_each_step=0.83s, eta=2:44:33\n",
      "2022-07-06 18:48:11 [INFO]\t[TRAIN] Epoch=199/500, Step=28/39, loss=0.034664, lr=0.000500, time_each_step=0.84s, eta=2:45:32\n",
      "2022-07-06 18:48:20 [INFO]\t[TRAIN] Epoch=199/500, Step=38/39, loss=0.034323, lr=0.000500, time_each_step=0.83s, eta=2:43:46\n",
      "2022-07-06 18:48:20 [INFO]\t[TRAIN] Epoch 199 finished, loss=0.02903181 .\n",
      "2022-07-06 18:48:31 [INFO]\t[TRAIN] Epoch=200/500, Step=9/39, loss=0.010965, lr=0.000500, time_each_step=1.11s, eta=3:37:38\n",
      "2022-07-06 18:48:39 [INFO]\t[TRAIN] Epoch=200/500, Step=19/39, loss=0.019889, lr=0.000500, time_each_step=0.84s, eta=2:45:0\n",
      "2022-07-06 18:48:47 [INFO]\t[TRAIN] Epoch=200/500, Step=29/39, loss=0.017170, lr=0.000500, time_each_step=0.83s, eta=2:43:43\n",
      "2022-07-06 18:48:56 [INFO]\t[TRAIN] Epoch=200/500, Step=39/39, loss=0.019439, lr=0.000500, time_each_step=0.83s, eta=2:43:22\n",
      "2022-07-06 18:48:56 [INFO]\t[TRAIN] Epoch 200 finished, loss=0.029029412 .\n",
      "2022-07-06 18:48:56 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 18:48:56 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 18:48:58 [INFO]\t[EVAL] Finished, Epoch=200, miou=0.885111, category_iou=[0.98829325 0.78192847], oacc=0.988765, category_acc=[0.99256697 0.90696766], kappa=0.871739, category_F1-score=[0.99411216 0.87762049] .\n",
      "2022-07-06 18:48:58 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_180, miou=0.8862387140739285\n",
      "2022-07-06 18:48:58 [INFO]\tModel saved in /home/aistudio/exp/epoch_200.\n",
      "2022-07-06 18:49:09 [INFO]\t[TRAIN] Epoch=201/500, Step=10/39, loss=0.032128, lr=0.000500, time_each_step=1.11s, eta=3:36:18\n",
      "2022-07-06 18:49:18 [INFO]\t[TRAIN] Epoch=201/500, Step=20/39, loss=0.030110, lr=0.000500, time_each_step=0.84s, eta=2:45:17\n",
      "2022-07-06 18:49:26 [INFO]\t[TRAIN] Epoch=201/500, Step=30/39, loss=0.025997, lr=0.000500, time_each_step=0.85s, eta=2:45:33\n",
      "2022-07-06 18:49:34 [INFO]\t[TRAIN] Epoch 201 finished, loss=0.027255578 .\n",
      "2022-07-06 18:49:37 [INFO]\t[TRAIN] Epoch=202/500, Step=1/39, loss=0.053079, lr=0.000500, time_each_step=1.09s, eta=3:33:22\n",
      "2022-07-06 18:49:46 [INFO]\t[TRAIN] Epoch=202/500, Step=11/39, loss=0.035251, lr=0.000500, time_each_step=0.87s, eta=2:49:59\n",
      "2022-07-06 18:49:54 [INFO]\t[TRAIN] Epoch=202/500, Step=21/39, loss=0.024604, lr=0.000500, time_each_step=0.84s, eta=2:44:43\n",
      "2022-07-06 18:50:03 [INFO]\t[TRAIN] Epoch=202/500, Step=31/39, loss=0.027194, lr=0.000500, time_each_step=0.83s, eta=2:42:35\n",
      "2022-07-06 18:50:10 [INFO]\t[TRAIN] Epoch 202 finished, loss=0.028164664 .\n",
      "2022-07-06 18:50:14 [INFO]\t[TRAIN] Epoch=203/500, Step=2/39, loss=0.024903, lr=0.000500, time_each_step=1.13s, eta=3:40:18\n",
      "2022-07-06 18:50:23 [INFO]\t[TRAIN] Epoch=203/500, Step=12/39, loss=0.025112, lr=0.000500, time_each_step=0.85s, eta=2:45:29\n",
      "2022-07-06 18:50:31 [INFO]\t[TRAIN] Epoch=203/500, Step=22/39, loss=0.028422, lr=0.000500, time_each_step=0.84s, eta=2:44:0\n",
      "2022-07-06 18:50:40 [INFO]\t[TRAIN] Epoch=203/500, Step=32/39, loss=0.033873, lr=0.000500, time_each_step=0.84s, eta=2:43:13\n",
      "2022-07-06 18:50:46 [INFO]\t[TRAIN] Epoch 203 finished, loss=0.02847339 .\n",
      "2022-07-06 18:50:50 [INFO]\t[TRAIN] Epoch=204/500, Step=3/39, loss=0.026897, lr=0.000500, time_each_step=1.07s, eta=3:26:48\n",
      "2022-07-06 18:50:59 [INFO]\t[TRAIN] Epoch=204/500, Step=13/39, loss=0.023868, lr=0.000500, time_each_step=0.85s, eta=2:44:30\n",
      "2022-07-06 18:51:07 [INFO]\t[TRAIN] Epoch=204/500, Step=23/39, loss=0.028826, lr=0.000500, time_each_step=0.84s, eta=2:42:6\n",
      "2022-07-06 18:51:16 [INFO]\t[TRAIN] Epoch=204/500, Step=33/39, loss=0.018585, lr=0.000500, time_each_step=0.83s, eta=2:41:24\n",
      "2022-07-06 18:51:21 [INFO]\t[TRAIN] Epoch 204 finished, loss=0.029099874 .\n",
      "2022-07-06 18:51:27 [INFO]\t[TRAIN] Epoch=205/500, Step=4/39, loss=0.018685, lr=0.000500, time_each_step=1.08s, eta=3:29:21\n",
      "2022-07-06 18:51:35 [INFO]\t[TRAIN] Epoch=205/500, Step=14/39, loss=0.030898, lr=0.000500, time_each_step=0.86s, eta=2:46:19\n",
      "2022-07-06 18:51:43 [INFO]\t[TRAIN] Epoch=205/500, Step=24/39, loss=0.017861, lr=0.000500, time_each_step=0.83s, eta=2:40:50\n",
      "2022-07-06 18:51:52 [INFO]\t[TRAIN] Epoch=205/500, Step=34/39, loss=0.041684, lr=0.000500, time_each_step=0.83s, eta=2:40:43\n",
      "2022-07-06 18:51:56 [INFO]\t[TRAIN] Epoch 205 finished, loss=0.028853817 .\n",
      "2022-07-06 18:52:03 [INFO]\t[TRAIN] Epoch=206/500, Step=5/39, loss=0.020516, lr=0.000500, time_each_step=1.08s, eta=3:28:51\n",
      "2022-07-06 18:52:11 [INFO]\t[TRAIN] Epoch=206/500, Step=15/39, loss=0.021144, lr=0.000500, time_each_step=0.84s, eta=2:42:39\n",
      "2022-07-06 18:52:20 [INFO]\t[TRAIN] Epoch=206/500, Step=25/39, loss=0.048233, lr=0.000500, time_each_step=0.84s, eta=2:41:54\n",
      "2022-07-06 18:52:28 [INFO]\t[TRAIN] Epoch=206/500, Step=35/39, loss=0.022037, lr=0.000500, time_each_step=0.83s, eta=2:39:58\n",
      "2022-07-06 18:52:31 [INFO]\t[TRAIN] Epoch 206 finished, loss=0.029105453 .\n",
      "2022-07-06 18:52:40 [INFO]\t[TRAIN] Epoch=207/500, Step=6/39, loss=0.035109, lr=0.000500, time_each_step=1.16s, eta=3:41:53\n",
      "2022-07-06 18:52:48 [INFO]\t[TRAIN] Epoch=207/500, Step=16/39, loss=0.030828, lr=0.000500, time_each_step=0.84s, eta=2:41:47\n",
      "2022-07-06 18:52:56 [INFO]\t[TRAIN] Epoch=207/500, Step=26/39, loss=0.043938, lr=0.000500, time_each_step=0.83s, eta=2:40:9\n",
      "2022-07-06 18:53:05 [INFO]\t[TRAIN] Epoch=207/500, Step=36/39, loss=0.014973, lr=0.000500, time_each_step=0.85s, eta=2:42:37\n",
      "2022-07-06 18:53:08 [INFO]\t[TRAIN] Epoch 207 finished, loss=0.029338928 .\n",
      "2022-07-06 18:53:16 [INFO]\t[TRAIN] Epoch=208/500, Step=7/39, loss=0.050854, lr=0.000500, time_each_step=1.09s, eta=3:27:54\n",
      "2022-07-06 18:53:24 [INFO]\t[TRAIN] Epoch=208/500, Step=17/39, loss=0.021339, lr=0.000500, time_each_step=0.85s, eta=2:42:17\n",
      "2022-07-06 18:53:33 [INFO]\t[TRAIN] Epoch=208/500, Step=27/39, loss=0.010045, lr=0.000500, time_each_step=0.83s, eta=2:39:24\n",
      "2022-07-06 18:53:41 [INFO]\t[TRAIN] Epoch=208/500, Step=37/39, loss=0.033103, lr=0.000500, time_each_step=0.84s, eta=2:39:35\n",
      "2022-07-06 18:53:43 [INFO]\t[TRAIN] Epoch 208 finished, loss=0.029237704 .\n",
      "2022-07-06 18:53:52 [INFO]\t[TRAIN] Epoch=209/500, Step=8/39, loss=0.018249, lr=0.000500, time_each_step=1.08s, eta=3:25:53\n",
      "2022-07-06 18:54:00 [INFO]\t[TRAIN] Epoch=209/500, Step=18/39, loss=0.013763, lr=0.000500, time_each_step=0.84s, eta=2:39:39\n",
      "2022-07-06 18:54:09 [INFO]\t[TRAIN] Epoch=209/500, Step=28/39, loss=0.023912, lr=0.000500, time_each_step=0.84s, eta=2:40:6\n",
      "2022-07-06 18:54:17 [INFO]\t[TRAIN] Epoch=209/500, Step=38/39, loss=0.021778, lr=0.000500, time_each_step=0.83s, eta=2:38:33\n",
      "2022-07-06 18:54:18 [INFO]\t[TRAIN] Epoch 209 finished, loss=0.029561976 .\n",
      "2022-07-06 18:54:28 [INFO]\t[TRAIN] Epoch=210/500, Step=9/39, loss=0.027459, lr=0.000500, time_each_step=1.09s, eta=3:27:23\n",
      "2022-07-06 18:54:37 [INFO]\t[TRAIN] Epoch=210/500, Step=19/39, loss=0.013323, lr=0.000500, time_each_step=0.84s, eta=2:39:34\n",
      "2022-07-06 18:54:45 [INFO]\t[TRAIN] Epoch=210/500, Step=29/39, loss=0.026654, lr=0.000500, time_each_step=0.84s, eta=2:39:28\n",
      "2022-07-06 18:54:53 [INFO]\t[TRAIN] Epoch=210/500, Step=39/39, loss=0.026773, lr=0.000500, time_each_step=0.84s, eta=2:39:1\n",
      "2022-07-06 18:54:54 [INFO]\t[TRAIN] Epoch 210 finished, loss=0.028708726 .\n",
      "2022-07-06 18:54:54 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 18:54:54 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 18:54:56 [INFO]\t[EVAL] Finished, Epoch=210, miou=0.880870, category_iou=[0.98803131 0.77370931], oacc=0.988502, category_acc=[0.99156465 0.91989753], kappa=0.866416, category_F1-score=[0.99397962 0.87241952] .\n",
      "2022-07-06 18:54:56 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_180, miou=0.8862387140739285\n",
      "2022-07-06 18:54:56 [INFO]\tModel saved in /home/aistudio/exp/epoch_210.\n",
      "2022-07-06 18:55:07 [INFO]\t[TRAIN] Epoch=211/500, Step=10/39, loss=0.024784, lr=0.000500, time_each_step=1.12s, eta=3:31:45\n",
      "2022-07-06 18:55:16 [INFO]\t[TRAIN] Epoch=211/500, Step=20/39, loss=0.031646, lr=0.000500, time_each_step=0.84s, eta=2:39:3\n",
      "2022-07-06 18:55:24 [INFO]\t[TRAIN] Epoch=211/500, Step=30/39, loss=0.030468, lr=0.000500, time_each_step=0.83s, eta=2:37:38\n",
      "2022-07-06 18:55:31 [INFO]\t[TRAIN] Epoch 211 finished, loss=0.028112993 .\n",
      "2022-07-06 18:55:35 [INFO]\t[TRAIN] Epoch=212/500, Step=1/39, loss=0.030406, lr=0.000500, time_each_step=1.07s, eta=3:22:13\n",
      "2022-07-06 18:55:43 [INFO]\t[TRAIN] Epoch=212/500, Step=11/39, loss=0.017976, lr=0.000500, time_each_step=0.85s, eta=2:40:3\n",
      "2022-07-06 18:55:52 [INFO]\t[TRAIN] Epoch=212/500, Step=21/39, loss=0.048368, lr=0.000500, time_each_step=0.84s, eta=2:37:42\n",
      "2022-07-06 18:56:00 [INFO]\t[TRAIN] Epoch=212/500, Step=31/39, loss=0.027778, lr=0.000500, time_each_step=0.83s, eta=2:37:11\n",
      "2022-07-06 18:56:07 [INFO]\t[TRAIN] Epoch 212 finished, loss=0.027500825 .\n",
      "2022-07-06 18:56:11 [INFO]\t[TRAIN] Epoch=213/500, Step=2/39, loss=0.028463, lr=0.000500, time_each_step=1.08s, eta=3:23:25\n",
      "2022-07-06 18:56:19 [INFO]\t[TRAIN] Epoch=213/500, Step=12/39, loss=0.024399, lr=0.000500, time_each_step=0.85s, eta=2:39:18\n",
      "2022-07-06 18:56:28 [INFO]\t[TRAIN] Epoch=213/500, Step=22/39, loss=0.037188, lr=0.000500, time_each_step=0.87s, eta=2:42:48\n",
      "2022-07-06 18:56:37 [INFO]\t[TRAIN] Epoch=213/500, Step=32/39, loss=0.029226, lr=0.000500, time_each_step=0.9s, eta=2:49:27\n",
      "2022-07-06 18:56:43 [INFO]\t[TRAIN] Epoch 213 finished, loss=0.028208992 .\n",
      "2022-07-06 18:56:48 [INFO]\t[TRAIN] Epoch=214/500, Step=3/39, loss=0.032826, lr=0.000500, time_each_step=1.09s, eta=3:24:50\n",
      "2022-07-06 18:56:57 [INFO]\t[TRAIN] Epoch=214/500, Step=13/39, loss=0.024737, lr=0.000500, time_each_step=0.86s, eta=2:41:12\n",
      "2022-07-06 18:57:05 [INFO]\t[TRAIN] Epoch=214/500, Step=23/39, loss=0.050835, lr=0.000500, time_each_step=0.83s, eta=2:36:10\n",
      "2022-07-06 18:57:13 [INFO]\t[TRAIN] Epoch=214/500, Step=33/39, loss=0.037026, lr=0.000500, time_each_step=0.83s, eta=2:35:58\n",
      "2022-07-06 18:57:19 [INFO]\t[TRAIN] Epoch 214 finished, loss=0.028083038 .\n",
      "2022-07-06 18:57:25 [INFO]\t[TRAIN] Epoch=215/500, Step=4/39, loss=0.045845, lr=0.000500, time_each_step=1.1s, eta=3:25:42\n",
      "2022-07-06 18:57:33 [INFO]\t[TRAIN] Epoch=215/500, Step=14/39, loss=0.034169, lr=0.000500, time_each_step=0.85s, eta=2:37:50\n",
      "2022-07-06 18:57:42 [INFO]\t[TRAIN] Epoch=215/500, Step=24/39, loss=0.029176, lr=0.000500, time_each_step=0.85s, eta=2:38:1\n",
      "2022-07-06 18:57:50 [INFO]\t[TRAIN] Epoch=215/500, Step=34/39, loss=0.024937, lr=0.000500, time_each_step=0.84s, eta=2:35:59\n",
      "2022-07-06 18:57:54 [INFO]\t[TRAIN] Epoch 215 finished, loss=0.027998468 .\n",
      "2022-07-06 18:58:01 [INFO]\t[TRAIN] Epoch=216/500, Step=5/39, loss=0.037174, lr=0.000500, time_each_step=1.09s, eta=3:22:24\n",
      "2022-07-06 18:58:09 [INFO]\t[TRAIN] Epoch=216/500, Step=15/39, loss=0.022719, lr=0.000500, time_each_step=0.84s, eta=2:36:42\n",
      "2022-07-06 18:58:18 [INFO]\t[TRAIN] Epoch=216/500, Step=25/39, loss=0.023564, lr=0.000500, time_each_step=0.84s, eta=2:36:11\n",
      "2022-07-06 18:58:26 [INFO]\t[TRAIN] Epoch=216/500, Step=35/39, loss=0.019588, lr=0.000500, time_each_step=0.83s, eta=2:34:59\n",
      "2022-07-06 18:58:29 [INFO]\t[TRAIN] Epoch 216 finished, loss=0.028997144 .\n",
      "2022-07-06 18:58:37 [INFO]\t[TRAIN] Epoch=217/500, Step=6/39, loss=0.029538, lr=0.000500, time_each_step=1.08s, eta=3:20:36\n",
      "2022-07-06 18:58:46 [INFO]\t[TRAIN] Epoch=217/500, Step=16/39, loss=0.020077, lr=0.000500, time_each_step=0.85s, eta=2:38:0\n",
      "2022-07-06 18:58:54 [INFO]\t[TRAIN] Epoch=217/500, Step=26/39, loss=0.050010, lr=0.000500, time_each_step=0.83s, eta=2:34:36\n",
      "2022-07-06 18:59:02 [INFO]\t[TRAIN] Epoch=217/500, Step=36/39, loss=0.037173, lr=0.000500, time_each_step=0.84s, eta=2:35:6\n",
      "2022-07-06 18:59:05 [INFO]\t[TRAIN] Epoch 217 finished, loss=0.029019156 .\n",
      "2022-07-06 18:59:13 [INFO]\t[TRAIN] Epoch=218/500, Step=7/39, loss=0.039096, lr=0.000500, time_each_step=1.08s, eta=3:19:54\n",
      "2022-07-06 18:59:22 [INFO]\t[TRAIN] Epoch=218/500, Step=17/39, loss=0.035596, lr=0.000500, time_each_step=0.84s, eta=2:34:39\n",
      "2022-07-06 18:59:30 [INFO]\t[TRAIN] Epoch=218/500, Step=27/39, loss=0.014029, lr=0.000500, time_each_step=0.83s, eta=2:33:49\n",
      "2022-07-06 18:59:38 [INFO]\t[TRAIN] Epoch=218/500, Step=37/39, loss=0.021845, lr=0.000500, time_each_step=0.83s, eta=2:33:20\n",
      "2022-07-06 18:59:40 [INFO]\t[TRAIN] Epoch 218 finished, loss=0.0286025 .\n",
      "2022-07-06 18:59:49 [INFO]\t[TRAIN] Epoch=219/500, Step=8/39, loss=0.023529, lr=0.000500, time_each_step=1.1s, eta=3:23:6\n",
      "2022-07-06 18:59:58 [INFO]\t[TRAIN] Epoch=219/500, Step=18/39, loss=0.014108, lr=0.000500, time_each_step=0.84s, eta=2:35:28\n",
      "2022-07-06 19:00:06 [INFO]\t[TRAIN] Epoch=219/500, Step=28/39, loss=0.029050, lr=0.000500, time_each_step=0.84s, eta=2:33:50\n",
      "2022-07-06 19:00:14 [INFO]\t[TRAIN] Epoch=219/500, Step=38/39, loss=0.022322, lr=0.000500, time_each_step=0.83s, eta=2:32:50\n",
      "2022-07-06 19:00:15 [INFO]\t[TRAIN] Epoch 219 finished, loss=0.028101286 .\n",
      "2022-07-06 19:00:25 [INFO]\t[TRAIN] Epoch=220/500, Step=9/39, loss=0.029016, lr=0.000500, time_each_step=1.09s, eta=3:19:50\n",
      "2022-07-06 19:00:34 [INFO]\t[TRAIN] Epoch=220/500, Step=19/39, loss=0.024476, lr=0.000500, time_each_step=0.84s, eta=2:33:26\n",
      "2022-07-06 19:00:42 [INFO]\t[TRAIN] Epoch=220/500, Step=29/39, loss=0.024949, lr=0.000500, time_each_step=0.83s, eta=2:32:46\n",
      "2022-07-06 19:00:51 [INFO]\t[TRAIN] Epoch=220/500, Step=39/39, loss=0.032051, lr=0.000500, time_each_step=0.83s, eta=2:32:19\n",
      "2022-07-06 19:00:51 [INFO]\t[TRAIN] Epoch 220 finished, loss=0.030111257 .\n",
      "2022-07-06 19:00:51 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 19:00:51 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 19:00:53 [INFO]\t[EVAL] Finished, Epoch=220, miou=0.884637, category_iou=[0.98829234 0.7809815 ], oacc=0.988762, category_acc=[0.99234966 0.91079948], kappa=0.871144, category_F1-score=[0.9941117  0.87702371] .\n",
      "2022-07-06 19:00:53 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_180, miou=0.8862387140739285\n",
      "2022-07-06 19:00:53 [INFO]\tModel saved in /home/aistudio/exp/epoch_220.\n",
      "2022-07-06 19:01:04 [INFO]\t[TRAIN] Epoch=221/500, Step=10/39, loss=0.031370, lr=0.000500, time_each_step=1.08s, eta=3:18:3\n",
      "2022-07-06 19:01:12 [INFO]\t[TRAIN] Epoch=221/500, Step=20/39, loss=0.026953, lr=0.000500, time_each_step=0.84s, eta=2:33:9\n",
      "2022-07-06 19:01:21 [INFO]\t[TRAIN] Epoch=221/500, Step=30/39, loss=0.042030, lr=0.000500, time_each_step=0.83s, eta=2:32:5\n",
      "2022-07-06 19:01:28 [INFO]\t[TRAIN] Epoch 221 finished, loss=0.0292105 .\n",
      "2022-07-06 19:01:31 [INFO]\t[TRAIN] Epoch=222/500, Step=1/39, loss=0.024319, lr=0.000500, time_each_step=1.07s, eta=3:15:18\n",
      "2022-07-06 19:01:40 [INFO]\t[TRAIN] Epoch=222/500, Step=11/39, loss=0.035503, lr=0.000500, time_each_step=0.85s, eta=2:34:8\n",
      "2022-07-06 19:01:48 [INFO]\t[TRAIN] Epoch=222/500, Step=21/39, loss=0.018548, lr=0.000500, time_each_step=0.83s, eta=2:31:52\n",
      "2022-07-06 19:01:57 [INFO]\t[TRAIN] Epoch=222/500, Step=31/39, loss=0.031774, lr=0.000500, time_each_step=0.84s, eta=2:32:47\n",
      "2022-07-06 19:02:03 [INFO]\t[TRAIN] Epoch 222 finished, loss=0.03025558 .\n",
      "2022-07-06 19:02:07 [INFO]\t[TRAIN] Epoch=223/500, Step=2/39, loss=0.023112, lr=0.000500, time_each_step=1.07s, eta=3:13:54\n",
      "2022-07-06 19:02:16 [INFO]\t[TRAIN] Epoch=223/500, Step=12/39, loss=0.028437, lr=0.000500, time_each_step=0.87s, eta=2:37:52\n",
      "2022-07-06 19:02:24 [INFO]\t[TRAIN] Epoch=223/500, Step=22/39, loss=0.028946, lr=0.000500, time_each_step=0.83s, eta=2:31:8\n",
      "2022-07-06 19:02:33 [INFO]\t[TRAIN] Epoch=223/500, Step=32/39, loss=0.036851, lr=0.000500, time_each_step=0.84s, eta=2:31:35\n",
      "2022-07-06 19:02:39 [INFO]\t[TRAIN] Epoch 223 finished, loss=0.0294028 .\n",
      "2022-07-06 19:02:44 [INFO]\t[TRAIN] Epoch=224/500, Step=3/39, loss=0.014599, lr=0.000500, time_each_step=1.07s, eta=3:13:32\n",
      "2022-07-06 19:02:52 [INFO]\t[TRAIN] Epoch=224/500, Step=13/39, loss=0.048237, lr=0.000500, time_each_step=0.84s, eta=2:32:19\n",
      "2022-07-06 19:03:00 [INFO]\t[TRAIN] Epoch=224/500, Step=23/39, loss=0.034683, lr=0.000500, time_each_step=0.84s, eta=2:31:44\n",
      "2022-07-06 19:03:09 [INFO]\t[TRAIN] Epoch=224/500, Step=33/39, loss=0.022754, lr=0.000500, time_each_step=0.83s, eta=2:30:34\n",
      "2022-07-06 19:03:14 [INFO]\t[TRAIN] Epoch 224 finished, loss=0.028964575 .\n",
      "2022-07-06 19:03:20 [INFO]\t[TRAIN] Epoch=225/500, Step=4/39, loss=0.041099, lr=0.000500, time_each_step=1.07s, eta=3:13:6\n",
      "2022-07-06 19:03:28 [INFO]\t[TRAIN] Epoch=225/500, Step=14/39, loss=0.020368, lr=0.000500, time_each_step=0.84s, eta=2:32:14\n",
      "2022-07-06 19:03:36 [INFO]\t[TRAIN] Epoch=225/500, Step=24/39, loss=0.026604, lr=0.000500, time_each_step=0.83s, eta=2:30:19\n",
      "2022-07-06 19:03:45 [INFO]\t[TRAIN] Epoch=225/500, Step=34/39, loss=0.030095, lr=0.000500, time_each_step=0.83s, eta=2:29:53\n",
      "2022-07-06 19:03:49 [INFO]\t[TRAIN] Epoch 225 finished, loss=0.027818918 .\n",
      "2022-07-06 19:03:56 [INFO]\t[TRAIN] Epoch=226/500, Step=5/39, loss=0.044037, lr=0.000500, time_each_step=1.1s, eta=3:17:16\n",
      "2022-07-06 19:04:04 [INFO]\t[TRAIN] Epoch=226/500, Step=15/39, loss=0.022463, lr=0.000500, time_each_step=0.85s, eta=2:32:45\n",
      "2022-07-06 19:04:13 [INFO]\t[TRAIN] Epoch=226/500, Step=25/39, loss=0.026128, lr=0.000500, time_each_step=0.83s, eta=2:29:30\n",
      "2022-07-06 19:04:21 [INFO]\t[TRAIN] Epoch=226/500, Step=35/39, loss=0.024490, lr=0.000500, time_each_step=0.84s, eta=2:30:22\n",
      "2022-07-06 19:04:25 [INFO]\t[TRAIN] Epoch 226 finished, loss=0.029264318 .\n",
      "2022-07-06 19:04:32 [INFO]\t[TRAIN] Epoch=227/500, Step=6/39, loss=0.024341, lr=0.000500, time_each_step=1.08s, eta=3:12:47\n",
      "2022-07-06 19:04:40 [INFO]\t[TRAIN] Epoch=227/500, Step=16/39, loss=0.027012, lr=0.000500, time_each_step=0.84s, eta=2:30:12\n",
      "2022-07-06 19:04:49 [INFO]\t[TRAIN] Epoch=227/500, Step=26/39, loss=0.032217, lr=0.000500, time_each_step=0.83s, eta=2:28:59\n",
      "2022-07-06 19:04:57 [INFO]\t[TRAIN] Epoch=227/500, Step=36/39, loss=0.022208, lr=0.000500, time_each_step=0.83s, eta=2:28:39\n",
      "2022-07-06 19:05:00 [INFO]\t[TRAIN] Epoch 227 finished, loss=0.027505616 .\n",
      "2022-07-06 19:05:09 [INFO]\t[TRAIN] Epoch=228/500, Step=7/39, loss=0.022302, lr=0.000500, time_each_step=1.14s, eta=3:22:24\n",
      "2022-07-06 19:05:17 [INFO]\t[TRAIN] Epoch=228/500, Step=17/39, loss=0.034126, lr=0.000500, time_each_step=0.86s, eta=2:32:43\n",
      "2022-07-06 19:05:26 [INFO]\t[TRAIN] Epoch=228/500, Step=27/39, loss=0.033560, lr=0.000500, time_each_step=0.84s, eta=2:29:22\n",
      "2022-07-06 19:05:34 [INFO]\t[TRAIN] Epoch=228/500, Step=37/39, loss=0.025912, lr=0.000500, time_each_step=0.83s, eta=2:28:29\n",
      "2022-07-06 19:05:36 [INFO]\t[TRAIN] Epoch 228 finished, loss=0.027879644 .\n",
      "2022-07-06 19:05:45 [INFO]\t[TRAIN] Epoch=229/500, Step=8/39, loss=0.037724, lr=0.000500, time_each_step=1.08s, eta=3:12:11\n",
      "2022-07-06 19:05:53 [INFO]\t[TRAIN] Epoch=229/500, Step=18/39, loss=0.025776, lr=0.000500, time_each_step=0.84s, eta=2:28:43\n",
      "2022-07-06 19:06:02 [INFO]\t[TRAIN] Epoch=229/500, Step=28/39, loss=0.022988, lr=0.000500, time_each_step=0.83s, eta=2:27:45\n",
      "2022-07-06 19:06:10 [INFO]\t[TRAIN] Epoch=229/500, Step=38/39, loss=0.021831, lr=0.000500, time_each_step=0.83s, eta=2:27:23\n",
      "2022-07-06 19:06:11 [INFO]\t[TRAIN] Epoch 229 finished, loss=0.028025538 .\n",
      "2022-07-06 19:06:21 [INFO]\t[TRAIN] Epoch=230/500, Step=9/39, loss=0.027276, lr=0.000500, time_each_step=1.08s, eta=3:11:27\n",
      "2022-07-06 19:06:29 [INFO]\t[TRAIN] Epoch=230/500, Step=19/39, loss=0.033708, lr=0.000500, time_each_step=0.84s, eta=2:29:20\n",
      "2022-07-06 19:06:38 [INFO]\t[TRAIN] Epoch=230/500, Step=29/39, loss=0.031046, lr=0.000500, time_each_step=0.83s, eta=2:27:12\n",
      "2022-07-06 19:06:46 [INFO]\t[TRAIN] Epoch=230/500, Step=39/39, loss=0.046386, lr=0.000500, time_each_step=0.83s, eta=2:26:38\n",
      "2022-07-06 19:06:46 [INFO]\t[TRAIN] Epoch 230 finished, loss=0.028802786 .\n",
      "2022-07-06 19:06:46 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 19:06:46 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 19:06:48 [INFO]\t[EVAL] Finished, Epoch=230, miou=0.886361, category_iou=[0.98839776 0.78432463], oacc=0.988867, category_acc=[0.99277322 0.90542258], kappa=0.873298, category_F1-score=[0.99416503 0.87912773] .\n",
      "2022-07-06 19:06:49 [INFO]\tModel saved in /home/aistudio/exp/best_model.\n",
      "2022-07-06 19:06:49 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_230, miou=0.8863611962354033\n",
      "2022-07-06 19:06:49 [INFO]\tModel saved in /home/aistudio/exp/epoch_230.\n",
      "2022-07-06 19:07:00 [INFO]\t[TRAIN] Epoch=231/500, Step=10/39, loss=0.036399, lr=0.000500, time_each_step=1.09s, eta=3:12:1\n",
      "2022-07-06 19:07:08 [INFO]\t[TRAIN] Epoch=231/500, Step=20/39, loss=0.024207, lr=0.000500, time_each_step=0.84s, eta=2:27:27\n",
      "2022-07-06 19:07:17 [INFO]\t[TRAIN] Epoch=231/500, Step=30/39, loss=0.024541, lr=0.000500, time_each_step=0.84s, eta=2:28:55\n",
      "2022-07-06 19:07:24 [INFO]\t[TRAIN] Epoch 231 finished, loss=0.027371617 .\n",
      "2022-07-06 19:07:28 [INFO]\t[TRAIN] Epoch=232/500, Step=1/39, loss=0.016216, lr=0.000500, time_each_step=1.12s, eta=3:16:15\n",
      "2022-07-06 19:07:36 [INFO]\t[TRAIN] Epoch=232/500, Step=11/39, loss=0.037905, lr=0.000500, time_each_step=0.85s, eta=2:30:0\n",
      "2022-07-06 19:07:45 [INFO]\t[TRAIN] Epoch=232/500, Step=21/39, loss=0.029618, lr=0.000500, time_each_step=0.84s, eta=2:28:18\n",
      "2022-07-06 19:07:53 [INFO]\t[TRAIN] Epoch=232/500, Step=31/39, loss=0.030265, lr=0.000500, time_each_step=0.83s, eta=2:26:24\n",
      "2022-07-06 19:08:00 [INFO]\t[TRAIN] Epoch 232 finished, loss=0.029230088 .\n",
      "2022-07-06 19:08:04 [INFO]\t[TRAIN] Epoch=233/500, Step=2/39, loss=0.018727, lr=0.000500, time_each_step=1.07s, eta=3:8:17\n",
      "2022-07-06 19:08:13 [INFO]\t[TRAIN] Epoch=233/500, Step=12/39, loss=0.024386, lr=0.000500, time_each_step=0.85s, eta=2:29:52\n",
      "2022-07-06 19:08:21 [INFO]\t[TRAIN] Epoch=233/500, Step=22/39, loss=0.017671, lr=0.000500, time_each_step=0.84s, eta=2:28:0\n",
      "2022-07-06 19:08:29 [INFO]\t[TRAIN] Epoch=233/500, Step=32/39, loss=0.044698, lr=0.000500, time_each_step=0.83s, eta=2:25:55\n",
      "2022-07-06 19:08:35 [INFO]\t[TRAIN] Epoch 233 finished, loss=0.027220864 .\n",
      "2022-07-06 19:08:40 [INFO]\t[TRAIN] Epoch=234/500, Step=3/39, loss=0.015282, lr=0.000500, time_each_step=1.07s, eta=3:7:36\n",
      "2022-07-06 19:08:49 [INFO]\t[TRAIN] Epoch=234/500, Step=13/39, loss=0.025837, lr=0.000500, time_each_step=0.85s, eta=2:28:21\n",
      "2022-07-06 19:08:57 [INFO]\t[TRAIN] Epoch=234/500, Step=23/39, loss=0.026797, lr=0.000500, time_each_step=0.83s, eta=2:25:34\n",
      "2022-07-06 19:09:05 [INFO]\t[TRAIN] Epoch=234/500, Step=33/39, loss=0.029756, lr=0.000500, time_each_step=0.83s, eta=2:25:5\n",
      "2022-07-06 19:09:11 [INFO]\t[TRAIN] Epoch 234 finished, loss=0.02817501 .\n",
      "2022-07-06 19:09:17 [INFO]\t[TRAIN] Epoch=235/500, Step=4/39, loss=0.034189, lr=0.000500, time_each_step=1.12s, eta=3:13:59\n",
      "2022-07-06 19:09:25 [INFO]\t[TRAIN] Epoch=235/500, Step=14/39, loss=0.031853, lr=0.000500, time_each_step=0.85s, eta=2:28:27\n",
      "2022-07-06 19:09:34 [INFO]\t[TRAIN] Epoch=235/500, Step=24/39, loss=0.027456, lr=0.000500, time_each_step=0.84s, eta=2:25:27\n",
      "2022-07-06 19:09:42 [INFO]\t[TRAIN] Epoch=235/500, Step=34/39, loss=0.023194, lr=0.000500, time_each_step=0.83s, eta=2:25:0\n",
      "2022-07-06 19:09:46 [INFO]\t[TRAIN] Epoch 235 finished, loss=0.027955499 .\n",
      "2022-07-06 19:09:53 [INFO]\t[TRAIN] Epoch=236/500, Step=5/39, loss=0.014465, lr=0.000500, time_each_step=1.07s, eta=3:5:54\n",
      "2022-07-06 19:10:01 [INFO]\t[TRAIN] Epoch=236/500, Step=15/39, loss=0.035979, lr=0.000500, time_each_step=0.84s, eta=2:25:55\n",
      "2022-07-06 19:10:10 [INFO]\t[TRAIN] Epoch=236/500, Step=25/39, loss=0.028500, lr=0.000500, time_each_step=0.83s, eta=2:24:33\n",
      "2022-07-06 19:10:18 [INFO]\t[TRAIN] Epoch=236/500, Step=35/39, loss=0.057306, lr=0.000500, time_each_step=0.83s, eta=2:24:6\n",
      "2022-07-06 19:10:21 [INFO]\t[TRAIN] Epoch 236 finished, loss=0.029923335 .\n",
      "2022-07-06 19:10:29 [INFO]\t[TRAIN] Epoch=237/500, Step=6/39, loss=0.032376, lr=0.000500, time_each_step=1.12s, eta=3:12:54\n",
      "2022-07-06 19:10:38 [INFO]\t[TRAIN] Epoch=237/500, Step=16/39, loss=0.020257, lr=0.000500, time_each_step=0.85s, eta=2:26:44\n",
      "2022-07-06 19:10:46 [INFO]\t[TRAIN] Epoch=237/500, Step=26/39, loss=0.036277, lr=0.000500, time_each_step=0.85s, eta=2:25:51\n",
      "2022-07-06 19:10:55 [INFO]\t[TRAIN] Epoch=237/500, Step=36/39, loss=0.016273, lr=0.000500, time_each_step=0.83s, eta=2:23:38\n",
      "2022-07-06 19:10:57 [INFO]\t[TRAIN] Epoch 237 finished, loss=0.029633144 .\n",
      "2022-07-06 19:11:06 [INFO]\t[TRAIN] Epoch=238/500, Step=7/39, loss=0.021793, lr=0.000500, time_each_step=1.08s, eta=3:6:7\n",
      "2022-07-06 19:11:14 [INFO]\t[TRAIN] Epoch=238/500, Step=17/39, loss=0.028289, lr=0.000500, time_each_step=0.84s, eta=2:24:12\n",
      "2022-07-06 19:11:22 [INFO]\t[TRAIN] Epoch=238/500, Step=27/39, loss=0.037669, lr=0.000500, time_each_step=0.83s, eta=2:23:23\n",
      "2022-07-06 19:11:31 [INFO]\t[TRAIN] Epoch=238/500, Step=37/39, loss=0.022735, lr=0.000500, time_each_step=0.83s, eta=2:22:50\n",
      "2022-07-06 19:11:32 [INFO]\t[TRAIN] Epoch 238 finished, loss=0.0289284 .\n",
      "2022-07-06 19:11:42 [INFO]\t[TRAIN] Epoch=239/500, Step=8/39, loss=0.026377, lr=0.000500, time_each_step=1.09s, eta=3:6:19\n",
      "2022-07-06 19:11:50 [INFO]\t[TRAIN] Epoch=239/500, Step=18/39, loss=0.035438, lr=0.000500, time_each_step=0.85s, eta=2:24:50\n",
      "2022-07-06 19:11:58 [INFO]\t[TRAIN] Epoch=239/500, Step=28/39, loss=0.039176, lr=0.000500, time_each_step=0.83s, eta=2:22:42\n",
      "2022-07-06 19:12:07 [INFO]\t[TRAIN] Epoch=239/500, Step=38/39, loss=0.027647, lr=0.000500, time_each_step=0.83s, eta=2:22:19\n",
      "2022-07-06 19:12:08 [INFO]\t[TRAIN] Epoch 239 finished, loss=0.030495146 .\n",
      "2022-07-06 19:12:18 [INFO]\t[TRAIN] Epoch=240/500, Step=9/39, loss=0.025066, lr=0.000500, time_each_step=1.09s, eta=3:5:26\n",
      "2022-07-06 19:12:26 [INFO]\t[TRAIN] Epoch=240/500, Step=19/39, loss=0.023360, lr=0.000500, time_each_step=0.84s, eta=2:22:36\n",
      "2022-07-06 19:12:34 [INFO]\t[TRAIN] Epoch=240/500, Step=29/39, loss=0.015728, lr=0.000500, time_each_step=0.84s, eta=2:23:18\n",
      "2022-07-06 19:12:43 [INFO]\t[TRAIN] Epoch=240/500, Step=39/39, loss=0.033348, lr=0.000500, time_each_step=0.83s, eta=2:21:43\n",
      "2022-07-06 19:12:43 [INFO]\t[TRAIN] Epoch 240 finished, loss=0.027826361 .\n",
      "2022-07-06 19:12:43 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 19:12:43 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 19:12:45 [INFO]\t[EVAL] Finished, Epoch=240, miou=0.885417, category_iou=[0.98842654 0.7824074 ], oacc=0.988889, category_acc=[0.99222519 0.91575459], kappa=0.872112, category_F1-score=[0.99417959 0.87792207] .\n",
      "2022-07-06 19:12:45 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_230, miou=0.8863611962354033\n",
      "2022-07-06 19:12:45 [INFO]\tModel saved in /home/aistudio/exp/epoch_240.\n",
      "2022-07-06 19:12:57 [INFO]\t[TRAIN] Epoch=241/500, Step=10/39, loss=0.025844, lr=0.000500, time_each_step=1.11s, eta=3:8:34\n",
      "2022-07-06 19:13:05 [INFO]\t[TRAIN] Epoch=241/500, Step=20/39, loss=0.020967, lr=0.000500, time_each_step=0.83s, eta=2:21:27\n",
      "2022-07-06 19:13:13 [INFO]\t[TRAIN] Epoch=241/500, Step=30/39, loss=0.027696, lr=0.000500, time_each_step=0.83s, eta=2:21:9\n",
      "2022-07-06 19:13:21 [INFO]\t[TRAIN] Epoch 241 finished, loss=0.028287215 .\n",
      "2022-07-06 19:13:24 [INFO]\t[TRAIN] Epoch=242/500, Step=1/39, loss=0.035249, lr=0.000500, time_each_step=1.09s, eta=3:4:9\n",
      "2022-07-06 19:13:34 [INFO]\t[TRAIN] Epoch=242/500, Step=11/39, loss=0.016832, lr=0.000500, time_each_step=0.98s, eta=2:45:32\n",
      "2022-07-06 19:13:43 [INFO]\t[TRAIN] Epoch=242/500, Step=21/39, loss=0.027690, lr=0.000500, time_each_step=0.84s, eta=2:21:35\n",
      "2022-07-06 19:13:51 [INFO]\t[TRAIN] Epoch=242/500, Step=31/39, loss=0.049845, lr=0.000500, time_each_step=0.84s, eta=2:21:18\n",
      "2022-07-06 19:13:58 [INFO]\t[TRAIN] Epoch 242 finished, loss=0.029248552 .\n",
      "2022-07-06 19:14:02 [INFO]\t[TRAIN] Epoch=243/500, Step=2/39, loss=0.018451, lr=0.000500, time_each_step=1.08s, eta=3:1:10\n",
      "2022-07-06 19:14:10 [INFO]\t[TRAIN] Epoch=243/500, Step=12/39, loss=0.027767, lr=0.000500, time_each_step=0.84s, eta=2:21:59\n",
      "2022-07-06 19:14:19 [INFO]\t[TRAIN] Epoch=243/500, Step=22/39, loss=0.025928, lr=0.000500, time_each_step=0.83s, eta=2:20:13\n",
      "2022-07-06 19:14:27 [INFO]\t[TRAIN] Epoch=243/500, Step=32/39, loss=0.027593, lr=0.000500, time_each_step=0.84s, eta=2:20:30\n",
      "2022-07-06 19:14:33 [INFO]\t[TRAIN] Epoch 243 finished, loss=0.029203411 .\n",
      "2022-07-06 19:14:38 [INFO]\t[TRAIN] Epoch=244/500, Step=3/39, loss=0.041341, lr=0.000500, time_each_step=1.09s, eta=3:3:6\n",
      "2022-07-06 19:14:47 [INFO]\t[TRAIN] Epoch=244/500, Step=13/39, loss=0.034759, lr=0.000500, time_each_step=0.87s, eta=2:25:48\n",
      "2022-07-06 19:14:55 [INFO]\t[TRAIN] Epoch=244/500, Step=23/39, loss=0.032232, lr=0.000500, time_each_step=0.84s, eta=2:20:20\n",
      "2022-07-06 19:15:03 [INFO]\t[TRAIN] Epoch=244/500, Step=33/39, loss=0.023385, lr=0.000500, time_each_step=0.83s, eta=2:19:39\n",
      "2022-07-06 19:15:09 [INFO]\t[TRAIN] Epoch 244 finished, loss=0.028915605 .\n",
      "2022-07-06 19:15:16 [INFO]\t[TRAIN] Epoch=245/500, Step=4/39, loss=0.037790, lr=0.000500, time_each_step=1.2s, eta=3:21:4\n",
      "2022-07-06 19:15:24 [INFO]\t[TRAIN] Epoch=245/500, Step=14/39, loss=0.023921, lr=0.000500, time_each_step=0.84s, eta=2:20:2\n",
      "2022-07-06 19:15:32 [INFO]\t[TRAIN] Epoch=245/500, Step=24/39, loss=0.018739, lr=0.000500, time_each_step=0.83s, eta=2:19:11\n",
      "2022-07-06 19:15:41 [INFO]\t[TRAIN] Epoch=245/500, Step=34/39, loss=0.027653, lr=0.000500, time_each_step=0.83s, eta=2:18:50\n",
      "2022-07-06 19:15:45 [INFO]\t[TRAIN] Epoch 245 finished, loss=0.029156256 .\n",
      "2022-07-06 19:15:52 [INFO]\t[TRAIN] Epoch=246/500, Step=5/39, loss=0.028068, lr=0.000500, time_each_step=1.09s, eta=3:0:58\n",
      "2022-07-06 19:16:00 [INFO]\t[TRAIN] Epoch=246/500, Step=15/39, loss=0.039661, lr=0.000500, time_each_step=0.85s, eta=2:21:34\n",
      "2022-07-06 19:16:09 [INFO]\t[TRAIN] Epoch=246/500, Step=25/39, loss=0.021524, lr=0.000500, time_each_step=0.83s, eta=2:18:40\n",
      "2022-07-06 19:16:17 [INFO]\t[TRAIN] Epoch=246/500, Step=35/39, loss=0.024150, lr=0.000500, time_each_step=0.83s, eta=2:18:44\n",
      "2022-07-06 19:16:20 [INFO]\t[TRAIN] Epoch 246 finished, loss=0.026836801 .\n",
      "2022-07-06 19:16:28 [INFO]\t[TRAIN] Epoch=247/500, Step=6/39, loss=0.030521, lr=0.000500, time_each_step=1.08s, eta=2:59:5\n",
      "2022-07-06 19:16:36 [INFO]\t[TRAIN] Epoch=247/500, Step=16/39, loss=0.030371, lr=0.000500, time_each_step=0.84s, eta=2:18:51\n",
      "2022-07-06 19:16:45 [INFO]\t[TRAIN] Epoch=247/500, Step=26/39, loss=0.020710, lr=0.000500, time_each_step=0.84s, eta=2:18:30\n",
      "2022-07-06 19:16:53 [INFO]\t[TRAIN] Epoch=247/500, Step=36/39, loss=0.025772, lr=0.000500, time_each_step=0.84s, eta=2:18:52\n",
      "2022-07-06 19:16:56 [INFO]\t[TRAIN] Epoch 247 finished, loss=0.028805975 .\n",
      "2022-07-06 19:17:04 [INFO]\t[TRAIN] Epoch=248/500, Step=7/39, loss=0.032756, lr=0.000500, time_each_step=1.14s, eta=3:7:59\n",
      "2022-07-06 19:17:13 [INFO]\t[TRAIN] Epoch=248/500, Step=17/39, loss=0.024877, lr=0.000500, time_each_step=0.85s, eta=2:20:12\n",
      "2022-07-06 19:17:21 [INFO]\t[TRAIN] Epoch=248/500, Step=27/39, loss=0.028429, lr=0.000500, time_each_step=0.84s, eta=2:18:10\n",
      "2022-07-06 19:17:30 [INFO]\t[TRAIN] Epoch=248/500, Step=37/39, loss=0.042613, lr=0.000500, time_each_step=0.83s, eta=2:17:18\n",
      "2022-07-06 19:17:32 [INFO]\t[TRAIN] Epoch 248 finished, loss=0.027910175 .\n",
      "2022-07-06 19:17:41 [INFO]\t[TRAIN] Epoch=249/500, Step=8/39, loss=0.038787, lr=0.000500, time_each_step=1.1s, eta=3:0:32\n",
      "2022-07-06 19:17:49 [INFO]\t[TRAIN] Epoch=249/500, Step=18/39, loss=0.033197, lr=0.000500, time_each_step=0.84s, eta=2:17:49\n",
      "2022-07-06 19:17:58 [INFO]\t[TRAIN] Epoch=249/500, Step=28/39, loss=0.021566, lr=0.000500, time_each_step=0.84s, eta=2:18:24\n",
      "2022-07-06 19:18:06 [INFO]\t[TRAIN] Epoch=249/500, Step=38/39, loss=0.023958, lr=0.000500, time_each_step=0.83s, eta=2:16:28\n",
      "2022-07-06 19:18:07 [INFO]\t[TRAIN] Epoch 249 finished, loss=0.028276917 .\n",
      "2022-07-06 19:18:17 [INFO]\t[TRAIN] Epoch=250/500, Step=9/39, loss=0.032353, lr=0.000500, time_each_step=1.1s, eta=3:0:46\n",
      "2022-07-06 19:18:25 [INFO]\t[TRAIN] Epoch=250/500, Step=19/39, loss=0.019994, lr=0.000500, time_each_step=0.84s, eta=2:17:1\n",
      "2022-07-06 19:18:34 [INFO]\t[TRAIN] Epoch=250/500, Step=29/39, loss=0.028467, lr=0.000500, time_each_step=0.83s, eta=2:16:13\n",
      "2022-07-06 19:18:42 [INFO]\t[TRAIN] Epoch=250/500, Step=39/39, loss=0.036640, lr=0.000500, time_each_step=0.83s, eta=2:15:44\n",
      "2022-07-06 19:18:42 [INFO]\t[TRAIN] Epoch 250 finished, loss=0.027215637 .\n",
      "2022-07-06 19:18:42 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 19:18:42 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 19:18:44 [INFO]\t[EVAL] Finished, Epoch=250, miou=0.888606, category_iou=[0.98855365 0.788658  ], oacc=0.989023, category_acc=[0.9932697  0.89996187], kappa=0.876090, category_F1-score=[0.99424388 0.88184326] .\n",
      "2022-07-06 19:18:45 [INFO]\tModel saved in /home/aistudio/exp/best_model.\n",
      "2022-07-06 19:18:45 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_250, miou=0.8886058229283059\n",
      "2022-07-06 19:18:45 [INFO]\tModel saved in /home/aistudio/exp/epoch_250.\n",
      "2022-07-06 19:18:56 [INFO]\t[TRAIN] Epoch=251/500, Step=10/39, loss=0.013233, lr=0.000500, time_each_step=1.1s, eta=2:59:34\n",
      "2022-07-06 19:19:05 [INFO]\t[TRAIN] Epoch=251/500, Step=20/39, loss=0.032113, lr=0.000500, time_each_step=0.85s, eta=2:18:38\n",
      "2022-07-06 19:19:13 [INFO]\t[TRAIN] Epoch=251/500, Step=30/39, loss=0.017103, lr=0.000500, time_each_step=0.84s, eta=2:17:31\n",
      "2022-07-06 19:19:21 [INFO]\t[TRAIN] Epoch 251 finished, loss=0.027348815 .\n",
      "2022-07-06 19:19:24 [INFO]\t[TRAIN] Epoch=252/500, Step=1/39, loss=0.022168, lr=0.000500, time_each_step=1.09s, eta=2:58:5\n",
      "2022-07-06 19:19:33 [INFO]\t[TRAIN] Epoch=252/500, Step=11/39, loss=0.029951, lr=0.000500, time_each_step=0.86s, eta=2:20:24\n",
      "2022-07-06 19:19:41 [INFO]\t[TRAIN] Epoch=252/500, Step=21/39, loss=0.042665, lr=0.000500, time_each_step=0.83s, eta=2:15:32\n",
      "2022-07-06 19:19:49 [INFO]\t[TRAIN] Epoch=252/500, Step=31/39, loss=0.020455, lr=0.000500, time_each_step=0.83s, eta=2:15:22\n",
      "2022-07-06 19:19:56 [INFO]\t[TRAIN] Epoch 252 finished, loss=0.027174715 .\n",
      "2022-07-06 19:20:01 [INFO]\t[TRAIN] Epoch=253/500, Step=2/39, loss=0.023484, lr=0.000500, time_each_step=1.12s, eta=3:1:7\n",
      "2022-07-06 19:20:09 [INFO]\t[TRAIN] Epoch=253/500, Step=12/39, loss=0.008185, lr=0.000500, time_each_step=0.86s, eta=2:18:48\n",
      "2022-07-06 19:20:18 [INFO]\t[TRAIN] Epoch=253/500, Step=22/39, loss=0.031529, lr=0.000500, time_each_step=0.84s, eta=2:16:8\n",
      "2022-07-06 19:20:26 [INFO]\t[TRAIN] Epoch=253/500, Step=32/39, loss=0.024917, lr=0.000500, time_each_step=0.83s, eta=2:14:44\n",
      "2022-07-06 19:20:32 [INFO]\t[TRAIN] Epoch 253 finished, loss=0.027623964 .\n",
      "2022-07-06 19:20:37 [INFO]\t[TRAIN] Epoch=254/500, Step=3/39, loss=0.025666, lr=0.000500, time_each_step=1.08s, eta=2:53:37\n",
      "2022-07-06 19:20:45 [INFO]\t[TRAIN] Epoch=254/500, Step=13/39, loss=0.045711, lr=0.000500, time_each_step=0.86s, eta=2:18:15\n",
      "2022-07-06 19:20:54 [INFO]\t[TRAIN] Epoch=254/500, Step=23/39, loss=0.015596, lr=0.000500, time_each_step=0.83s, eta=2:14:43\n",
      "2022-07-06 19:21:02 [INFO]\t[TRAIN] Epoch=254/500, Step=33/39, loss=0.014567, lr=0.000500, time_each_step=0.84s, eta=2:14:42\n",
      "2022-07-06 19:21:07 [INFO]\t[TRAIN] Epoch 254 finished, loss=0.026811685 .\n",
      "2022-07-06 19:21:13 [INFO]\t[TRAIN] Epoch=255/500, Step=4/39, loss=0.019107, lr=0.000500, time_each_step=1.07s, eta=2:52:21\n",
      "2022-07-06 19:21:21 [INFO]\t[TRAIN] Epoch=255/500, Step=14/39, loss=0.020288, lr=0.000500, time_each_step=0.86s, eta=2:18:20\n",
      "2022-07-06 19:21:30 [INFO]\t[TRAIN] Epoch=255/500, Step=24/39, loss=0.021267, lr=0.000500, time_each_step=0.83s, eta=2:13:53\n",
      "2022-07-06 19:21:38 [INFO]\t[TRAIN] Epoch=255/500, Step=34/39, loss=0.038547, lr=0.000500, time_each_step=0.83s, eta=2:13:41\n",
      "2022-07-06 19:21:42 [INFO]\t[TRAIN] Epoch 255 finished, loss=0.026812239 .\n",
      "2022-07-06 19:21:49 [INFO]\t[TRAIN] Epoch=256/500, Step=5/39, loss=0.026935, lr=0.000500, time_each_step=1.1s, eta=2:55:23\n",
      "2022-07-06 19:21:58 [INFO]\t[TRAIN] Epoch=256/500, Step=15/39, loss=0.019922, lr=0.000500, time_each_step=0.84s, eta=2:14:13\n",
      "2022-07-06 19:22:06 [INFO]\t[TRAIN] Epoch=256/500, Step=25/39, loss=0.038210, lr=0.000500, time_each_step=0.84s, eta=2:13:39\n",
      "2022-07-06 19:22:14 [INFO]\t[TRAIN] Epoch=256/500, Step=35/39, loss=0.028532, lr=0.000500, time_each_step=0.83s, eta=2:13:26\n",
      "2022-07-06 19:22:18 [INFO]\t[TRAIN] Epoch 256 finished, loss=0.027155576 .\n",
      "2022-07-06 19:22:25 [INFO]\t[TRAIN] Epoch=257/500, Step=6/39, loss=0.016460, lr=0.000500, time_each_step=1.09s, eta=2:53:47\n",
      "2022-07-06 19:22:34 [INFO]\t[TRAIN] Epoch=257/500, Step=16/39, loss=0.022946, lr=0.000500, time_each_step=0.85s, eta=2:14:50\n",
      "2022-07-06 19:22:42 [INFO]\t[TRAIN] Epoch=257/500, Step=26/39, loss=0.022143, lr=0.000500, time_each_step=0.83s, eta=2:12:41\n",
      "2022-07-06 19:22:50 [INFO]\t[TRAIN] Epoch=257/500, Step=36/39, loss=0.028492, lr=0.000500, time_each_step=0.84s, eta=2:13:7\n",
      "2022-07-06 19:22:53 [INFO]\t[TRAIN] Epoch 257 finished, loss=0.02650998 .\n",
      "2022-07-06 19:23:01 [INFO]\t[TRAIN] Epoch=258/500, Step=7/39, loss=0.022151, lr=0.000500, time_each_step=1.08s, eta=2:51:26\n",
      "2022-07-06 19:23:10 [INFO]\t[TRAIN] Epoch=258/500, Step=17/39, loss=0.045347, lr=0.000500, time_each_step=0.84s, eta=2:13:28\n",
      "2022-07-06 19:23:18 [INFO]\t[TRAIN] Epoch=258/500, Step=27/39, loss=0.034250, lr=0.000500, time_each_step=0.84s, eta=2:13:16\n",
      "2022-07-06 19:23:27 [INFO]\t[TRAIN] Epoch=258/500, Step=37/39, loss=0.025849, lr=0.000500, time_each_step=0.83s, eta=2:12:6\n",
      "2022-07-06 19:23:28 [INFO]\t[TRAIN] Epoch 258 finished, loss=0.028301697 .\n",
      "2022-07-06 19:23:38 [INFO]\t[TRAIN] Epoch=259/500, Step=8/39, loss=0.018554, lr=0.000500, time_each_step=1.12s, eta=2:57:29\n",
      "2022-07-06 19:23:46 [INFO]\t[TRAIN] Epoch=259/500, Step=18/39, loss=0.016430, lr=0.000500, time_each_step=0.83s, eta=2:11:46\n",
      "2022-07-06 19:23:55 [INFO]\t[TRAIN] Epoch=259/500, Step=28/39, loss=0.034405, lr=0.000500, time_each_step=0.85s, eta=2:14:2\n",
      "2022-07-06 19:24:03 [INFO]\t[TRAIN] Epoch=259/500, Step=38/39, loss=0.032646, lr=0.000500, time_each_step=0.83s, eta=2:11:27\n",
      "2022-07-06 19:24:04 [INFO]\t[TRAIN] Epoch 259 finished, loss=0.02768282 .\n",
      "2022-07-06 19:24:14 [INFO]\t[TRAIN] Epoch=260/500, Step=9/39, loss=0.022798, lr=0.000500, time_each_step=1.09s, eta=2:50:47\n",
      "2022-07-06 19:24:22 [INFO]\t[TRAIN] Epoch=260/500, Step=19/39, loss=0.034566, lr=0.000500, time_each_step=0.85s, eta=2:13:16\n",
      "2022-07-06 19:24:31 [INFO]\t[TRAIN] Epoch=260/500, Step=29/39, loss=0.021174, lr=0.000500, time_each_step=0.84s, eta=2:12:5\n",
      "2022-07-06 19:24:39 [INFO]\t[TRAIN] Epoch=260/500, Step=39/39, loss=0.036833, lr=0.000500, time_each_step=0.83s, eta=2:10:57\n",
      "2022-07-06 19:24:39 [INFO]\t[TRAIN] Epoch 260 finished, loss=0.027971769 .\n",
      "2022-07-06 19:24:39 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 19:24:39 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 19:24:41 [INFO]\t[EVAL] Finished, Epoch=260, miou=0.888657, category_iou=[0.98863745 0.78867672], oacc=0.989100, category_acc=[0.99297759 0.90655995], kappa=0.876146, category_F1-score=[0.99428627 0.88185496] .\n",
      "2022-07-06 19:24:42 [INFO]\tModel saved in /home/aistudio/exp/best_model.\n",
      "2022-07-06 19:24:42 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_260, miou=0.8886570872738304\n",
      "2022-07-06 19:24:42 [INFO]\tModel saved in /home/aistudio/exp/epoch_260.\n",
      "2022-07-06 19:24:53 [INFO]\t[TRAIN] Epoch=261/500, Step=10/39, loss=0.023901, lr=0.000500, time_each_step=1.09s, eta=2:51:25\n",
      "2022-07-06 19:25:01 [INFO]\t[TRAIN] Epoch=261/500, Step=20/39, loss=0.033189, lr=0.000500, time_each_step=0.84s, eta=2:11:12\n",
      "2022-07-06 19:25:10 [INFO]\t[TRAIN] Epoch=261/500, Step=30/39, loss=0.021791, lr=0.000500, time_each_step=0.84s, eta=2:11:3\n",
      "2022-07-06 19:25:17 [INFO]\t[TRAIN] Epoch 261 finished, loss=0.028725157 .\n",
      "2022-07-06 19:25:21 [INFO]\t[TRAIN] Epoch=262/500, Step=1/39, loss=0.030698, lr=0.000500, time_each_step=1.11s, eta=2:53:30\n",
      "2022-07-06 19:25:30 [INFO]\t[TRAIN] Epoch=262/500, Step=11/39, loss=0.033469, lr=0.000500, time_each_step=0.85s, eta=2:12:58\n",
      "2022-07-06 19:25:38 [INFO]\t[TRAIN] Epoch=262/500, Step=21/39, loss=0.018250, lr=0.000500, time_each_step=0.84s, eta=2:10:46\n",
      "2022-07-06 19:25:46 [INFO]\t[TRAIN] Epoch=262/500, Step=31/39, loss=0.014863, lr=0.000500, time_each_step=0.83s, eta=2:10:3\n",
      "2022-07-06 19:25:53 [INFO]\t[TRAIN] Epoch 262 finished, loss=0.028370906 .\n",
      "2022-07-06 19:25:57 [INFO]\t[TRAIN] Epoch=263/500, Step=2/39, loss=0.035252, lr=0.000500, time_each_step=1.07s, eta=2:46:15\n",
      "2022-07-06 19:26:06 [INFO]\t[TRAIN] Epoch=263/500, Step=12/39, loss=0.034248, lr=0.000500, time_each_step=0.85s, eta=2:11:39\n",
      "2022-07-06 19:26:14 [INFO]\t[TRAIN] Epoch=263/500, Step=22/39, loss=0.008103, lr=0.000500, time_each_step=0.83s, eta=2:9:42\n",
      "2022-07-06 19:26:22 [INFO]\t[TRAIN] Epoch=263/500, Step=32/39, loss=0.046558, lr=0.000500, time_each_step=0.84s, eta=2:10:58\n",
      "2022-07-06 19:26:28 [INFO]\t[TRAIN] Epoch 263 finished, loss=0.027460828 .\n",
      "2022-07-06 19:26:33 [INFO]\t[TRAIN] Epoch=264/500, Step=3/39, loss=0.017702, lr=0.000500, time_each_step=1.08s, eta=2:47:28\n",
      "2022-07-06 19:26:42 [INFO]\t[TRAIN] Epoch=264/500, Step=13/39, loss=0.011070, lr=0.000500, time_each_step=0.89s, eta=2:17:16\n",
      "2022-07-06 19:26:51 [INFO]\t[TRAIN] Epoch=264/500, Step=23/39, loss=0.031357, lr=0.000500, time_each_step=0.84s, eta=2:10:40\n",
      "2022-07-06 19:26:59 [INFO]\t[TRAIN] Epoch=264/500, Step=33/39, loss=0.032884, lr=0.000500, time_each_step=0.84s, eta=2:9:22\n",
      "2022-07-06 19:27:04 [INFO]\t[TRAIN] Epoch 264 finished, loss=0.02689126 .\n",
      "2022-07-06 19:27:10 [INFO]\t[TRAIN] Epoch=265/500, Step=4/39, loss=0.024801, lr=0.000500, time_each_step=1.11s, eta=2:51:53\n",
      "2022-07-06 19:27:19 [INFO]\t[TRAIN] Epoch=265/500, Step=14/39, loss=0.033162, lr=0.000500, time_each_step=0.85s, eta=2:10:39\n",
      "2022-07-06 19:27:27 [INFO]\t[TRAIN] Epoch=265/500, Step=24/39, loss=0.019096, lr=0.000500, time_each_step=0.84s, eta=2:10:0\n",
      "2022-07-06 19:27:35 [INFO]\t[TRAIN] Epoch=265/500, Step=34/39, loss=0.035254, lr=0.000500, time_each_step=0.84s, eta=2:9:4\n",
      "2022-07-06 19:27:40 [INFO]\t[TRAIN] Epoch 265 finished, loss=0.02840721 .\n",
      "2022-07-06 19:27:47 [INFO]\t[TRAIN] Epoch=266/500, Step=5/39, loss=0.028366, lr=0.000500, time_each_step=1.14s, eta=2:54:41\n",
      "2022-07-06 19:27:55 [INFO]\t[TRAIN] Epoch=266/500, Step=15/39, loss=0.013769, lr=0.000500, time_each_step=0.84s, eta=2:8:23\n",
      "2022-07-06 19:28:04 [INFO]\t[TRAIN] Epoch=266/500, Step=25/39, loss=0.026072, lr=0.000500, time_each_step=0.84s, eta=2:8:37\n",
      "2022-07-06 19:28:12 [INFO]\t[TRAIN] Epoch=266/500, Step=35/39, loss=0.022449, lr=0.000500, time_each_step=0.83s, eta=2:7:48\n",
      "2022-07-06 19:28:16 [INFO]\t[TRAIN] Epoch 266 finished, loss=0.026528822 .\n",
      "2022-07-06 19:28:23 [INFO]\t[TRAIN] Epoch=267/500, Step=6/39, loss=0.016081, lr=0.000500, time_each_step=1.11s, eta=2:49:40\n",
      "2022-07-06 19:28:32 [INFO]\t[TRAIN] Epoch=267/500, Step=16/39, loss=0.032986, lr=0.000500, time_each_step=0.87s, eta=2:13:14\n",
      "2022-07-06 19:28:40 [INFO]\t[TRAIN] Epoch=267/500, Step=26/39, loss=0.010074, lr=0.000500, time_each_step=0.83s, eta=2:7:21\n",
      "2022-07-06 19:28:49 [INFO]\t[TRAIN] Epoch=267/500, Step=36/39, loss=0.012639, lr=0.000500, time_each_step=0.83s, eta=2:7:10\n",
      "2022-07-06 19:28:51 [INFO]\t[TRAIN] Epoch 267 finished, loss=0.027410565 .\n",
      "2022-07-06 19:29:00 [INFO]\t[TRAIN] Epoch=268/500, Step=7/39, loss=0.038100, lr=0.000500, time_each_step=1.09s, eta=2:45:57\n",
      "2022-07-06 19:29:08 [INFO]\t[TRAIN] Epoch=268/500, Step=17/39, loss=0.022294, lr=0.000500, time_each_step=0.85s, eta=2:9:27\n",
      "2022-07-06 19:29:17 [INFO]\t[TRAIN] Epoch=268/500, Step=27/39, loss=0.022503, lr=0.000500, time_each_step=0.83s, eta=2:6:58\n",
      "2022-07-06 19:29:25 [INFO]\t[TRAIN] Epoch=268/500, Step=37/39, loss=0.041009, lr=0.000500, time_each_step=0.84s, eta=2:6:56\n",
      "2022-07-06 19:29:27 [INFO]\t[TRAIN] Epoch 268 finished, loss=0.025714811 .\n",
      "2022-07-06 19:29:36 [INFO]\t[TRAIN] Epoch=269/500, Step=8/39, loss=0.028698, lr=0.000500, time_each_step=1.1s, eta=2:46:25\n",
      "2022-07-06 19:29:45 [INFO]\t[TRAIN] Epoch=269/500, Step=18/39, loss=0.021615, lr=0.000500, time_each_step=0.85s, eta=2:8:22\n",
      "2022-07-06 19:29:53 [INFO]\t[TRAIN] Epoch=269/500, Step=28/39, loss=0.023694, lr=0.000500, time_each_step=0.84s, eta=2:6:46\n",
      "2022-07-06 19:30:01 [INFO]\t[TRAIN] Epoch=269/500, Step=38/39, loss=0.034391, lr=0.000500, time_each_step=0.83s, eta=2:6:11\n",
      "2022-07-06 19:30:02 [INFO]\t[TRAIN] Epoch 269 finished, loss=0.028122097 .\n",
      "2022-07-06 19:30:12 [INFO]\t[TRAIN] Epoch=270/500, Step=9/39, loss=0.019037, lr=0.000500, time_each_step=1.09s, eta=2:43:46\n",
      "2022-07-06 19:30:21 [INFO]\t[TRAIN] Epoch=270/500, Step=19/39, loss=0.018898, lr=0.000500, time_each_step=0.83s, eta=2:5:50\n",
      "2022-07-06 19:30:29 [INFO]\t[TRAIN] Epoch=270/500, Step=29/39, loss=0.027839, lr=0.000500, time_each_step=0.83s, eta=2:5:36\n",
      "2022-07-06 19:30:37 [INFO]\t[TRAIN] Epoch=270/500, Step=39/39, loss=0.033114, lr=0.000500, time_each_step=0.83s, eta=2:5:30\n",
      "2022-07-06 19:30:38 [INFO]\t[TRAIN] Epoch 270 finished, loss=0.027968507 .\n",
      "2022-07-06 19:30:38 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 19:30:38 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 19:30:40 [INFO]\t[EVAL] Finished, Epoch=270, miou=0.889807, category_iou=[0.98864298 0.79097177], oacc=0.989111, category_acc=[0.99351892 0.89750583], kappa=0.877578, category_F1-score=[0.99428906 0.88328781] .\n",
      "2022-07-06 19:30:40 [INFO]\tModel saved in /home/aistudio/exp/best_model.\n",
      "2022-07-06 19:30:40 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_270, miou=0.8898073759959635\n",
      "2022-07-06 19:30:40 [INFO]\tModel saved in /home/aistudio/exp/epoch_270.\n",
      "2022-07-06 19:30:51 [INFO]\t[TRAIN] Epoch=271/500, Step=10/39, loss=0.029802, lr=0.000500, time_each_step=1.09s, eta=2:43:41\n",
      "2022-07-06 19:31:00 [INFO]\t[TRAIN] Epoch=271/500, Step=20/39, loss=0.018880, lr=0.000500, time_each_step=0.85s, eta=2:7:21\n",
      "2022-07-06 19:31:08 [INFO]\t[TRAIN] Epoch=271/500, Step=30/39, loss=0.014927, lr=0.000500, time_each_step=0.84s, eta=2:5:41\n",
      "2022-07-06 19:31:16 [INFO]\t[TRAIN] Epoch 271 finished, loss=0.027777513 .\n",
      "2022-07-06 19:31:19 [INFO]\t[TRAIN] Epoch=272/500, Step=1/39, loss=0.023279, lr=0.000500, time_each_step=1.08s, eta=2:41:11\n",
      "2022-07-06 19:31:28 [INFO]\t[TRAIN] Epoch=272/500, Step=11/39, loss=0.024977, lr=0.000500, time_each_step=0.93s, eta=2:19:18\n",
      "2022-07-06 19:31:37 [INFO]\t[TRAIN] Epoch=272/500, Step=21/39, loss=0.038302, lr=0.000500, time_each_step=0.85s, eta=2:7:8\n",
      "2022-07-06 19:31:45 [INFO]\t[TRAIN] Epoch=272/500, Step=31/39, loss=0.033713, lr=0.000500, time_each_step=0.84s, eta=2:4:55\n",
      "2022-07-06 19:31:52 [INFO]\t[TRAIN] Epoch 272 finished, loss=0.028475557 .\n",
      "2022-07-06 19:31:57 [INFO]\t[TRAIN] Epoch=273/500, Step=2/39, loss=0.032724, lr=0.000500, time_each_step=1.12s, eta=2:47:8\n",
      "2022-07-06 19:32:05 [INFO]\t[TRAIN] Epoch=273/500, Step=12/39, loss=0.012284, lr=0.000500, time_each_step=0.86s, eta=2:7:35\n",
      "2022-07-06 19:32:13 [INFO]\t[TRAIN] Epoch=273/500, Step=22/39, loss=0.025850, lr=0.000500, time_each_step=0.83s, eta=2:4:4\n",
      "2022-07-06 19:32:22 [INFO]\t[TRAIN] Epoch=273/500, Step=32/39, loss=0.038919, lr=0.000500, time_each_step=0.84s, eta=2:4:17\n",
      "2022-07-06 19:32:28 [INFO]\t[TRAIN] Epoch 273 finished, loss=0.027913114 .\n",
      "2022-07-06 19:32:33 [INFO]\t[TRAIN] Epoch=274/500, Step=3/39, loss=0.045865, lr=0.000500, time_each_step=1.08s, eta=2:39:33\n",
      "2022-07-06 19:32:41 [INFO]\t[TRAIN] Epoch=274/500, Step=13/39, loss=0.024432, lr=0.000500, time_each_step=0.84s, eta=2:4:57\n",
      "2022-07-06 19:32:49 [INFO]\t[TRAIN] Epoch=274/500, Step=23/39, loss=0.019684, lr=0.000500, time_each_step=0.84s, eta=2:4:19\n",
      "2022-07-06 19:32:58 [INFO]\t[TRAIN] Epoch=274/500, Step=33/39, loss=0.031249, lr=0.000500, time_each_step=0.83s, eta=2:3:19\n",
      "2022-07-06 19:33:03 [INFO]\t[TRAIN] Epoch 274 finished, loss=0.02769698 .\n",
      "2022-07-06 19:33:09 [INFO]\t[TRAIN] Epoch=275/500, Step=4/39, loss=0.016397, lr=0.000500, time_each_step=1.12s, eta=2:46:2\n",
      "2022-07-06 19:33:18 [INFO]\t[TRAIN] Epoch=275/500, Step=14/39, loss=0.024356, lr=0.000500, time_each_step=0.84s, eta=2:4:32\n",
      "2022-07-06 19:33:26 [INFO]\t[TRAIN] Epoch=275/500, Step=24/39, loss=0.038425, lr=0.000500, time_each_step=0.83s, eta=2:3:8\n",
      "2022-07-06 19:33:34 [INFO]\t[TRAIN] Epoch=275/500, Step=34/39, loss=0.019350, lr=0.000500, time_each_step=0.83s, eta=2:2:48\n",
      "2022-07-06 19:33:39 [INFO]\t[TRAIN] Epoch 275 finished, loss=0.027743965 .\n",
      "2022-07-06 19:33:45 [INFO]\t[TRAIN] Epoch=276/500, Step=5/39, loss=0.031465, lr=0.000500, time_each_step=1.11s, eta=2:43:14\n",
      "2022-07-06 19:33:54 [INFO]\t[TRAIN] Epoch=276/500, Step=15/39, loss=0.046575, lr=0.000500, time_each_step=0.85s, eta=2:5:35\n",
      "2022-07-06 19:34:02 [INFO]\t[TRAIN] Epoch=276/500, Step=25/39, loss=0.023492, lr=0.000500, time_each_step=0.83s, eta=2:2:29\n",
      "2022-07-06 19:34:11 [INFO]\t[TRAIN] Epoch=276/500, Step=35/39, loss=0.030410, lr=0.000500, time_each_step=0.84s, eta=2:2:50\n",
      "2022-07-06 19:34:14 [INFO]\t[TRAIN] Epoch 276 finished, loss=0.02827044 .\n",
      "2022-07-06 19:34:22 [INFO]\t[TRAIN] Epoch=277/500, Step=6/39, loss=0.033907, lr=0.000500, time_each_step=1.08s, eta=2:38:34\n",
      "2022-07-06 19:34:30 [INFO]\t[TRAIN] Epoch=277/500, Step=16/39, loss=0.028219, lr=0.000500, time_each_step=0.84s, eta=2:3:28\n",
      "2022-07-06 19:34:38 [INFO]\t[TRAIN] Epoch=277/500, Step=26/39, loss=0.029812, lr=0.000500, time_each_step=0.83s, eta=2:1:47\n",
      "2022-07-06 19:34:47 [INFO]\t[TRAIN] Epoch=277/500, Step=36/39, loss=0.037592, lr=0.000500, time_each_step=0.83s, eta=2:1:39\n",
      "2022-07-06 19:34:49 [INFO]\t[TRAIN] Epoch 277 finished, loss=0.028238019 .\n",
      "2022-07-06 19:34:58 [INFO]\t[TRAIN] Epoch=278/500, Step=7/39, loss=0.029970, lr=0.000500, time_each_step=1.1s, eta=2:40:22\n",
      "2022-07-06 19:35:06 [INFO]\t[TRAIN] Epoch=278/500, Step=17/39, loss=0.021597, lr=0.000500, time_each_step=0.85s, eta=2:3:26\n",
      "2022-07-06 19:35:15 [INFO]\t[TRAIN] Epoch=278/500, Step=27/39, loss=0.012484, lr=0.000500, time_each_step=0.84s, eta=2:2:18\n",
      "2022-07-06 19:35:23 [INFO]\t[TRAIN] Epoch=278/500, Step=37/39, loss=0.011179, lr=0.000500, time_each_step=0.83s, eta=2:0:54\n",
      "2022-07-06 19:35:25 [INFO]\t[TRAIN] Epoch 278 finished, loss=0.026781382 .\n",
      "2022-07-06 19:35:34 [INFO]\t[TRAIN] Epoch=279/500, Step=8/39, loss=0.022069, lr=0.000500, time_each_step=1.08s, eta=2:37:2\n",
      "2022-07-06 19:35:43 [INFO]\t[TRAIN] Epoch=279/500, Step=18/39, loss=0.031524, lr=0.000500, time_each_step=0.84s, eta=2:1:58\n",
      "2022-07-06 19:35:51 [INFO]\t[TRAIN] Epoch=279/500, Step=28/39, loss=0.024673, lr=0.000500, time_each_step=0.84s, eta=2:1:52\n",
      "2022-07-06 19:35:59 [INFO]\t[TRAIN] Epoch=279/500, Step=38/39, loss=0.026388, lr=0.000500, time_each_step=0.83s, eta=2:0:41\n",
      "2022-07-06 19:36:00 [INFO]\t[TRAIN] Epoch 279 finished, loss=0.02809379 .\n",
      "2022-07-06 19:36:10 [INFO]\t[TRAIN] Epoch=280/500, Step=9/39, loss=0.020855, lr=0.000500, time_each_step=1.09s, eta=2:36:42\n",
      "2022-07-06 19:36:19 [INFO]\t[TRAIN] Epoch=280/500, Step=19/39, loss=0.015441, lr=0.000500, time_each_step=0.84s, eta=2:1:56\n",
      "2022-07-06 19:36:27 [INFO]\t[TRAIN] Epoch=280/500, Step=29/39, loss=0.038909, lr=0.000500, time_each_step=0.83s, eta=2:0:9\n",
      "2022-07-06 19:36:35 [INFO]\t[TRAIN] Epoch=280/500, Step=39/39, loss=0.043443, lr=0.000500, time_each_step=0.83s, eta=1:59:50\n",
      "2022-07-06 19:36:36 [INFO]\t[TRAIN] Epoch 280 finished, loss=0.028316254 .\n",
      "2022-07-06 19:36:36 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 19:36:36 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 19:36:38 [INFO]\t[EVAL] Finished, Epoch=280, miou=0.888471, category_iou=[0.98870387 0.78823834], oacc=0.989160, category_acc=[0.99263757 0.91386997], kappa=0.875908, category_F1-score=[0.99431985 0.88158085] .\n",
      "2022-07-06 19:36:38 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_270, miou=0.8898073759959635\n",
      "2022-07-06 19:36:38 [INFO]\tModel saved in /home/aistudio/exp/epoch_280.\n",
      "2022-07-06 19:36:49 [INFO]\t[TRAIN] Epoch=281/500, Step=10/39, loss=0.041965, lr=0.000500, time_each_step=1.09s, eta=2:36:39\n",
      "2022-07-06 19:36:57 [INFO]\t[TRAIN] Epoch=281/500, Step=20/39, loss=0.018941, lr=0.000500, time_each_step=0.83s, eta=1:59:27\n",
      "2022-07-06 19:37:06 [INFO]\t[TRAIN] Epoch=281/500, Step=30/39, loss=0.010658, lr=0.000500, time_each_step=0.85s, eta=2:1:52\n",
      "2022-07-06 19:37:13 [INFO]\t[TRAIN] Epoch 281 finished, loss=0.02763577 .\n",
      "2022-07-06 19:37:17 [INFO]\t[TRAIN] Epoch=282/500, Step=1/39, loss=0.025959, lr=0.000500, time_each_step=1.08s, eta=2:35:4\n",
      "2022-07-06 19:37:26 [INFO]\t[TRAIN] Epoch=282/500, Step=11/39, loss=0.054806, lr=0.000500, time_each_step=0.88s, eta=2:6:11\n",
      "2022-07-06 19:37:34 [INFO]\t[TRAIN] Epoch=282/500, Step=21/39, loss=0.036689, lr=0.000500, time_each_step=0.84s, eta=1:59:58\n",
      "2022-07-06 19:37:42 [INFO]\t[TRAIN] Epoch=282/500, Step=31/39, loss=0.017397, lr=0.000500, time_each_step=0.83s, eta=1:58:53\n",
      "2022-07-06 19:37:49 [INFO]\t[TRAIN] Epoch 282 finished, loss=0.028027663 .\n",
      "2022-07-06 19:37:53 [INFO]\t[TRAIN] Epoch=283/500, Step=2/39, loss=0.026708, lr=0.000500, time_each_step=1.1s, eta=2:36:51\n",
      "2022-07-06 19:38:02 [INFO]\t[TRAIN] Epoch=283/500, Step=12/39, loss=0.015446, lr=0.000500, time_each_step=0.85s, eta=2:1:1\n",
      "2022-07-06 19:38:10 [INFO]\t[TRAIN] Epoch=283/500, Step=22/39, loss=0.016114, lr=0.000500, time_each_step=0.84s, eta=1:58:48\n",
      "2022-07-06 19:38:19 [INFO]\t[TRAIN] Epoch=283/500, Step=32/39, loss=0.032142, lr=0.000500, time_each_step=0.83s, eta=1:58:27\n",
      "2022-07-06 19:38:25 [INFO]\t[TRAIN] Epoch 283 finished, loss=0.027113661 .\n",
      "2022-07-06 19:38:30 [INFO]\t[TRAIN] Epoch=284/500, Step=3/39, loss=0.034661, lr=0.000500, time_each_step=1.12s, eta=2:38:42\n",
      "2022-07-06 19:38:38 [INFO]\t[TRAIN] Epoch=284/500, Step=13/39, loss=0.041799, lr=0.000500, time_each_step=0.84s, eta=1:59:11\n",
      "2022-07-06 19:38:47 [INFO]\t[TRAIN] Epoch=284/500, Step=23/39, loss=0.027705, lr=0.000500, time_each_step=0.84s, eta=1:58:25\n",
      "2022-07-06 19:38:55 [INFO]\t[TRAIN] Epoch=284/500, Step=33/39, loss=0.019862, lr=0.000500, time_each_step=0.84s, eta=1:58:38\n",
      "2022-07-06 19:39:00 [INFO]\t[TRAIN] Epoch 284 finished, loss=0.027601132 .\n",
      "2022-07-06 19:39:06 [INFO]\t[TRAIN] Epoch=285/500, Step=4/39, loss=0.031771, lr=0.000500, time_each_step=1.08s, eta=2:32:6\n",
      "2022-07-06 19:39:15 [INFO]\t[TRAIN] Epoch=285/500, Step=14/39, loss=0.020566, lr=0.000500, time_each_step=0.86s, eta=2:0:49\n",
      "2022-07-06 19:39:23 [INFO]\t[TRAIN] Epoch=285/500, Step=24/39, loss=0.023168, lr=0.000500, time_each_step=0.83s, eta=1:57:22\n",
      "2022-07-06 19:39:31 [INFO]\t[TRAIN] Epoch=285/500, Step=34/39, loss=0.046313, lr=0.000500, time_each_step=0.84s, eta=1:58:8\n",
      "2022-07-06 19:39:36 [INFO]\t[TRAIN] Epoch 285 finished, loss=0.02895905 .\n",
      "2022-07-06 19:39:43 [INFO]\t[TRAIN] Epoch=286/500, Step=5/39, loss=0.028429, lr=0.000500, time_each_step=1.12s, eta=2:36:52\n",
      "2022-07-06 19:39:51 [INFO]\t[TRAIN] Epoch=286/500, Step=15/39, loss=0.027012, lr=0.000500, time_each_step=0.84s, eta=1:57:22\n",
      "2022-07-06 19:39:59 [INFO]\t[TRAIN] Epoch=286/500, Step=25/39, loss=0.026419, lr=0.000500, time_each_step=0.84s, eta=1:57:33\n",
      "2022-07-06 19:40:08 [INFO]\t[TRAIN] Epoch=286/500, Step=35/39, loss=0.039645, lr=0.000500, time_each_step=0.84s, eta=1:57:15\n",
      "2022-07-06 19:40:11 [INFO]\t[TRAIN] Epoch 286 finished, loss=0.027003428 .\n",
      "2022-07-06 19:40:19 [INFO]\t[TRAIN] Epoch=287/500, Step=6/39, loss=0.031982, lr=0.000500, time_each_step=1.14s, eta=2:38:33\n",
      "2022-07-06 19:40:28 [INFO]\t[TRAIN] Epoch=287/500, Step=16/39, loss=0.030475, lr=0.000500, time_each_step=0.85s, eta=1:58:7\n",
      "2022-07-06 19:40:36 [INFO]\t[TRAIN] Epoch=287/500, Step=26/39, loss=0.022244, lr=0.000500, time_each_step=0.84s, eta=1:56:46\n",
      "2022-07-06 19:40:44 [INFO]\t[TRAIN] Epoch=287/500, Step=36/39, loss=0.018857, lr=0.000500, time_each_step=0.83s, eta=1:56:9\n",
      "2022-07-06 19:40:47 [INFO]\t[TRAIN] Epoch 287 finished, loss=0.027583027 .\n",
      "2022-07-06 19:40:56 [INFO]\t[TRAIN] Epoch=288/500, Step=7/39, loss=0.021570, lr=0.000500, time_each_step=1.15s, eta=2:40:20\n",
      "2022-07-06 19:41:05 [INFO]\t[TRAIN] Epoch=288/500, Step=17/39, loss=0.036352, lr=0.000500, time_each_step=0.84s, eta=1:56:41\n",
      "2022-07-06 19:41:13 [INFO]\t[TRAIN] Epoch=288/500, Step=27/39, loss=0.025427, lr=0.000500, time_each_step=0.83s, eta=1:55:39\n",
      "2022-07-06 19:41:21 [INFO]\t[TRAIN] Epoch=288/500, Step=37/39, loss=0.027421, lr=0.000500, time_each_step=0.83s, eta=1:55:21\n",
      "2022-07-06 19:41:23 [INFO]\t[TRAIN] Epoch 288 finished, loss=0.028107027 .\n",
      "2022-07-06 19:41:32 [INFO]\t[TRAIN] Epoch=289/500, Step=8/39, loss=0.039647, lr=0.000500, time_each_step=1.1s, eta=2:31:47\n",
      "2022-07-06 19:41:41 [INFO]\t[TRAIN] Epoch=289/500, Step=18/39, loss=0.023812, lr=0.000500, time_each_step=0.86s, eta=1:58:27\n",
      "2022-07-06 19:41:49 [INFO]\t[TRAIN] Epoch=289/500, Step=28/39, loss=0.028974, lr=0.000500, time_each_step=0.84s, eta=1:55:39\n",
      "2022-07-06 19:41:58 [INFO]\t[TRAIN] Epoch=289/500, Step=38/39, loss=0.041875, lr=0.000500, time_each_step=0.83s, eta=1:54:49\n",
      "2022-07-06 19:41:58 [INFO]\t[TRAIN] Epoch 289 finished, loss=0.027718712 .\n",
      "2022-07-06 19:42:09 [INFO]\t[TRAIN] Epoch=290/500, Step=9/39, loss=0.037897, lr=0.000500, time_each_step=1.13s, eta=2:35:14\n",
      "2022-07-06 19:42:17 [INFO]\t[TRAIN] Epoch=290/500, Step=19/39, loss=0.033483, lr=0.000500, time_each_step=0.83s, eta=1:54:54\n",
      "2022-07-06 19:42:26 [INFO]\t[TRAIN] Epoch=290/500, Step=29/39, loss=0.030750, lr=0.000500, time_each_step=0.84s, eta=1:55:28\n",
      "2022-07-06 19:42:34 [INFO]\t[TRAIN] Epoch=290/500, Step=39/39, loss=0.018129, lr=0.000500, time_each_step=0.83s, eta=1:54:11\n",
      "2022-07-06 19:42:34 [INFO]\t[TRAIN] Epoch 290 finished, loss=0.028597279 .\n",
      "2022-07-06 19:42:34 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 19:42:34 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 19:42:36 [INFO]\t[EVAL] Finished, Epoch=290, miou=0.889380, category_iou=[0.98863271 0.79012801], oacc=0.989099, category_acc=[0.99334792 0.90015688], kappa=0.877048, category_F1-score=[0.99428387 0.88276146] .\n",
      "2022-07-06 19:42:36 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_270, miou=0.8898073759959635\n",
      "2022-07-06 19:42:37 [INFO]\tModel saved in /home/aistudio/exp/epoch_290.\n",
      "2022-07-06 19:42:48 [INFO]\t[TRAIN] Epoch=291/500, Step=10/39, loss=0.022237, lr=0.000500, time_each_step=1.14s, eta=2:35:26\n",
      "2022-07-06 19:42:56 [INFO]\t[TRAIN] Epoch=291/500, Step=20/39, loss=0.041823, lr=0.000500, time_each_step=0.84s, eta=1:55:4\n",
      "2022-07-06 19:43:05 [INFO]\t[TRAIN] Epoch=291/500, Step=30/39, loss=0.033554, lr=0.000500, time_each_step=0.84s, eta=1:55:28\n",
      "2022-07-06 19:43:12 [INFO]\t[TRAIN] Epoch 291 finished, loss=0.026946383 .\n",
      "2022-07-06 19:43:16 [INFO]\t[TRAIN] Epoch=292/500, Step=1/39, loss=0.018924, lr=0.000500, time_each_step=1.08s, eta=2:27:17\n",
      "2022-07-06 19:43:24 [INFO]\t[TRAIN] Epoch=292/500, Step=11/39, loss=0.035284, lr=0.000500, time_each_step=0.84s, eta=1:55:2\n",
      "2022-07-06 19:43:32 [INFO]\t[TRAIN] Epoch=292/500, Step=21/39, loss=0.049022, lr=0.000500, time_each_step=0.84s, eta=1:54:6\n",
      "2022-07-06 19:43:41 [INFO]\t[TRAIN] Epoch=292/500, Step=31/39, loss=0.016844, lr=0.000500, time_each_step=0.84s, eta=1:54:0\n",
      "2022-07-06 19:43:48 [INFO]\t[TRAIN] Epoch 292 finished, loss=0.028568424 .\n",
      "2022-07-06 19:43:52 [INFO]\t[TRAIN] Epoch=293/500, Step=2/39, loss=0.022891, lr=0.000500, time_each_step=1.08s, eta=2:26:4\n",
      "2022-07-06 19:44:00 [INFO]\t[TRAIN] Epoch=293/500, Step=12/39, loss=0.023275, lr=0.000500, time_each_step=0.85s, eta=1:55:40\n",
      "2022-07-06 19:44:09 [INFO]\t[TRAIN] Epoch=293/500, Step=22/39, loss=0.015604, lr=0.000500, time_each_step=0.84s, eta=1:53:32\n",
      "2022-07-06 19:44:17 [INFO]\t[TRAIN] Epoch=293/500, Step=32/39, loss=0.032332, lr=0.000500, time_each_step=0.83s, eta=1:52:52\n",
      "2022-07-06 19:44:23 [INFO]\t[TRAIN] Epoch 293 finished, loss=0.027872013 .\n",
      "2022-07-06 19:44:28 [INFO]\t[TRAIN] Epoch=294/500, Step=3/39, loss=0.037139, lr=0.000500, time_each_step=1.08s, eta=2:25:54\n",
      "2022-07-06 19:44:36 [INFO]\t[TRAIN] Epoch=294/500, Step=13/39, loss=0.034145, lr=0.000500, time_each_step=0.85s, eta=1:55:17\n",
      "2022-07-06 19:44:45 [INFO]\t[TRAIN] Epoch=294/500, Step=23/39, loss=0.023443, lr=0.000500, time_each_step=0.83s, eta=1:52:42\n",
      "2022-07-06 19:44:53 [INFO]\t[TRAIN] Epoch=294/500, Step=33/39, loss=0.027192, lr=0.000500, time_each_step=0.84s, eta=1:52:41\n",
      "2022-07-06 19:44:58 [INFO]\t[TRAIN] Epoch 294 finished, loss=0.028159657 .\n",
      "2022-07-06 19:45:04 [INFO]\t[TRAIN] Epoch=295/500, Step=4/39, loss=0.026539, lr=0.000500, time_each_step=1.07s, eta=2:24:24\n",
      "2022-07-06 19:45:12 [INFO]\t[TRAIN] Epoch=295/500, Step=14/39, loss=0.029862, lr=0.000500, time_each_step=0.85s, eta=1:53:59\n",
      "2022-07-06 19:45:21 [INFO]\t[TRAIN] Epoch=295/500, Step=24/39, loss=0.025294, lr=0.000500, time_each_step=0.84s, eta=1:52:18\n",
      "2022-07-06 19:45:29 [INFO]\t[TRAIN] Epoch=295/500, Step=34/39, loss=0.033786, lr=0.000500, time_each_step=0.84s, eta=1:52:13\n",
      "2022-07-06 19:45:33 [INFO]\t[TRAIN] Epoch 295 finished, loss=0.027183432 .\n",
      "2022-07-06 19:45:41 [INFO]\t[TRAIN] Epoch=296/500, Step=5/39, loss=0.050481, lr=0.000500, time_each_step=1.14s, eta=2:32:18\n",
      "2022-07-06 19:45:49 [INFO]\t[TRAIN] Epoch=296/500, Step=15/39, loss=0.025953, lr=0.000500, time_each_step=0.85s, eta=1:53:14\n",
      "2022-07-06 19:45:58 [INFO]\t[TRAIN] Epoch=296/500, Step=25/39, loss=0.030961, lr=0.000500, time_each_step=0.84s, eta=1:52:43\n",
      "2022-07-06 19:46:06 [INFO]\t[TRAIN] Epoch=296/500, Step=35/39, loss=0.020043, lr=0.000500, time_each_step=0.83s, eta=1:51:10\n",
      "2022-07-06 19:46:09 [INFO]\t[TRAIN] Epoch 296 finished, loss=0.02671758 .\n",
      "2022-07-06 19:46:17 [INFO]\t[TRAIN] Epoch=297/500, Step=6/39, loss=0.017011, lr=0.000500, time_each_step=1.14s, eta=2:31:48\n",
      "2022-07-06 19:46:26 [INFO]\t[TRAIN] Epoch=297/500, Step=16/39, loss=0.010368, lr=0.000500, time_each_step=0.85s, eta=1:52:42\n",
      "2022-07-06 19:46:35 [INFO]\t[TRAIN] Epoch=297/500, Step=26/39, loss=0.033479, lr=0.000500, time_each_step=0.86s, eta=1:54:6\n",
      "2022-07-06 19:46:43 [INFO]\t[TRAIN] Epoch=297/500, Step=36/39, loss=0.026761, lr=0.000500, time_each_step=0.84s, eta=1:51:35\n",
      "2022-07-06 19:46:46 [INFO]\t[TRAIN] Epoch 297 finished, loss=0.027073685 .\n",
      "2022-07-06 19:46:54 [INFO]\t[TRAIN] Epoch=298/500, Step=7/39, loss=0.022896, lr=0.000500, time_each_step=1.09s, eta=2:24:23\n",
      "2022-07-06 19:47:02 [INFO]\t[TRAIN] Epoch=298/500, Step=17/39, loss=0.037846, lr=0.000500, time_each_step=0.84s, eta=1:51:54\n",
      "2022-07-06 19:47:11 [INFO]\t[TRAIN] Epoch=298/500, Step=27/39, loss=0.032762, lr=0.000500, time_each_step=0.83s, eta=1:50:22\n",
      "2022-07-06 19:47:19 [INFO]\t[TRAIN] Epoch=298/500, Step=37/39, loss=0.021483, lr=0.000500, time_each_step=0.83s, eta=1:50:12\n",
      "2022-07-06 19:47:21 [INFO]\t[TRAIN] Epoch 298 finished, loss=0.026660552 .\n",
      "2022-07-06 19:47:30 [INFO]\t[TRAIN] Epoch=299/500, Step=8/39, loss=0.013255, lr=0.000500, time_each_step=1.1s, eta=2:24:41\n",
      "2022-07-06 19:47:39 [INFO]\t[TRAIN] Epoch=299/500, Step=18/39, loss=0.015887, lr=0.000500, time_each_step=0.84s, eta=1:50:17\n",
      "2022-07-06 19:47:47 [INFO]\t[TRAIN] Epoch=299/500, Step=28/39, loss=0.032172, lr=0.000500, time_each_step=0.85s, eta=1:51:35\n",
      "2022-07-06 19:47:55 [INFO]\t[TRAIN] Epoch=299/500, Step=38/39, loss=0.026000, lr=0.000500, time_each_step=0.83s, eta=1:49:19\n",
      "2022-07-06 19:47:56 [INFO]\t[TRAIN] Epoch 299 finished, loss=0.027541965 .\n",
      "2022-07-06 19:48:07 [INFO]\t[TRAIN] Epoch=300/500, Step=9/39, loss=0.016416, lr=0.000500, time_each_step=1.14s, eta=2:30:1\n",
      "2022-07-06 19:48:15 [INFO]\t[TRAIN] Epoch=300/500, Step=19/39, loss=0.029301, lr=0.000500, time_each_step=0.84s, eta=1:50:9\n",
      "2022-07-06 19:48:24 [INFO]\t[TRAIN] Epoch=300/500, Step=29/39, loss=0.020991, lr=0.000500, time_each_step=0.83s, eta=1:49:8\n",
      "2022-07-06 19:48:32 [INFO]\t[TRAIN] Epoch=300/500, Step=39/39, loss=0.011308, lr=0.000500, time_each_step=0.83s, eta=1:48:55\n",
      "2022-07-06 19:48:32 [INFO]\t[TRAIN] Epoch 300 finished, loss=0.025678825 .\n",
      "2022-07-06 19:48:32 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 19:48:32 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 19:48:34 [INFO]\t[EVAL] Finished, Epoch=300, miou=0.887562, category_iou=[0.98869251 0.78643221], oacc=0.989145, category_acc=[0.99224906 0.92074019], kappa=0.874776, category_F1-score=[0.99431411 0.8804501 ] .\n",
      "2022-07-06 19:48:34 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_270, miou=0.8898073759959635\n",
      "2022-07-06 19:48:35 [INFO]\tModel saved in /home/aistudio/exp/epoch_300.\n",
      "2022-07-06 19:48:46 [INFO]\t[TRAIN] Epoch=301/500, Step=10/39, loss=0.032790, lr=0.000500, time_each_step=1.11s, eta=2:24:14\n",
      "2022-07-06 19:48:54 [INFO]\t[TRAIN] Epoch=301/500, Step=20/39, loss=0.025411, lr=0.000500, time_each_step=0.85s, eta=1:50:49\n",
      "2022-07-06 19:49:03 [INFO]\t[TRAIN] Epoch=301/500, Step=30/39, loss=0.034019, lr=0.000500, time_each_step=0.84s, eta=1:48:58\n",
      "2022-07-06 19:49:10 [INFO]\t[TRAIN] Epoch 301 finished, loss=0.027395653 .\n",
      "2022-07-06 19:49:14 [INFO]\t[TRAIN] Epoch=302/500, Step=1/39, loss=0.030379, lr=0.000500, time_each_step=1.08s, eta=2:19:49\n",
      "2022-07-06 19:49:22 [INFO]\t[TRAIN] Epoch=302/500, Step=11/39, loss=0.023908, lr=0.000500, time_each_step=0.85s, eta=1:50:57\n",
      "2022-07-06 19:49:30 [INFO]\t[TRAIN] Epoch=302/500, Step=21/39, loss=0.028811, lr=0.000500, time_each_step=0.84s, eta=1:48:28\n",
      "2022-07-06 19:49:39 [INFO]\t[TRAIN] Epoch=302/500, Step=31/39, loss=0.033218, lr=0.000500, time_each_step=0.83s, eta=1:47:59\n",
      "2022-07-06 19:49:46 [INFO]\t[TRAIN] Epoch 302 finished, loss=0.026705746 .\n",
      "2022-07-06 19:49:50 [INFO]\t[TRAIN] Epoch=303/500, Step=2/39, loss=0.028378, lr=0.000500, time_each_step=1.12s, eta=2:25:18\n",
      "2022-07-06 19:49:59 [INFO]\t[TRAIN] Epoch=303/500, Step=12/39, loss=0.017160, lr=0.000500, time_each_step=0.84s, eta=1:49:10\n",
      "2022-07-06 19:50:07 [INFO]\t[TRAIN] Epoch=303/500, Step=22/39, loss=0.016429, lr=0.000500, time_each_step=0.84s, eta=1:48:26\n",
      "2022-07-06 19:50:15 [INFO]\t[TRAIN] Epoch=303/500, Step=32/39, loss=0.035163, lr=0.000500, time_each_step=0.84s, eta=1:47:51\n",
      "2022-07-06 19:50:22 [INFO]\t[TRAIN] Epoch 303 finished, loss=0.026092295 .\n",
      "2022-07-06 19:50:27 [INFO]\t[TRAIN] Epoch=304/500, Step=3/39, loss=0.031033, lr=0.000500, time_each_step=1.08s, eta=2:19:7\n",
      "2022-07-06 19:50:35 [INFO]\t[TRAIN] Epoch=304/500, Step=13/39, loss=0.016405, lr=0.000500, time_each_step=0.85s, eta=1:48:56\n",
      "2022-07-06 19:50:43 [INFO]\t[TRAIN] Epoch=304/500, Step=23/39, loss=0.019029, lr=0.000500, time_each_step=0.83s, eta=1:47:0\n",
      "2022-07-06 19:50:52 [INFO]\t[TRAIN] Epoch=304/500, Step=33/39, loss=0.032437, lr=0.000500, time_each_step=0.84s, eta=1:47:13\n",
      "2022-07-06 19:50:57 [INFO]\t[TRAIN] Epoch 304 finished, loss=0.028092962 .\n",
      "2022-07-06 19:51:03 [INFO]\t[TRAIN] Epoch=305/500, Step=4/39, loss=0.021682, lr=0.000500, time_each_step=1.08s, eta=2:18:1\n",
      "2022-07-06 19:51:11 [INFO]\t[TRAIN] Epoch=305/500, Step=14/39, loss=0.036534, lr=0.000500, time_each_step=0.85s, eta=1:48:13\n",
      "2022-07-06 19:51:19 [INFO]\t[TRAIN] Epoch=305/500, Step=24/39, loss=0.033124, lr=0.000500, time_each_step=0.84s, eta=1:46:43\n",
      "2022-07-06 19:51:28 [INFO]\t[TRAIN] Epoch=305/500, Step=34/39, loss=0.029368, lr=0.000500, time_each_step=0.84s, eta=1:47:34\n",
      "2022-07-06 19:51:32 [INFO]\t[TRAIN] Epoch 305 finished, loss=0.027769819 .\n",
      "2022-07-06 19:51:39 [INFO]\t[TRAIN] Epoch=306/500, Step=5/39, loss=0.030788, lr=0.000500, time_each_step=1.09s, eta=2:18:15\n",
      "2022-07-06 19:51:47 [INFO]\t[TRAIN] Epoch=306/500, Step=15/39, loss=0.042148, lr=0.000500, time_each_step=0.84s, eta=1:47:29\n",
      "2022-07-06 19:51:56 [INFO]\t[TRAIN] Epoch=306/500, Step=25/39, loss=0.017095, lr=0.000500, time_each_step=0.84s, eta=1:46:36\n",
      "2022-07-06 19:52:04 [INFO]\t[TRAIN] Epoch=306/500, Step=35/39, loss=0.029260, lr=0.000500, time_each_step=0.84s, eta=1:46:17\n",
      "2022-07-06 19:52:08 [INFO]\t[TRAIN] Epoch 306 finished, loss=0.027540136 .\n",
      "2022-07-06 19:52:15 [INFO]\t[TRAIN] Epoch=307/500, Step=6/39, loss=0.026737, lr=0.000500, time_each_step=1.1s, eta=2:18:39\n",
      "2022-07-06 19:52:24 [INFO]\t[TRAIN] Epoch=307/500, Step=16/39, loss=0.028424, lr=0.000500, time_each_step=0.85s, eta=1:47:50\n",
      "2022-07-06 19:52:32 [INFO]\t[TRAIN] Epoch=307/500, Step=26/39, loss=0.023923, lr=0.000500, time_each_step=0.84s, eta=1:46:33\n",
      "2022-07-06 19:52:40 [INFO]\t[TRAIN] Epoch=307/500, Step=36/39, loss=0.020633, lr=0.000500, time_each_step=0.84s, eta=1:45:29\n",
      "2022-07-06 19:52:43 [INFO]\t[TRAIN] Epoch 307 finished, loss=0.02685524 .\n",
      "2022-07-06 19:52:52 [INFO]\t[TRAIN] Epoch=308/500, Step=7/39, loss=0.019605, lr=0.000500, time_each_step=1.09s, eta=2:17:7\n",
      "2022-07-06 19:53:00 [INFO]\t[TRAIN] Epoch=308/500, Step=17/39, loss=0.035318, lr=0.000500, time_each_step=0.84s, eta=1:45:40\n",
      "2022-07-06 19:53:08 [INFO]\t[TRAIN] Epoch=308/500, Step=27/39, loss=0.020060, lr=0.000500, time_each_step=0.84s, eta=1:45:45\n",
      "2022-07-06 19:53:17 [INFO]\t[TRAIN] Epoch=308/500, Step=37/39, loss=0.013512, lr=0.000500, time_each_step=0.83s, eta=1:44:32\n",
      "2022-07-06 19:53:18 [INFO]\t[TRAIN] Epoch 308 finished, loss=0.027153477 .\n",
      "2022-07-06 19:53:29 [INFO]\t[TRAIN] Epoch=309/500, Step=8/39, loss=0.036235, lr=0.000500, time_each_step=1.2s, eta=2:30:8\n",
      "2022-07-06 19:53:37 [INFO]\t[TRAIN] Epoch=309/500, Step=18/39, loss=0.015267, lr=0.000500, time_each_step=0.84s, eta=1:44:50\n",
      "2022-07-06 19:53:46 [INFO]\t[TRAIN] Epoch=309/500, Step=28/39, loss=0.027612, lr=0.000500, time_each_step=0.84s, eta=1:44:54\n",
      "2022-07-06 19:53:54 [INFO]\t[TRAIN] Epoch=309/500, Step=38/39, loss=0.040594, lr=0.000500, time_each_step=0.83s, eta=1:44:15\n",
      "2022-07-06 19:53:55 [INFO]\t[TRAIN] Epoch 309 finished, loss=0.02752525 .\n",
      "2022-07-06 19:54:05 [INFO]\t[TRAIN] Epoch=310/500, Step=9/39, loss=0.026963, lr=0.000500, time_each_step=1.15s, eta=2:22:48\n",
      "2022-07-06 19:54:14 [INFO]\t[TRAIN] Epoch=310/500, Step=19/39, loss=0.044275, lr=0.000500, time_each_step=0.84s, eta=1:44:11\n",
      "2022-07-06 19:54:22 [INFO]\t[TRAIN] Epoch=310/500, Step=29/39, loss=0.018656, lr=0.000500, time_each_step=0.84s, eta=1:44:34\n",
      "2022-07-06 19:54:31 [INFO]\t[TRAIN] Epoch=310/500, Step=39/39, loss=0.029873, lr=0.000500, time_each_step=0.84s, eta=1:44:4\n",
      "2022-07-06 19:54:31 [INFO]\t[TRAIN] Epoch 310 finished, loss=0.026759237 .\n",
      "2022-07-06 19:54:31 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 19:54:31 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 19:54:33 [INFO]\t[EVAL] Finished, Epoch=310, miou=0.891801, category_iou=[0.98881068 0.79479164], oacc=0.989275, category_acc=[0.99386425 0.89499067], kappa=0.880039, category_F1-score=[0.99437387 0.88566452] .\n",
      "2022-07-06 19:54:33 [INFO]\tModel saved in /home/aistudio/exp/best_model.\n",
      "2022-07-06 19:54:33 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_310, miou=0.8918011632689018\n",
      "2022-07-06 19:54:34 [INFO]\tModel saved in /home/aistudio/exp/epoch_310.\n",
      "2022-07-06 19:54:45 [INFO]\t[TRAIN] Epoch=311/500, Step=10/39, loss=0.028116, lr=0.000500, time_each_step=1.09s, eta=2:14:53\n",
      "2022-07-06 19:54:53 [INFO]\t[TRAIN] Epoch=311/500, Step=20/39, loss=0.022129, lr=0.000500, time_each_step=0.84s, eta=1:43:42\n",
      "2022-07-06 19:55:01 [INFO]\t[TRAIN] Epoch=311/500, Step=30/39, loss=0.028495, lr=0.000500, time_each_step=0.83s, eta=1:43:14\n",
      "2022-07-06 19:55:09 [INFO]\t[TRAIN] Epoch 311 finished, loss=0.028195867 .\n",
      "2022-07-06 19:55:12 [INFO]\t[TRAIN] Epoch=312/500, Step=1/39, loss=0.032364, lr=0.000500, time_each_step=1.1s, eta=2:16:27\n",
      "2022-07-06 19:55:21 [INFO]\t[TRAIN] Epoch=312/500, Step=11/39, loss=0.041873, lr=0.000500, time_each_step=0.87s, eta=1:46:53\n",
      "2022-07-06 19:55:29 [INFO]\t[TRAIN] Epoch=312/500, Step=21/39, loss=0.027859, lr=0.000500, time_each_step=0.84s, eta=1:43:40\n",
      "2022-07-06 19:55:38 [INFO]\t[TRAIN] Epoch=312/500, Step=31/39, loss=0.038358, lr=0.000500, time_each_step=0.84s, eta=1:43:14\n",
      "2022-07-06 19:55:45 [INFO]\t[TRAIN] Epoch 312 finished, loss=0.027215851 .\n",
      "2022-07-06 19:55:49 [INFO]\t[TRAIN] Epoch=313/500, Step=2/39, loss=0.024932, lr=0.000500, time_each_step=1.08s, eta=2:13:7\n",
      "2022-07-06 19:55:57 [INFO]\t[TRAIN] Epoch=313/500, Step=12/39, loss=0.029690, lr=0.000500, time_each_step=0.86s, eta=1:45:47\n",
      "2022-07-06 19:56:06 [INFO]\t[TRAIN] Epoch=313/500, Step=22/39, loss=0.034816, lr=0.000500, time_each_step=0.84s, eta=1:42:33\n",
      "2022-07-06 19:56:14 [INFO]\t[TRAIN] Epoch=313/500, Step=32/39, loss=0.012222, lr=0.000500, time_each_step=0.83s, eta=1:42:11\n",
      "2022-07-06 19:56:20 [INFO]\t[TRAIN] Epoch 313 finished, loss=0.02540278 .\n",
      "2022-07-06 19:56:25 [INFO]\t[TRAIN] Epoch=314/500, Step=3/39, loss=0.021101, lr=0.000500, time_each_step=1.07s, eta=2:11:19\n",
      "2022-07-06 19:56:34 [INFO]\t[TRAIN] Epoch=314/500, Step=13/39, loss=0.021925, lr=0.000500, time_each_step=0.86s, eta=1:44:49\n",
      "2022-07-06 19:56:42 [INFO]\t[TRAIN] Epoch=314/500, Step=23/39, loss=0.036212, lr=0.000500, time_each_step=0.85s, eta=1:43:36\n",
      "2022-07-06 19:56:50 [INFO]\t[TRAIN] Epoch=314/500, Step=33/39, loss=0.014498, lr=0.000500, time_each_step=0.83s, eta=1:41:36\n",
      "2022-07-06 19:56:55 [INFO]\t[TRAIN] Epoch 314 finished, loss=0.026193032 .\n",
      "2022-07-06 19:57:01 [INFO]\t[TRAIN] Epoch=315/500, Step=4/39, loss=0.028024, lr=0.000500, time_each_step=1.09s, eta=2:12:37\n",
      "2022-07-06 19:57:10 [INFO]\t[TRAIN] Epoch=315/500, Step=14/39, loss=0.030581, lr=0.000500, time_each_step=0.85s, eta=1:43:43\n",
      "2022-07-06 19:57:18 [INFO]\t[TRAIN] Epoch=315/500, Step=24/39, loss=0.046243, lr=0.000500, time_each_step=0.84s, eta=1:41:49\n",
      "2022-07-06 19:57:27 [INFO]\t[TRAIN] Epoch=315/500, Step=34/39, loss=0.035341, lr=0.000500, time_each_step=0.83s, eta=1:40:56\n",
      "2022-07-06 19:57:31 [INFO]\t[TRAIN] Epoch 315 finished, loss=0.026127394 .\n",
      "2022-07-06 19:57:38 [INFO]\t[TRAIN] Epoch=316/500, Step=5/39, loss=0.028058, lr=0.000500, time_each_step=1.11s, eta=2:14:25\n",
      "2022-07-06 19:57:46 [INFO]\t[TRAIN] Epoch=316/500, Step=15/39, loss=0.027033, lr=0.000500, time_each_step=0.85s, eta=1:42:56\n",
      "2022-07-06 19:57:55 [INFO]\t[TRAIN] Epoch=316/500, Step=25/39, loss=0.011219, lr=0.000500, time_each_step=0.83s, eta=1:40:40\n",
      "2022-07-06 19:58:03 [INFO]\t[TRAIN] Epoch=316/500, Step=35/39, loss=0.032383, lr=0.000500, time_each_step=0.84s, eta=1:40:50\n",
      "2022-07-06 19:58:07 [INFO]\t[TRAIN] Epoch 316 finished, loss=0.02640854 .\n",
      "2022-07-06 19:58:14 [INFO]\t[TRAIN] Epoch=317/500, Step=6/39, loss=0.014760, lr=0.000500, time_each_step=1.11s, eta=2:13:42\n",
      "2022-07-06 19:58:23 [INFO]\t[TRAIN] Epoch=317/500, Step=16/39, loss=0.031336, lr=0.000500, time_each_step=0.84s, eta=1:41:25\n",
      "2022-07-06 19:58:31 [INFO]\t[TRAIN] Epoch=317/500, Step=26/39, loss=0.022355, lr=0.000500, time_each_step=0.83s, eta=1:40:4\n",
      "2022-07-06 19:58:39 [INFO]\t[TRAIN] Epoch=317/500, Step=36/39, loss=0.020524, lr=0.000500, time_each_step=0.83s, eta=1:39:47\n",
      "2022-07-06 19:58:42 [INFO]\t[TRAIN] Epoch 317 finished, loss=0.026440367 .\n",
      "2022-07-06 19:58:50 [INFO]\t[TRAIN] Epoch=318/500, Step=7/39, loss=0.013181, lr=0.000500, time_each_step=1.08s, eta=2:8:55\n",
      "2022-07-06 19:58:59 [INFO]\t[TRAIN] Epoch=318/500, Step=17/39, loss=0.026236, lr=0.000500, time_each_step=0.84s, eta=1:40:11\n",
      "2022-07-06 19:59:07 [INFO]\t[TRAIN] Epoch=318/500, Step=27/39, loss=0.026613, lr=0.000500, time_each_step=0.83s, eta=1:39:22\n",
      "2022-07-06 19:59:16 [INFO]\t[TRAIN] Epoch=318/500, Step=37/39, loss=0.026708, lr=0.000500, time_each_step=0.85s, eta=1:41:43\n",
      "2022-07-06 19:59:17 [INFO]\t[TRAIN] Epoch 318 finished, loss=0.027515883 .\n",
      "2022-07-06 19:59:27 [INFO]\t[TRAIN] Epoch=319/500, Step=8/39, loss=0.027687, lr=0.000500, time_each_step=1.1s, eta=2:10:43\n",
      "2022-07-06 19:59:35 [INFO]\t[TRAIN] Epoch=319/500, Step=18/39, loss=0.034712, lr=0.000500, time_each_step=0.87s, eta=1:43:26\n",
      "2022-07-06 19:59:44 [INFO]\t[TRAIN] Epoch=319/500, Step=28/39, loss=0.018779, lr=0.000500, time_each_step=0.85s, eta=1:40:54\n",
      "2022-07-06 19:59:52 [INFO]\t[TRAIN] Epoch=319/500, Step=38/39, loss=0.019925, lr=0.000500, time_each_step=0.84s, eta=1:39:28\n",
      "2022-07-06 19:59:53 [INFO]\t[TRAIN] Epoch 319 finished, loss=0.026406065 .\n",
      "2022-07-06 20:00:03 [INFO]\t[TRAIN] Epoch=320/500, Step=9/39, loss=0.021219, lr=0.000500, time_each_step=1.09s, eta=2:8:43\n",
      "2022-07-06 20:00:12 [INFO]\t[TRAIN] Epoch=320/500, Step=19/39, loss=0.027894, lr=0.000500, time_each_step=0.83s, eta=1:38:34\n",
      "2022-07-06 20:00:20 [INFO]\t[TRAIN] Epoch=320/500, Step=29/39, loss=0.032131, lr=0.000500, time_each_step=0.84s, eta=1:38:42\n",
      "2022-07-06 20:00:28 [INFO]\t[TRAIN] Epoch=320/500, Step=39/39, loss=0.015657, lr=0.000500, time_each_step=0.83s, eta=1:38:3\n",
      "2022-07-06 20:00:28 [INFO]\t[TRAIN] Epoch 320 finished, loss=0.02721151 .\n",
      "2022-07-06 20:00:28 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 20:00:28 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 20:00:30 [INFO]\t[EVAL] Finished, Epoch=320, miou=0.890440, category_iou=[0.98878053 0.79209986], oacc=0.989240, category_acc=[0.99330189 0.90376242], kappa=0.878352, category_F1-score=[0.99435862 0.88399076] .\n",
      "2022-07-06 20:00:30 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_310, miou=0.8918011632689018\n",
      "2022-07-06 20:00:31 [INFO]\tModel saved in /home/aistudio/exp/epoch_320.\n",
      "2022-07-06 20:00:42 [INFO]\t[TRAIN] Epoch=321/500, Step=10/39, loss=0.021333, lr=0.000500, time_each_step=1.09s, eta=2:8:14\n",
      "2022-07-06 20:00:50 [INFO]\t[TRAIN] Epoch=321/500, Step=20/39, loss=0.021462, lr=0.000500, time_each_step=0.84s, eta=1:38:57\n",
      "2022-07-06 20:00:59 [INFO]\t[TRAIN] Epoch=321/500, Step=30/39, loss=0.032912, lr=0.000500, time_each_step=0.83s, eta=1:37:43\n",
      "2022-07-06 20:01:06 [INFO]\t[TRAIN] Epoch 321 finished, loss=0.026844624 .\n",
      "2022-07-06 20:01:09 [INFO]\t[TRAIN] Epoch=322/500, Step=1/39, loss=0.033552, lr=0.000500, time_each_step=1.07s, eta=2:4:47\n",
      "2022-07-06 20:01:18 [INFO]\t[TRAIN] Epoch=322/500, Step=11/39, loss=0.013504, lr=0.000500, time_each_step=0.85s, eta=1:39:19\n",
      "2022-07-06 20:01:26 [INFO]\t[TRAIN] Epoch=322/500, Step=21/39, loss=0.021781, lr=0.000500, time_each_step=0.83s, eta=1:37:14\n",
      "2022-07-06 20:01:35 [INFO]\t[TRAIN] Epoch=322/500, Step=31/39, loss=0.043743, lr=0.000500, time_each_step=0.84s, eta=1:37:55\n",
      "2022-07-06 20:01:41 [INFO]\t[TRAIN] Epoch 322 finished, loss=0.027613549 .\n",
      "2022-07-06 20:01:46 [INFO]\t[TRAIN] Epoch=323/500, Step=2/39, loss=0.023368, lr=0.000500, time_each_step=1.08s, eta=2:5:29\n",
      "2022-07-06 20:01:54 [INFO]\t[TRAIN] Epoch=323/500, Step=12/39, loss=0.013253, lr=0.000500, time_each_step=0.86s, eta=1:40:25\n",
      "2022-07-06 20:02:03 [INFO]\t[TRAIN] Epoch=323/500, Step=22/39, loss=0.020256, lr=0.000500, time_each_step=0.84s, eta=1:37:0\n",
      "2022-07-06 20:02:11 [INFO]\t[TRAIN] Epoch=323/500, Step=32/39, loss=0.019019, lr=0.000500, time_each_step=0.83s, eta=1:36:35\n",
      "2022-07-06 20:02:17 [INFO]\t[TRAIN] Epoch 323 finished, loss=0.025397867 .\n",
      "2022-07-06 20:02:22 [INFO]\t[TRAIN] Epoch=324/500, Step=3/39, loss=0.041676, lr=0.000500, time_each_step=1.09s, eta=2:6:23\n",
      "2022-07-06 20:02:30 [INFO]\t[TRAIN] Epoch=324/500, Step=13/39, loss=0.020543, lr=0.000500, time_each_step=0.85s, eta=1:37:45\n",
      "2022-07-06 20:02:39 [INFO]\t[TRAIN] Epoch=324/500, Step=23/39, loss=0.023209, lr=0.000500, time_each_step=0.84s, eta=1:37:2\n",
      "2022-07-06 20:02:47 [INFO]\t[TRAIN] Epoch=324/500, Step=33/39, loss=0.018551, lr=0.000500, time_each_step=0.83s, eta=1:35:58\n",
      "2022-07-06 20:02:52 [INFO]\t[TRAIN] Epoch 324 finished, loss=0.026373502 .\n",
      "2022-07-06 20:02:58 [INFO]\t[TRAIN] Epoch=325/500, Step=4/39, loss=0.041398, lr=0.000500, time_each_step=1.12s, eta=2:8:19\n",
      "2022-07-06 20:03:07 [INFO]\t[TRAIN] Epoch=325/500, Step=14/39, loss=0.027509, lr=0.000500, time_each_step=0.84s, eta=1:36:33\n",
      "2022-07-06 20:03:15 [INFO]\t[TRAIN] Epoch=325/500, Step=24/39, loss=0.046701, lr=0.000500, time_each_step=0.83s, eta=1:35:38\n",
      "2022-07-06 20:03:24 [INFO]\t[TRAIN] Epoch=325/500, Step=34/39, loss=0.036163, lr=0.000500, time_each_step=0.84s, eta=1:36:3\n",
      "2022-07-06 20:03:28 [INFO]\t[TRAIN] Epoch 325 finished, loss=0.02756956 .\n",
      "2022-07-06 20:03:35 [INFO]\t[TRAIN] Epoch=326/500, Step=5/39, loss=0.037066, lr=0.000500, time_each_step=1.09s, eta=2:4:17\n",
      "2022-07-06 20:03:43 [INFO]\t[TRAIN] Epoch=326/500, Step=15/39, loss=0.030875, lr=0.000500, time_each_step=0.85s, eta=1:37:1\n",
      "2022-07-06 20:03:51 [INFO]\t[TRAIN] Epoch=326/500, Step=25/39, loss=0.028738, lr=0.000500, time_each_step=0.83s, eta=1:35:3\n",
      "2022-07-06 20:04:00 [INFO]\t[TRAIN] Epoch=326/500, Step=35/39, loss=0.032847, lr=0.000500, time_each_step=0.84s, eta=1:35:10\n",
      "2022-07-06 20:04:03 [INFO]\t[TRAIN] Epoch 326 finished, loss=0.02698708 .\n",
      "2022-07-06 20:04:11 [INFO]\t[TRAIN] Epoch=327/500, Step=6/39, loss=0.014826, lr=0.000500, time_each_step=1.1s, eta=2:4:44\n",
      "2022-07-06 20:04:19 [INFO]\t[TRAIN] Epoch=327/500, Step=16/39, loss=0.016544, lr=0.000500, time_each_step=0.86s, eta=1:37:34\n",
      "2022-07-06 20:04:28 [INFO]\t[TRAIN] Epoch=327/500, Step=26/39, loss=0.033500, lr=0.000500, time_each_step=0.84s, eta=1:34:52\n",
      "2022-07-06 20:04:36 [INFO]\t[TRAIN] Epoch=327/500, Step=36/39, loss=0.031101, lr=0.000500, time_each_step=0.83s, eta=1:34:12\n",
      "2022-07-06 20:04:39 [INFO]\t[TRAIN] Epoch 327 finished, loss=0.026433744 .\n",
      "2022-07-06 20:04:47 [INFO]\t[TRAIN] Epoch=328/500, Step=7/39, loss=0.019869, lr=0.000500, time_each_step=1.09s, eta=2:3:3\n",
      "2022-07-06 20:04:56 [INFO]\t[TRAIN] Epoch=328/500, Step=17/39, loss=0.021933, lr=0.000500, time_each_step=0.84s, eta=1:34:33\n",
      "2022-07-06 20:05:04 [INFO]\t[TRAIN] Epoch=328/500, Step=27/39, loss=0.039637, lr=0.000500, time_each_step=0.87s, eta=1:38:15\n",
      "2022-07-06 20:05:13 [INFO]\t[TRAIN] Epoch=328/500, Step=37/39, loss=0.018709, lr=0.000500, time_each_step=0.83s, eta=1:33:39\n",
      "2022-07-06 20:05:14 [INFO]\t[TRAIN] Epoch 328 finished, loss=0.02595571 .\n",
      "2022-07-06 20:05:24 [INFO]\t[TRAIN] Epoch=329/500, Step=8/39, loss=0.021712, lr=0.000500, time_each_step=1.08s, eta=2:1:33\n",
      "2022-07-06 20:05:32 [INFO]\t[TRAIN] Epoch=329/500, Step=18/39, loss=0.024263, lr=0.000500, time_each_step=0.85s, eta=1:35:8\n",
      "2022-07-06 20:05:40 [INFO]\t[TRAIN] Epoch=329/500, Step=28/39, loss=0.034040, lr=0.000500, time_each_step=0.84s, eta=1:33:43\n",
      "2022-07-06 20:05:49 [INFO]\t[TRAIN] Epoch=329/500, Step=38/39, loss=0.026271, lr=0.000500, time_each_step=0.83s, eta=1:33:9\n",
      "2022-07-06 20:05:50 [INFO]\t[TRAIN] Epoch 329 finished, loss=0.0274854 .\n",
      "2022-07-06 20:06:00 [INFO]\t[TRAIN] Epoch=330/500, Step=9/39, loss=0.032512, lr=0.000500, time_each_step=1.11s, eta=2:3:24\n",
      "2022-07-06 20:06:08 [INFO]\t[TRAIN] Epoch=330/500, Step=19/39, loss=0.035016, lr=0.000500, time_each_step=0.85s, eta=1:34:31\n",
      "2022-07-06 20:06:17 [INFO]\t[TRAIN] Epoch=330/500, Step=29/39, loss=0.031083, lr=0.000500, time_each_step=0.84s, eta=1:33:11\n",
      "2022-07-06 20:06:25 [INFO]\t[TRAIN] Epoch=330/500, Step=39/39, loss=0.018620, lr=0.000500, time_each_step=0.83s, eta=1:32:39\n",
      "2022-07-06 20:06:25 [INFO]\t[TRAIN] Epoch 330 finished, loss=0.027068706 .\n",
      "2022-07-06 20:06:25 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 20:06:25 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 20:06:27 [INFO]\t[EVAL] Finished, Epoch=330, miou=0.890893, category_iou=[0.98888416 0.79290237], oacc=0.989338, category_acc=[0.99312426 0.90882686], kappa=0.878906, category_F1-score=[0.99441102 0.88449029] .\n",
      "2022-07-06 20:06:27 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_310, miou=0.8918011632689018\n",
      "2022-07-06 20:06:28 [INFO]\tModel saved in /home/aistudio/exp/epoch_330.\n",
      "2022-07-06 20:06:39 [INFO]\t[TRAIN] Epoch=331/500, Step=10/39, loss=0.018521, lr=0.000250, time_each_step=1.12s, eta=2:3:40\n",
      "2022-07-06 20:06:47 [INFO]\t[TRAIN] Epoch=331/500, Step=20/39, loss=0.019240, lr=0.000250, time_each_step=0.83s, eta=1:32:19\n",
      "2022-07-06 20:06:56 [INFO]\t[TRAIN] Epoch=331/500, Step=30/39, loss=0.023462, lr=0.000250, time_each_step=0.84s, eta=1:33:0\n",
      "2022-07-06 20:07:03 [INFO]\t[TRAIN] Epoch 331 finished, loss=0.026530052 .\n",
      "2022-07-06 20:07:06 [INFO]\t[TRAIN] Epoch=332/500, Step=1/39, loss=0.017040, lr=0.000250, time_each_step=1.07s, eta=1:58:19\n",
      "2022-07-06 20:07:15 [INFO]\t[TRAIN] Epoch=332/500, Step=11/39, loss=0.021602, lr=0.000250, time_each_step=0.85s, eta=1:34:13\n",
      "2022-07-06 20:07:23 [INFO]\t[TRAIN] Epoch=332/500, Step=21/39, loss=0.031291, lr=0.000250, time_each_step=0.84s, eta=1:32:11\n",
      "2022-07-06 20:07:32 [INFO]\t[TRAIN] Epoch=332/500, Step=31/39, loss=0.032430, lr=0.000250, time_each_step=0.84s, eta=1:31:54\n",
      "2022-07-06 20:07:39 [INFO]\t[TRAIN] Epoch 332 finished, loss=0.026379487 .\n",
      "2022-07-06 20:07:43 [INFO]\t[TRAIN] Epoch=333/500, Step=2/39, loss=0.035207, lr=0.000250, time_each_step=1.08s, eta=1:58:10\n",
      "2022-07-06 20:07:51 [INFO]\t[TRAIN] Epoch=333/500, Step=12/39, loss=0.032284, lr=0.000250, time_each_step=0.86s, eta=1:34:16\n",
      "2022-07-06 20:08:00 [INFO]\t[TRAIN] Epoch=333/500, Step=22/39, loss=0.016327, lr=0.000250, time_each_step=0.87s, eta=1:34:59\n",
      "2022-07-06 20:08:08 [INFO]\t[TRAIN] Epoch=333/500, Step=32/39, loss=0.029476, lr=0.000250, time_each_step=0.84s, eta=1:32:21\n",
      "2022-07-06 20:08:14 [INFO]\t[TRAIN] Epoch 333 finished, loss=0.028926214 .\n",
      "2022-07-06 20:08:19 [INFO]\t[TRAIN] Epoch=334/500, Step=3/39, loss=0.032265, lr=0.000250, time_each_step=1.1s, eta=1:59:50\n",
      "2022-07-06 20:08:28 [INFO]\t[TRAIN] Epoch=334/500, Step=13/39, loss=0.039584, lr=0.000250, time_each_step=0.85s, eta=1:32:38\n",
      "2022-07-06 20:08:36 [INFO]\t[TRAIN] Epoch=334/500, Step=23/39, loss=0.049233, lr=0.000250, time_each_step=0.84s, eta=1:31:41\n",
      "2022-07-06 20:08:45 [INFO]\t[TRAIN] Epoch=334/500, Step=33/39, loss=0.027191, lr=0.000250, time_each_step=0.84s, eta=1:30:57\n",
      "2022-07-06 20:08:50 [INFO]\t[TRAIN] Epoch 334 finished, loss=0.027213365 .\n",
      "2022-07-06 20:08:56 [INFO]\t[TRAIN] Epoch=335/500, Step=4/39, loss=0.036730, lr=0.000250, time_each_step=1.07s, eta=1:55:40\n",
      "2022-07-06 20:09:04 [INFO]\t[TRAIN] Epoch=335/500, Step=14/39, loss=0.023554, lr=0.000250, time_each_step=0.86s, eta=1:32:40\n",
      "2022-07-06 20:09:13 [INFO]\t[TRAIN] Epoch=335/500, Step=24/39, loss=0.028435, lr=0.000250, time_each_step=0.84s, eta=1:30:35\n",
      "2022-07-06 20:09:21 [INFO]\t[TRAIN] Epoch=335/500, Step=34/39, loss=0.026713, lr=0.000250, time_each_step=0.84s, eta=1:30:17\n",
      "2022-07-06 20:09:25 [INFO]\t[TRAIN] Epoch 335 finished, loss=0.026491543 .\n",
      "2022-07-06 20:09:32 [INFO]\t[TRAIN] Epoch=336/500, Step=5/39, loss=0.020468, lr=0.000250, time_each_step=1.07s, eta=1:55:7\n",
      "2022-07-06 20:09:40 [INFO]\t[TRAIN] Epoch=336/500, Step=15/39, loss=0.039074, lr=0.000250, time_each_step=0.85s, eta=1:31:47\n",
      "2022-07-06 20:09:49 [INFO]\t[TRAIN] Epoch=336/500, Step=25/39, loss=0.038851, lr=0.000250, time_each_step=0.83s, eta=1:29:40\n",
      "2022-07-06 20:09:57 [INFO]\t[TRAIN] Epoch=336/500, Step=35/39, loss=0.020459, lr=0.000250, time_each_step=0.83s, eta=1:29:20\n",
      "2022-07-06 20:10:00 [INFO]\t[TRAIN] Epoch 336 finished, loss=0.026653381 .\n",
      "2022-07-06 20:10:09 [INFO]\t[TRAIN] Epoch=337/500, Step=6/39, loss=0.023364, lr=0.000250, time_each_step=1.18s, eta=2:6:1\n",
      "2022-07-06 20:10:17 [INFO]\t[TRAIN] Epoch=337/500, Step=16/39, loss=0.039183, lr=0.000250, time_each_step=0.86s, eta=1:31:32\n",
      "2022-07-06 20:10:26 [INFO]\t[TRAIN] Epoch=337/500, Step=26/39, loss=0.022278, lr=0.000250, time_each_step=0.84s, eta=1:29:23\n",
      "2022-07-06 20:10:34 [INFO]\t[TRAIN] Epoch=337/500, Step=36/39, loss=0.036450, lr=0.000250, time_each_step=0.83s, eta=1:28:42\n",
      "2022-07-06 20:10:37 [INFO]\t[TRAIN] Epoch 337 finished, loss=0.026567364 .\n",
      "2022-07-06 20:10:45 [INFO]\t[TRAIN] Epoch=338/500, Step=7/39, loss=0.018574, lr=0.000250, time_each_step=1.09s, eta=1:55:39\n",
      "2022-07-06 20:10:54 [INFO]\t[TRAIN] Epoch=338/500, Step=17/39, loss=0.025788, lr=0.000250, time_each_step=0.84s, eta=1:29:36\n",
      "2022-07-06 20:11:02 [INFO]\t[TRAIN] Epoch=338/500, Step=27/39, loss=0.019558, lr=0.000250, time_each_step=0.83s, eta=1:28:32\n",
      "2022-07-06 20:11:10 [INFO]\t[TRAIN] Epoch=338/500, Step=37/39, loss=0.032477, lr=0.000250, time_each_step=0.83s, eta=1:28:9\n",
      "2022-07-06 20:11:12 [INFO]\t[TRAIN] Epoch 338 finished, loss=0.027331047 .\n",
      "2022-07-06 20:11:21 [INFO]\t[TRAIN] Epoch=339/500, Step=8/39, loss=0.025297, lr=0.000250, time_each_step=1.1s, eta=1:56:4\n",
      "2022-07-06 20:11:30 [INFO]\t[TRAIN] Epoch=339/500, Step=18/39, loss=0.024485, lr=0.000250, time_each_step=0.84s, eta=1:28:49\n",
      "2022-07-06 20:11:38 [INFO]\t[TRAIN] Epoch=339/500, Step=28/39, loss=0.024705, lr=0.000250, time_each_step=0.84s, eta=1:28:18\n",
      "2022-07-06 20:11:46 [INFO]\t[TRAIN] Epoch=339/500, Step=38/39, loss=0.047985, lr=0.000250, time_each_step=0.83s, eta=1:27:43\n",
      "2022-07-06 20:11:47 [INFO]\t[TRAIN] Epoch 339 finished, loss=0.027649885 .\n",
      "2022-07-06 20:11:57 [INFO]\t[TRAIN] Epoch=340/500, Step=9/39, loss=0.024412, lr=0.000250, time_each_step=1.09s, eta=1:54:13\n",
      "2022-07-06 20:12:06 [INFO]\t[TRAIN] Epoch=340/500, Step=19/39, loss=0.027760, lr=0.000250, time_each_step=0.84s, eta=1:27:53\n",
      "2022-07-06 20:12:14 [INFO]\t[TRAIN] Epoch=340/500, Step=29/39, loss=0.034271, lr=0.000250, time_each_step=0.85s, eta=1:28:41\n",
      "2022-07-06 20:12:23 [INFO]\t[TRAIN] Epoch=340/500, Step=39/39, loss=0.029686, lr=0.000250, time_each_step=0.84s, eta=1:27:22\n",
      "2022-07-06 20:12:23 [INFO]\t[TRAIN] Epoch 340 finished, loss=0.026438313 .\n",
      "2022-07-06 20:12:23 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 20:12:23 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 20:12:25 [INFO]\t[EVAL] Finished, Epoch=340, miou=0.891116, category_iou=[0.98884949 0.79338247], oacc=0.989307, category_acc=[0.99336909 0.90394475], kappa=0.879185, category_F1-score=[0.99439348 0.88478892] .\n",
      "2022-07-06 20:12:25 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_310, miou=0.8918011632689018\n",
      "2022-07-06 20:12:25 [INFO]\tModel saved in /home/aistudio/exp/epoch_340.\n",
      "2022-07-06 20:12:36 [INFO]\t[TRAIN] Epoch=341/500, Step=10/39, loss=0.032382, lr=0.000250, time_each_step=1.12s, eta=1:57:4\n",
      "2022-07-06 20:12:45 [INFO]\t[TRAIN] Epoch=341/500, Step=20/39, loss=0.015648, lr=0.000250, time_each_step=0.84s, eta=1:27:44\n",
      "2022-07-06 20:12:53 [INFO]\t[TRAIN] Epoch=341/500, Step=30/39, loss=0.025783, lr=0.000250, time_each_step=0.83s, eta=1:26:41\n",
      "2022-07-06 20:13:01 [INFO]\t[TRAIN] Epoch 341 finished, loss=0.027257232 .\n",
      "2022-07-06 20:13:04 [INFO]\t[TRAIN] Epoch=342/500, Step=1/39, loss=0.033955, lr=0.000250, time_each_step=1.07s, eta=1:50:59\n",
      "2022-07-06 20:13:12 [INFO]\t[TRAIN] Epoch=342/500, Step=11/39, loss=0.012204, lr=0.000250, time_each_step=0.85s, eta=1:27:47\n",
      "2022-07-06 20:13:21 [INFO]\t[TRAIN] Epoch=342/500, Step=21/39, loss=0.028287, lr=0.000250, time_each_step=0.84s, eta=1:26:55\n",
      "2022-07-06 20:13:29 [INFO]\t[TRAIN] Epoch=342/500, Step=31/39, loss=0.020678, lr=0.000250, time_each_step=0.85s, eta=1:28:12\n",
      "2022-07-06 20:13:36 [INFO]\t[TRAIN] Epoch 342 finished, loss=0.026646147 .\n",
      "2022-07-06 20:13:40 [INFO]\t[TRAIN] Epoch=343/500, Step=2/39, loss=0.036527, lr=0.000250, time_each_step=1.08s, eta=1:50:56\n",
      "2022-07-06 20:13:49 [INFO]\t[TRAIN] Epoch=343/500, Step=12/39, loss=0.019410, lr=0.000250, time_each_step=0.85s, eta=1:27:32\n",
      "2022-07-06 20:13:57 [INFO]\t[TRAIN] Epoch=343/500, Step=22/39, loss=0.035615, lr=0.000250, time_each_step=0.84s, eta=1:26:3\n",
      "2022-07-06 20:14:05 [INFO]\t[TRAIN] Epoch=343/500, Step=32/39, loss=0.026552, lr=0.000250, time_each_step=0.83s, eta=1:25:39\n",
      "2022-07-06 20:14:11 [INFO]\t[TRAIN] Epoch 343 finished, loss=0.025771135 .\n",
      "2022-07-06 20:14:16 [INFO]\t[TRAIN] Epoch=344/500, Step=3/39, loss=0.016074, lr=0.000250, time_each_step=1.08s, eta=1:50:30\n",
      "2022-07-06 20:14:25 [INFO]\t[TRAIN] Epoch=344/500, Step=13/39, loss=0.051220, lr=0.000250, time_each_step=0.86s, eta=1:27:40\n",
      "2022-07-06 20:14:33 [INFO]\t[TRAIN] Epoch=344/500, Step=23/39, loss=0.043870, lr=0.000250, time_each_step=0.83s, eta=1:25:20\n",
      "2022-07-06 20:14:42 [INFO]\t[TRAIN] Epoch=344/500, Step=33/39, loss=0.026257, lr=0.000250, time_each_step=0.85s, eta=1:26:18\n",
      "2022-07-06 20:14:47 [INFO]\t[TRAIN] Epoch 344 finished, loss=0.027161226 .\n",
      "2022-07-06 20:14:53 [INFO]\t[TRAIN] Epoch=345/500, Step=4/39, loss=0.023129, lr=0.000250, time_each_step=1.11s, eta=1:53:3\n",
      "2022-07-06 20:15:01 [INFO]\t[TRAIN] Epoch=345/500, Step=14/39, loss=0.033133, lr=0.000250, time_each_step=0.85s, eta=1:26:12\n",
      "2022-07-06 20:15:10 [INFO]\t[TRAIN] Epoch=345/500, Step=24/39, loss=0.036999, lr=0.000250, time_each_step=0.83s, eta=1:24:42\n",
      "2022-07-06 20:15:18 [INFO]\t[TRAIN] Epoch=345/500, Step=34/39, loss=0.036257, lr=0.000250, time_each_step=0.83s, eta=1:24:33\n",
      "2022-07-06 20:15:22 [INFO]\t[TRAIN] Epoch 345 finished, loss=0.025481384 .\n",
      "2022-07-06 20:15:29 [INFO]\t[TRAIN] Epoch=346/500, Step=5/39, loss=0.031316, lr=0.000250, time_each_step=1.1s, eta=1:50:50\n",
      "2022-07-06 20:15:38 [INFO]\t[TRAIN] Epoch=346/500, Step=15/39, loss=0.040325, lr=0.000250, time_each_step=0.85s, eta=1:25:54\n",
      "2022-07-06 20:15:46 [INFO]\t[TRAIN] Epoch=346/500, Step=25/39, loss=0.032145, lr=0.000250, time_each_step=0.84s, eta=1:24:51\n",
      "2022-07-06 20:15:54 [INFO]\t[TRAIN] Epoch=346/500, Step=35/39, loss=0.021372, lr=0.000250, time_each_step=0.83s, eta=1:23:58\n",
      "2022-07-06 20:15:58 [INFO]\t[TRAIN] Epoch 346 finished, loss=0.026414527 .\n",
      "2022-07-06 20:16:05 [INFO]\t[TRAIN] Epoch=347/500, Step=6/39, loss=0.023674, lr=0.000250, time_each_step=1.08s, eta=1:48:39\n",
      "2022-07-06 20:16:14 [INFO]\t[TRAIN] Epoch=347/500, Step=16/39, loss=0.031327, lr=0.000250, time_each_step=0.84s, eta=1:24:4\n",
      "2022-07-06 20:16:22 [INFO]\t[TRAIN] Epoch=347/500, Step=26/39, loss=0.040684, lr=0.000250, time_each_step=0.84s, eta=1:23:56\n",
      "2022-07-06 20:16:30 [INFO]\t[TRAIN] Epoch=347/500, Step=36/39, loss=0.026021, lr=0.000250, time_each_step=0.84s, eta=1:23:43\n",
      "2022-07-06 20:16:33 [INFO]\t[TRAIN] Epoch 347 finished, loss=0.025953522 .\n",
      "2022-07-06 20:16:41 [INFO]\t[TRAIN] Epoch=348/500, Step=7/39, loss=0.028239, lr=0.000250, time_each_step=1.09s, eta=1:49:6\n",
      "2022-07-06 20:16:50 [INFO]\t[TRAIN] Epoch=348/500, Step=17/39, loss=0.035209, lr=0.000250, time_each_step=0.86s, eta=1:25:51\n",
      "2022-07-06 20:16:58 [INFO]\t[TRAIN] Epoch=348/500, Step=27/39, loss=0.026522, lr=0.000250, time_each_step=0.84s, eta=1:23:23\n",
      "2022-07-06 20:17:07 [INFO]\t[TRAIN] Epoch=348/500, Step=37/39, loss=0.029455, lr=0.000250, time_each_step=0.83s, eta=1:22:44\n",
      "2022-07-06 20:17:09 [INFO]\t[TRAIN] Epoch 348 finished, loss=0.027071424 .\n",
      "2022-07-06 20:17:18 [INFO]\t[TRAIN] Epoch=349/500, Step=8/39, loss=0.016687, lr=0.000250, time_each_step=1.08s, eta=1:46:50\n",
      "2022-07-06 20:17:26 [INFO]\t[TRAIN] Epoch=349/500, Step=18/39, loss=0.035291, lr=0.000250, time_each_step=0.84s, eta=1:23:13\n",
      "2022-07-06 20:17:34 [INFO]\t[TRAIN] Epoch=349/500, Step=28/39, loss=0.025377, lr=0.000250, time_each_step=0.84s, eta=1:22:56\n",
      "2022-07-06 20:17:43 [INFO]\t[TRAIN] Epoch=349/500, Step=38/39, loss=0.015553, lr=0.000250, time_each_step=0.83s, eta=1:22:22\n",
      "2022-07-06 20:17:44 [INFO]\t[TRAIN] Epoch 349 finished, loss=0.026422748 .\n",
      "2022-07-06 20:17:54 [INFO]\t[TRAIN] Epoch=350/500, Step=9/39, loss=0.024050, lr=0.000250, time_each_step=1.09s, eta=1:47:15\n",
      "2022-07-06 20:18:02 [INFO]\t[TRAIN] Epoch=350/500, Step=19/39, loss=0.038638, lr=0.000250, time_each_step=0.84s, eta=1:22:59\n",
      "2022-07-06 20:18:11 [INFO]\t[TRAIN] Epoch=350/500, Step=29/39, loss=0.019051, lr=0.000250, time_each_step=0.83s, eta=1:21:57\n",
      "2022-07-06 20:18:19 [INFO]\t[TRAIN] Epoch=350/500, Step=39/39, loss=0.045587, lr=0.000250, time_each_step=0.84s, eta=1:22:5\n",
      "2022-07-06 20:18:19 [INFO]\t[TRAIN] Epoch 350 finished, loss=0.025886854 .\n",
      "2022-07-06 20:18:19 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 20:18:19 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 20:18:21 [INFO]\t[EVAL] Finished, Epoch=350, miou=0.891666, category_iou=[0.98889433 0.79443803], oacc=0.989351, category_acc=[0.99346809 0.90312629], kappa=0.879863, category_F1-score=[0.99441616 0.88544493] .\n",
      "2022-07-06 20:18:21 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_310, miou=0.8918011632689018\n",
      "2022-07-06 20:18:21 [INFO]\tModel saved in /home/aistudio/exp/epoch_350.\n",
      "2022-07-06 20:18:32 [INFO]\t[TRAIN] Epoch=351/500, Step=10/39, loss=0.011368, lr=0.000250, time_each_step=1.1s, eta=1:47:17\n",
      "2022-07-06 20:18:41 [INFO]\t[TRAIN] Epoch=351/500, Step=20/39, loss=0.030107, lr=0.000250, time_each_step=0.84s, eta=1:21:45\n",
      "2022-07-06 20:18:49 [INFO]\t[TRAIN] Epoch=351/500, Step=30/39, loss=0.037317, lr=0.000250, time_each_step=0.83s, eta=1:21:13\n",
      "2022-07-06 20:18:57 [INFO]\t[TRAIN] Epoch 351 finished, loss=0.026596393 .\n",
      "2022-07-06 20:19:00 [INFO]\t[TRAIN] Epoch=352/500, Step=1/39, loss=0.020639, lr=0.000250, time_each_step=1.1s, eta=1:46:34\n",
      "2022-07-06 20:19:09 [INFO]\t[TRAIN] Epoch=352/500, Step=11/39, loss=0.032391, lr=0.000250, time_each_step=0.85s, eta=1:22:9\n",
      "2022-07-06 20:19:17 [INFO]\t[TRAIN] Epoch=352/500, Step=21/39, loss=0.028692, lr=0.000250, time_each_step=0.83s, eta=1:21:2\n",
      "2022-07-06 20:19:25 [INFO]\t[TRAIN] Epoch=352/500, Step=31/39, loss=0.022745, lr=0.000250, time_each_step=0.83s, eta=1:20:44\n",
      "2022-07-06 20:19:32 [INFO]\t[TRAIN] Epoch 352 finished, loss=0.02665017 .\n",
      "2022-07-06 20:19:36 [INFO]\t[TRAIN] Epoch=353/500, Step=2/39, loss=0.028856, lr=0.000250, time_each_step=1.08s, eta=1:43:57\n",
      "2022-07-06 20:19:45 [INFO]\t[TRAIN] Epoch=353/500, Step=12/39, loss=0.019569, lr=0.000250, time_each_step=0.87s, eta=1:23:34\n",
      "2022-07-06 20:19:53 [INFO]\t[TRAIN] Epoch=353/500, Step=22/39, loss=0.017079, lr=0.000250, time_each_step=0.83s, eta=1:20:27\n",
      "2022-07-06 20:20:02 [INFO]\t[TRAIN] Epoch=353/500, Step=32/39, loss=0.041236, lr=0.000250, time_each_step=0.84s, eta=1:20:46\n",
      "2022-07-06 20:20:08 [INFO]\t[TRAIN] Epoch 353 finished, loss=0.02745375 .\n",
      "2022-07-06 20:20:13 [INFO]\t[TRAIN] Epoch=354/500, Step=3/39, loss=0.036794, lr=0.000250, time_each_step=1.08s, eta=1:43:58\n",
      "2022-07-06 20:20:21 [INFO]\t[TRAIN] Epoch=354/500, Step=13/39, loss=0.028597, lr=0.000250, time_each_step=0.84s, eta=1:20:44\n",
      "2022-07-06 20:20:29 [INFO]\t[TRAIN] Epoch=354/500, Step=23/39, loss=0.040617, lr=0.000250, time_each_step=0.84s, eta=1:20:2\n",
      "2022-07-06 20:20:38 [INFO]\t[TRAIN] Epoch=354/500, Step=33/39, loss=0.024029, lr=0.000250, time_each_step=0.84s, eta=1:20:9\n",
      "2022-07-06 20:20:43 [INFO]\t[TRAIN] Epoch 354 finished, loss=0.02732121 .\n",
      "2022-07-06 20:20:49 [INFO]\t[TRAIN] Epoch=355/500, Step=4/39, loss=0.026893, lr=0.000250, time_each_step=1.12s, eta=1:46:41\n",
      "2022-07-06 20:20:57 [INFO]\t[TRAIN] Epoch=355/500, Step=14/39, loss=0.017871, lr=0.000250, time_each_step=0.84s, eta=1:20:4\n",
      "2022-07-06 20:21:06 [INFO]\t[TRAIN] Epoch=355/500, Step=24/39, loss=0.021741, lr=0.000250, time_each_step=0.84s, eta=1:19:48\n",
      "2022-07-06 20:21:14 [INFO]\t[TRAIN] Epoch=355/500, Step=34/39, loss=0.024268, lr=0.000250, time_each_step=0.83s, eta=1:19:8\n",
      "2022-07-06 20:21:18 [INFO]\t[TRAIN] Epoch 355 finished, loss=0.025469992 .\n",
      "2022-07-06 20:21:25 [INFO]\t[TRAIN] Epoch=356/500, Step=5/39, loss=0.029509, lr=0.000250, time_each_step=1.08s, eta=1:42:13\n",
      "2022-07-06 20:21:34 [INFO]\t[TRAIN] Epoch=356/500, Step=15/39, loss=0.024406, lr=0.000250, time_each_step=0.84s, eta=1:19:42\n",
      "2022-07-06 20:21:42 [INFO]\t[TRAIN] Epoch=356/500, Step=25/39, loss=0.019144, lr=0.000250, time_each_step=0.83s, eta=1:18:34\n",
      "2022-07-06 20:21:50 [INFO]\t[TRAIN] Epoch=356/500, Step=35/39, loss=0.025276, lr=0.000250, time_each_step=0.83s, eta=1:18:30\n",
      "2022-07-06 20:21:54 [INFO]\t[TRAIN] Epoch 356 finished, loss=0.026000904 .\n",
      "2022-07-06 20:22:01 [INFO]\t[TRAIN] Epoch=357/500, Step=6/39, loss=0.017679, lr=0.000250, time_each_step=1.09s, eta=1:42:20\n",
      "2022-07-06 20:22:10 [INFO]\t[TRAIN] Epoch=357/500, Step=16/39, loss=0.017335, lr=0.000250, time_each_step=0.87s, eta=1:21:58\n",
      "2022-07-06 20:22:18 [INFO]\t[TRAIN] Epoch=357/500, Step=26/39, loss=0.041547, lr=0.000250, time_each_step=0.83s, eta=1:18:1\n",
      "2022-07-06 20:22:27 [INFO]\t[TRAIN] Epoch=357/500, Step=36/39, loss=0.024056, lr=0.000250, time_each_step=0.83s, eta=1:17:58\n",
      "2022-07-06 20:22:29 [INFO]\t[TRAIN] Epoch 357 finished, loss=0.026716571 .\n",
      "2022-07-06 20:22:38 [INFO]\t[TRAIN] Epoch=358/500, Step=7/39, loss=0.034910, lr=0.000250, time_each_step=1.09s, eta=1:41:24\n",
      "2022-07-06 20:22:46 [INFO]\t[TRAIN] Epoch=358/500, Step=17/39, loss=0.015798, lr=0.000250, time_each_step=0.84s, eta=1:18:35\n",
      "2022-07-06 20:22:54 [INFO]\t[TRAIN] Epoch=358/500, Step=27/39, loss=0.023347, lr=0.000250, time_each_step=0.84s, eta=1:17:59\n",
      "2022-07-06 20:23:03 [INFO]\t[TRAIN] Epoch=358/500, Step=37/39, loss=0.021493, lr=0.000250, time_each_step=0.84s, eta=1:17:54\n",
      "2022-07-06 20:23:05 [INFO]\t[TRAIN] Epoch 358 finished, loss=0.025794955 .\n",
      "2022-07-06 20:23:14 [INFO]\t[TRAIN] Epoch=359/500, Step=8/39, loss=0.018494, lr=0.000250, time_each_step=1.1s, eta=1:42:12\n",
      "2022-07-06 20:23:22 [INFO]\t[TRAIN] Epoch=359/500, Step=18/39, loss=0.018012, lr=0.000250, time_each_step=0.84s, eta=1:17:49\n",
      "2022-07-06 20:23:31 [INFO]\t[TRAIN] Epoch=359/500, Step=28/39, loss=0.025604, lr=0.000250, time_each_step=0.84s, eta=1:17:17\n",
      "2022-07-06 20:23:39 [INFO]\t[TRAIN] Epoch=359/500, Step=38/39, loss=0.022736, lr=0.000250, time_each_step=0.84s, eta=1:17:2\n",
      "2022-07-06 20:23:40 [INFO]\t[TRAIN] Epoch 359 finished, loss=0.024920631 .\n",
      "2022-07-06 20:23:50 [INFO]\t[TRAIN] Epoch=360/500, Step=9/39, loss=0.020892, lr=0.000250, time_each_step=1.11s, eta=1:41:48\n",
      "2022-07-06 20:23:59 [INFO]\t[TRAIN] Epoch=360/500, Step=19/39, loss=0.027894, lr=0.000250, time_each_step=0.84s, eta=1:17:17\n",
      "2022-07-06 20:24:07 [INFO]\t[TRAIN] Epoch=360/500, Step=29/39, loss=0.033208, lr=0.000250, time_each_step=0.85s, eta=1:17:44\n",
      "2022-07-06 20:24:16 [INFO]\t[TRAIN] Epoch=360/500, Step=39/39, loss=0.034248, lr=0.000250, time_each_step=0.84s, eta=1:17:6\n",
      "2022-07-06 20:24:16 [INFO]\t[TRAIN] Epoch 360 finished, loss=0.026247362 .\n",
      "2022-07-06 20:24:16 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 20:24:16 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 20:24:18 [INFO]\t[EVAL] Finished, Epoch=360, miou=0.892545, category_iou=[0.98897678 0.79611275], oacc=0.989432, category_acc=[0.99358443 0.90273802], kappa=0.880944, category_F1-score=[0.99445785 0.88648416] .\n",
      "2022-07-06 20:24:18 [INFO]\tModel saved in /home/aistudio/exp/best_model.\n",
      "2022-07-06 20:24:18 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_360, miou=0.8925447692318851\n",
      "2022-07-06 20:24:19 [INFO]\tModel saved in /home/aistudio/exp/epoch_360.\n",
      "2022-07-06 20:24:30 [INFO]\t[TRAIN] Epoch=361/500, Step=10/39, loss=0.029701, lr=0.000250, time_each_step=1.14s, eta=1:44:14\n",
      "2022-07-06 20:24:38 [INFO]\t[TRAIN] Epoch=361/500, Step=20/39, loss=0.023070, lr=0.000250, time_each_step=0.84s, eta=1:16:16\n",
      "2022-07-06 20:24:47 [INFO]\t[TRAIN] Epoch=361/500, Step=30/39, loss=0.031304, lr=0.000250, time_each_step=0.83s, eta=1:16:3\n",
      "2022-07-06 20:24:54 [INFO]\t[TRAIN] Epoch 361 finished, loss=0.027542707 .\n",
      "2022-07-06 20:24:58 [INFO]\t[TRAIN] Epoch=362/500, Step=1/39, loss=0.026613, lr=0.000250, time_each_step=1.07s, eta=1:37:6\n",
      "2022-07-06 20:25:06 [INFO]\t[TRAIN] Epoch=362/500, Step=11/39, loss=0.013903, lr=0.000250, time_each_step=0.85s, eta=1:17:12\n",
      "2022-07-06 20:25:15 [INFO]\t[TRAIN] Epoch=362/500, Step=21/39, loss=0.023521, lr=0.000250, time_each_step=0.84s, eta=1:16:21\n",
      "2022-07-06 20:25:23 [INFO]\t[TRAIN] Epoch=362/500, Step=31/39, loss=0.028961, lr=0.000250, time_each_step=0.84s, eta=1:16:4\n",
      "2022-07-06 20:25:30 [INFO]\t[TRAIN] Epoch 362 finished, loss=0.025895914 .\n",
      "2022-07-06 20:25:34 [INFO]\t[TRAIN] Epoch=363/500, Step=2/39, loss=0.023424, lr=0.000250, time_each_step=1.06s, eta=1:35:59\n",
      "2022-07-06 20:25:42 [INFO]\t[TRAIN] Epoch=363/500, Step=12/39, loss=0.024289, lr=0.000250, time_each_step=0.86s, eta=1:17:7\n",
      "2022-07-06 20:25:51 [INFO]\t[TRAIN] Epoch=363/500, Step=22/39, loss=0.020284, lr=0.000250, time_each_step=0.84s, eta=1:15:15\n",
      "2022-07-06 20:25:59 [INFO]\t[TRAIN] Epoch=363/500, Step=32/39, loss=0.035044, lr=0.000250, time_each_step=0.84s, eta=1:15:15\n",
      "2022-07-06 20:26:05 [INFO]\t[TRAIN] Epoch 363 finished, loss=0.027035147 .\n",
      "2022-07-06 20:26:10 [INFO]\t[TRAIN] Epoch=364/500, Step=3/39, loss=0.019286, lr=0.000250, time_each_step=1.1s, eta=1:38:21\n",
      "2022-07-06 20:26:19 [INFO]\t[TRAIN] Epoch=364/500, Step=13/39, loss=0.028000, lr=0.000250, time_each_step=0.84s, eta=1:15:14\n",
      "2022-07-06 20:26:27 [INFO]\t[TRAIN] Epoch=364/500, Step=23/39, loss=0.021486, lr=0.000250, time_each_step=0.84s, eta=1:14:59\n",
      "2022-07-06 20:26:35 [INFO]\t[TRAIN] Epoch=364/500, Step=33/39, loss=0.026726, lr=0.000250, time_each_step=0.83s, eta=1:14:17\n",
      "2022-07-06 20:26:41 [INFO]\t[TRAIN] Epoch 364 finished, loss=0.027551042 .\n",
      "2022-07-06 20:26:47 [INFO]\t[TRAIN] Epoch=365/500, Step=4/39, loss=0.022404, lr=0.000250, time_each_step=1.1s, eta=1:37:25\n",
      "2022-07-06 20:26:55 [INFO]\t[TRAIN] Epoch=365/500, Step=14/39, loss=0.041765, lr=0.000250, time_each_step=0.85s, eta=1:15:32\n",
      "2022-07-06 20:27:03 [INFO]\t[TRAIN] Epoch=365/500, Step=24/39, loss=0.016621, lr=0.000250, time_each_step=0.84s, eta=1:14:14\n",
      "2022-07-06 20:27:12 [INFO]\t[TRAIN] Epoch=365/500, Step=34/39, loss=0.024591, lr=0.000250, time_each_step=0.84s, eta=1:13:57\n",
      "2022-07-06 20:27:16 [INFO]\t[TRAIN] Epoch 365 finished, loss=0.02704259 .\n",
      "2022-07-06 20:27:23 [INFO]\t[TRAIN] Epoch=366/500, Step=5/39, loss=0.005648, lr=0.000250, time_each_step=1.09s, eta=1:36:23\n",
      "2022-07-06 20:27:31 [INFO]\t[TRAIN] Epoch=366/500, Step=15/39, loss=0.026758, lr=0.000250, time_each_step=0.86s, eta=1:15:33\n",
      "2022-07-06 20:27:40 [INFO]\t[TRAIN] Epoch=366/500, Step=25/39, loss=0.045089, lr=0.000250, time_each_step=0.83s, eta=1:13:19\n",
      "2022-07-06 20:27:48 [INFO]\t[TRAIN] Epoch=366/500, Step=35/39, loss=0.045237, lr=0.000250, time_each_step=0.84s, eta=1:13:35\n",
      "2022-07-06 20:27:52 [INFO]\t[TRAIN] Epoch 366 finished, loss=0.025860706 .\n",
      "2022-07-06 20:28:00 [INFO]\t[TRAIN] Epoch=367/500, Step=6/39, loss=0.013714, lr=0.000250, time_each_step=1.13s, eta=1:39:1\n",
      "2022-07-06 20:28:08 [INFO]\t[TRAIN] Epoch=367/500, Step=16/39, loss=0.026737, lr=0.000250, time_each_step=0.85s, eta=1:14:3\n",
      "2022-07-06 20:28:16 [INFO]\t[TRAIN] Epoch=367/500, Step=26/39, loss=0.051439, lr=0.000250, time_each_step=0.84s, eta=1:13:21\n",
      "2022-07-06 20:28:25 [INFO]\t[TRAIN] Epoch=367/500, Step=36/39, loss=0.031426, lr=0.000250, time_each_step=0.83s, eta=1:12:36\n",
      "2022-07-06 20:28:27 [INFO]\t[TRAIN] Epoch 367 finished, loss=0.025900224 .\n",
      "2022-07-06 20:28:36 [INFO]\t[TRAIN] Epoch=368/500, Step=7/39, loss=0.034506, lr=0.000250, time_each_step=1.13s, eta=1:38:21\n",
      "2022-07-06 20:28:45 [INFO]\t[TRAIN] Epoch=368/500, Step=17/39, loss=0.031904, lr=0.000250, time_each_step=0.84s, eta=1:12:45\n",
      "2022-07-06 20:28:53 [INFO]\t[TRAIN] Epoch=368/500, Step=27/39, loss=0.035020, lr=0.000250, time_each_step=0.84s, eta=1:12:32\n",
      "2022-07-06 20:29:01 [INFO]\t[TRAIN] Epoch=368/500, Step=37/39, loss=0.027540, lr=0.000250, time_each_step=0.83s, eta=1:11:58\n",
      "2022-07-06 20:29:03 [INFO]\t[TRAIN] Epoch 368 finished, loss=0.02716651 .\n",
      "2022-07-06 20:29:12 [INFO]\t[TRAIN] Epoch=369/500, Step=8/39, loss=0.034333, lr=0.000250, time_each_step=1.09s, eta=1:33:55\n",
      "2022-07-06 20:29:21 [INFO]\t[TRAIN] Epoch=369/500, Step=18/39, loss=0.019954, lr=0.000250, time_each_step=0.85s, eta=1:13:5\n",
      "2022-07-06 20:29:30 [INFO]\t[TRAIN] Epoch=369/500, Step=28/39, loss=0.024129, lr=0.000250, time_each_step=0.89s, eta=1:16:18\n",
      "2022-07-06 20:29:38 [INFO]\t[TRAIN] Epoch=369/500, Step=38/39, loss=0.015416, lr=0.000250, time_each_step=0.83s, eta=1:11:23\n",
      "2022-07-06 20:29:39 [INFO]\t[TRAIN] Epoch 369 finished, loss=0.026252765 .\n",
      "2022-07-06 20:29:49 [INFO]\t[TRAIN] Epoch=370/500, Step=9/39, loss=0.029274, lr=0.000250, time_each_step=1.11s, eta=1:35:0\n",
      "2022-07-06 20:29:58 [INFO]\t[TRAIN] Epoch=370/500, Step=19/39, loss=0.017515, lr=0.000250, time_each_step=0.84s, eta=1:11:46\n",
      "2022-07-06 20:30:06 [INFO]\t[TRAIN] Epoch=370/500, Step=29/39, loss=0.018131, lr=0.000250, time_each_step=0.85s, eta=1:12:41\n",
      "2022-07-06 20:30:15 [INFO]\t[TRAIN] Epoch=370/500, Step=39/39, loss=0.026241, lr=0.000250, time_each_step=0.84s, eta=1:11:14\n",
      "2022-07-06 20:30:15 [INFO]\t[TRAIN] Epoch 370 finished, loss=0.026024226 .\n",
      "2022-07-06 20:30:15 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 20:30:15 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 20:30:17 [INFO]\t[EVAL] Finished, Epoch=370, miou=0.890731, category_iou=[0.98887262 0.79258941], oacc=0.989326, category_acc=[0.99308912 0.90921382], kappa=0.878705, category_F1-score=[0.99440518 0.88429554] .\n",
      "2022-07-06 20:30:17 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_360, miou=0.8925447692318851\n",
      "2022-07-06 20:30:17 [INFO]\tModel saved in /home/aistudio/exp/epoch_370.\n",
      "2022-07-06 20:30:29 [INFO]\t[TRAIN] Epoch=371/500, Step=10/39, loss=0.031018, lr=0.000250, time_each_step=1.16s, eta=1:37:56\n",
      "2022-07-06 20:30:37 [INFO]\t[TRAIN] Epoch=371/500, Step=20/39, loss=0.040367, lr=0.000250, time_each_step=0.84s, eta=1:11:12\n",
      "2022-07-06 20:30:46 [INFO]\t[TRAIN] Epoch=371/500, Step=30/39, loss=0.020004, lr=0.000250, time_each_step=0.84s, eta=1:11:12\n",
      "2022-07-06 20:30:53 [INFO]\t[TRAIN] Epoch 371 finished, loss=0.02566648 .\n",
      "2022-07-06 20:30:57 [INFO]\t[TRAIN] Epoch=372/500, Step=1/39, loss=0.019769, lr=0.000250, time_each_step=1.08s, eta=1:31:19\n",
      "2022-07-06 20:31:05 [INFO]\t[TRAIN] Epoch=372/500, Step=11/39, loss=0.029021, lr=0.000250, time_each_step=0.85s, eta=1:11:52\n",
      "2022-07-06 20:31:13 [INFO]\t[TRAIN] Epoch=372/500, Step=21/39, loss=0.044659, lr=0.000250, time_each_step=0.84s, eta=1:10:9\n",
      "2022-07-06 20:31:22 [INFO]\t[TRAIN] Epoch=372/500, Step=31/39, loss=0.025808, lr=0.000250, time_each_step=0.84s, eta=1:10:1\n",
      "2022-07-06 20:31:29 [INFO]\t[TRAIN] Epoch 372 finished, loss=0.027044872 .\n",
      "2022-07-06 20:31:33 [INFO]\t[TRAIN] Epoch=373/500, Step=2/39, loss=0.022988, lr=0.000250, time_each_step=1.08s, eta=1:30:18\n",
      "2022-07-06 20:31:41 [INFO]\t[TRAIN] Epoch=373/500, Step=12/39, loss=0.029561, lr=0.000250, time_each_step=0.85s, eta=1:11:4\n",
      "2022-07-06 20:31:50 [INFO]\t[TRAIN] Epoch=373/500, Step=22/39, loss=0.026359, lr=0.000250, time_each_step=0.84s, eta=1:9:53\n",
      "2022-07-06 20:31:58 [INFO]\t[TRAIN] Epoch=373/500, Step=32/39, loss=0.035456, lr=0.000250, time_each_step=0.83s, eta=1:9:26\n",
      "2022-07-06 20:32:04 [INFO]\t[TRAIN] Epoch 373 finished, loss=0.025841666 .\n",
      "2022-07-06 20:32:09 [INFO]\t[TRAIN] Epoch=374/500, Step=3/39, loss=0.016177, lr=0.000250, time_each_step=1.11s, eta=1:32:12\n",
      "2022-07-06 20:32:18 [INFO]\t[TRAIN] Epoch=374/500, Step=13/39, loss=0.030256, lr=0.000250, time_each_step=0.84s, eta=1:9:34\n",
      "2022-07-06 20:32:26 [INFO]\t[TRAIN] Epoch=374/500, Step=23/39, loss=0.032771, lr=0.000250, time_each_step=0.83s, eta=1:8:55\n",
      "2022-07-06 20:32:34 [INFO]\t[TRAIN] Epoch=374/500, Step=33/39, loss=0.019954, lr=0.000250, time_each_step=0.84s, eta=1:8:56\n",
      "2022-07-06 20:32:39 [INFO]\t[TRAIN] Epoch 374 finished, loss=0.025726805 .\n",
      "2022-07-06 20:32:45 [INFO]\t[TRAIN] Epoch=375/500, Step=4/39, loss=0.023551, lr=0.000250, time_each_step=1.09s, eta=1:29:14\n",
      "2022-07-06 20:32:54 [INFO]\t[TRAIN] Epoch=375/500, Step=14/39, loss=0.020334, lr=0.000250, time_each_step=0.85s, eta=1:9:49\n",
      "2022-07-06 20:33:02 [INFO]\t[TRAIN] Epoch=375/500, Step=24/39, loss=0.017908, lr=0.000250, time_each_step=0.84s, eta=1:8:52\n",
      "2022-07-06 20:33:11 [INFO]\t[TRAIN] Epoch=375/500, Step=34/39, loss=0.030628, lr=0.000250, time_each_step=0.83s, eta=1:8:14\n",
      "2022-07-06 20:33:15 [INFO]\t[TRAIN] Epoch 375 finished, loss=0.026114883 .\n",
      "2022-07-06 20:33:22 [INFO]\t[TRAIN] Epoch=376/500, Step=5/39, loss=0.012000, lr=0.000250, time_each_step=1.09s, eta=1:28:48\n",
      "2022-07-06 20:33:30 [INFO]\t[TRAIN] Epoch=376/500, Step=15/39, loss=0.026901, lr=0.000250, time_each_step=0.85s, eta=1:9:16\n",
      "2022-07-06 20:33:39 [INFO]\t[TRAIN] Epoch=376/500, Step=25/39, loss=0.020793, lr=0.000250, time_each_step=0.84s, eta=1:8:35\n",
      "2022-07-06 20:33:47 [INFO]\t[TRAIN] Epoch=376/500, Step=35/39, loss=0.038358, lr=0.000250, time_each_step=0.83s, eta=1:7:35\n",
      "2022-07-06 20:33:50 [INFO]\t[TRAIN] Epoch 376 finished, loss=0.024873497 .\n",
      "2022-07-06 20:33:58 [INFO]\t[TRAIN] Epoch=377/500, Step=6/39, loss=0.035497, lr=0.000250, time_each_step=1.11s, eta=1:29:51\n",
      "2022-07-06 20:34:07 [INFO]\t[TRAIN] Epoch=377/500, Step=16/39, loss=0.022028, lr=0.000250, time_each_step=0.84s, eta=1:8:4\n",
      "2022-07-06 20:34:15 [INFO]\t[TRAIN] Epoch=377/500, Step=26/39, loss=0.027506, lr=0.000250, time_each_step=0.85s, eta=1:8:28\n",
      "2022-07-06 20:34:23 [INFO]\t[TRAIN] Epoch=377/500, Step=36/39, loss=0.025610, lr=0.000250, time_each_step=0.83s, eta=1:6:59\n",
      "2022-07-06 20:34:26 [INFO]\t[TRAIN] Epoch 377 finished, loss=0.02669151 .\n",
      "2022-07-06 20:34:34 [INFO]\t[TRAIN] Epoch=378/500, Step=7/39, loss=0.028561, lr=0.000250, time_each_step=1.09s, eta=1:27:41\n",
      "2022-07-06 20:34:43 [INFO]\t[TRAIN] Epoch=378/500, Step=17/39, loss=0.031431, lr=0.000250, time_each_step=0.85s, eta=1:8:8\n",
      "2022-07-06 20:34:51 [INFO]\t[TRAIN] Epoch=378/500, Step=27/39, loss=0.032205, lr=0.000250, time_each_step=0.84s, eta=1:6:48\n",
      "2022-07-06 20:35:00 [INFO]\t[TRAIN] Epoch=378/500, Step=37/39, loss=0.030856, lr=0.000250, time_each_step=0.84s, eta=1:6:56\n",
      "2022-07-06 20:35:01 [INFO]\t[TRAIN] Epoch 378 finished, loss=0.027100788 .\n",
      "2022-07-06 20:35:11 [INFO]\t[TRAIN] Epoch=379/500, Step=8/39, loss=0.023713, lr=0.000250, time_each_step=1.12s, eta=1:28:56\n",
      "2022-07-06 20:35:19 [INFO]\t[TRAIN] Epoch=379/500, Step=18/39, loss=0.022605, lr=0.000250, time_each_step=0.85s, eta=1:7:24\n",
      "2022-07-06 20:35:28 [INFO]\t[TRAIN] Epoch=379/500, Step=28/39, loss=0.026355, lr=0.000250, time_each_step=0.84s, eta=1:6:25\n",
      "2022-07-06 20:35:36 [INFO]\t[TRAIN] Epoch=379/500, Step=38/39, loss=0.019374, lr=0.000250, time_each_step=0.83s, eta=1:5:54\n",
      "2022-07-06 20:35:37 [INFO]\t[TRAIN] Epoch 379 finished, loss=0.025995651 .\n",
      "2022-07-06 20:35:48 [INFO]\t[TRAIN] Epoch=380/500, Step=9/39, loss=0.023794, lr=0.000250, time_each_step=1.18s, eta=1:32:44\n",
      "2022-07-06 20:35:56 [INFO]\t[TRAIN] Epoch=380/500, Step=19/39, loss=0.042262, lr=0.000250, time_each_step=0.85s, eta=1:6:56\n",
      "2022-07-06 20:36:05 [INFO]\t[TRAIN] Epoch=380/500, Step=29/39, loss=0.035811, lr=0.000250, time_each_step=0.84s, eta=1:5:42\n",
      "2022-07-06 20:36:13 [INFO]\t[TRAIN] Epoch=380/500, Step=39/39, loss=0.018334, lr=0.000250, time_each_step=0.83s, eta=1:5:15\n",
      "2022-07-06 20:36:13 [INFO]\t[TRAIN] Epoch 380 finished, loss=0.02623807 .\n",
      "2022-07-06 20:36:13 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 20:36:13 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 20:36:15 [INFO]\t[EVAL] Finished, Epoch=380, miou=0.892501, category_iou=[0.98899608 0.79600657], oacc=0.989449, category_acc=[0.99348621 0.90476729], kappa=0.880888, category_F1-score=[0.9944676  0.88641833] .\n",
      "2022-07-06 20:36:15 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_360, miou=0.8925447692318851\n",
      "2022-07-06 20:36:16 [INFO]\tModel saved in /home/aistudio/exp/epoch_380.\n",
      "2022-07-06 20:36:27 [INFO]\t[TRAIN] Epoch=381/500, Step=10/39, loss=0.033280, lr=0.000250, time_each_step=1.09s, eta=1:25:17\n",
      "2022-07-06 20:36:35 [INFO]\t[TRAIN] Epoch=381/500, Step=20/39, loss=0.024873, lr=0.000250, time_each_step=0.83s, eta=1:5:3\n",
      "2022-07-06 20:36:43 [INFO]\t[TRAIN] Epoch=381/500, Step=30/39, loss=0.006967, lr=0.000250, time_each_step=0.84s, eta=1:5:17\n",
      "2022-07-06 20:36:51 [INFO]\t[TRAIN] Epoch 381 finished, loss=0.026618209 .\n",
      "2022-07-06 20:36:54 [INFO]\t[TRAIN] Epoch=382/500, Step=1/39, loss=0.044287, lr=0.000250, time_each_step=1.07s, eta=1:23:12\n",
      "2022-07-06 20:37:03 [INFO]\t[TRAIN] Epoch=382/500, Step=11/39, loss=0.025703, lr=0.000250, time_each_step=0.86s, eta=1:6:59\n",
      "2022-07-06 20:37:11 [INFO]\t[TRAIN] Epoch=382/500, Step=21/39, loss=0.023167, lr=0.000250, time_each_step=0.84s, eta=1:4:51\n",
      "2022-07-06 20:37:20 [INFO]\t[TRAIN] Epoch=382/500, Step=31/39, loss=0.015998, lr=0.000250, time_each_step=0.84s, eta=1:4:39\n",
      "2022-07-06 20:37:26 [INFO]\t[TRAIN] Epoch 382 finished, loss=0.025972167 .\n",
      "2022-07-06 20:37:30 [INFO]\t[TRAIN] Epoch=383/500, Step=2/39, loss=0.019866, lr=0.000250, time_each_step=1.07s, eta=1:22:36\n",
      "2022-07-06 20:37:39 [INFO]\t[TRAIN] Epoch=383/500, Step=12/39, loss=0.025733, lr=0.000250, time_each_step=0.84s, eta=1:4:58\n",
      "2022-07-06 20:37:47 [INFO]\t[TRAIN] Epoch=383/500, Step=22/39, loss=0.016762, lr=0.000250, time_each_step=0.84s, eta=1:4:22\n",
      "2022-07-06 20:37:56 [INFO]\t[TRAIN] Epoch=383/500, Step=32/39, loss=0.030288, lr=0.000250, time_each_step=0.83s, eta=1:3:57\n",
      "2022-07-06 20:38:01 [INFO]\t[TRAIN] Epoch 383 finished, loss=0.025205089 .\n",
      "2022-07-06 20:38:07 [INFO]\t[TRAIN] Epoch=384/500, Step=3/39, loss=0.024956, lr=0.000250, time_each_step=1.12s, eta=1:25:52\n",
      "2022-07-06 20:38:15 [INFO]\t[TRAIN] Epoch=384/500, Step=13/39, loss=0.005666, lr=0.000250, time_each_step=0.85s, eta=1:4:52\n",
      "2022-07-06 20:38:24 [INFO]\t[TRAIN] Epoch=384/500, Step=23/39, loss=0.024893, lr=0.000250, time_each_step=0.84s, eta=1:3:35\n",
      "2022-07-06 20:38:32 [INFO]\t[TRAIN] Epoch=384/500, Step=33/39, loss=0.047641, lr=0.000250, time_each_step=0.83s, eta=1:3:24\n",
      "2022-07-06 20:38:37 [INFO]\t[TRAIN] Epoch 384 finished, loss=0.026216049 .\n",
      "2022-07-06 20:38:43 [INFO]\t[TRAIN] Epoch=385/500, Step=4/39, loss=0.033970, lr=0.000250, time_each_step=1.07s, eta=1:21:22\n",
      "2022-07-06 20:38:51 [INFO]\t[TRAIN] Epoch=385/500, Step=14/39, loss=0.026969, lr=0.000250, time_each_step=0.84s, eta=1:3:51\n",
      "2022-07-06 20:39:00 [INFO]\t[TRAIN] Epoch=385/500, Step=24/39, loss=0.029247, lr=0.000250, time_each_step=0.84s, eta=1:3:7\n",
      "2022-07-06 20:39:08 [INFO]\t[TRAIN] Epoch=385/500, Step=34/39, loss=0.029504, lr=0.000250, time_each_step=0.83s, eta=1:2:44\n",
      "2022-07-06 20:39:12 [INFO]\t[TRAIN] Epoch 385 finished, loss=0.02616005 .\n",
      "2022-07-06 20:39:19 [INFO]\t[TRAIN] Epoch=386/500, Step=5/39, loss=0.024065, lr=0.000250, time_each_step=1.08s, eta=1:20:49\n",
      "2022-07-06 20:39:27 [INFO]\t[TRAIN] Epoch=386/500, Step=15/39, loss=0.018421, lr=0.000250, time_each_step=0.85s, eta=1:3:37\n",
      "2022-07-06 20:39:36 [INFO]\t[TRAIN] Epoch=386/500, Step=25/39, loss=0.029442, lr=0.000250, time_each_step=0.84s, eta=1:2:39\n",
      "2022-07-06 20:39:44 [INFO]\t[TRAIN] Epoch=386/500, Step=35/39, loss=0.025589, lr=0.000250, time_each_step=0.84s, eta=1:2:21\n",
      "2022-07-06 20:39:48 [INFO]\t[TRAIN] Epoch 386 finished, loss=0.026524773 .\n",
      "2022-07-06 20:39:55 [INFO]\t[TRAIN] Epoch=387/500, Step=6/39, loss=0.028857, lr=0.000250, time_each_step=1.09s, eta=1:20:43\n",
      "2022-07-06 20:40:04 [INFO]\t[TRAIN] Epoch=387/500, Step=16/39, loss=0.023995, lr=0.000250, time_each_step=0.85s, eta=1:3:12\n",
      "2022-07-06 20:40:12 [INFO]\t[TRAIN] Epoch=387/500, Step=26/39, loss=0.024111, lr=0.000250, time_each_step=0.83s, eta=1:1:44\n",
      "2022-07-06 20:40:20 [INFO]\t[TRAIN] Epoch=387/500, Step=36/39, loss=0.015870, lr=0.000250, time_each_step=0.84s, eta=1:1:51\n",
      "2022-07-06 20:40:23 [INFO]\t[TRAIN] Epoch 387 finished, loss=0.026686553 .\n",
      "2022-07-06 20:40:31 [INFO]\t[TRAIN] Epoch=388/500, Step=7/39, loss=0.027945, lr=0.000250, time_each_step=1.08s, eta=1:19:43\n",
      "2022-07-06 20:40:40 [INFO]\t[TRAIN] Epoch=388/500, Step=17/39, loss=0.035979, lr=0.000250, time_each_step=0.85s, eta=1:2:16\n",
      "2022-07-06 20:40:48 [INFO]\t[TRAIN] Epoch=388/500, Step=27/39, loss=0.021238, lr=0.000250, time_each_step=0.83s, eta=1:1:12\n",
      "2022-07-06 20:40:57 [INFO]\t[TRAIN] Epoch=388/500, Step=37/39, loss=0.031654, lr=0.000250, time_each_step=0.85s, eta=1:2:17\n",
      "2022-07-06 20:40:58 [INFO]\t[TRAIN] Epoch 388 finished, loss=0.026688542 .\n",
      "2022-07-06 20:41:09 [INFO]\t[TRAIN] Epoch=389/500, Step=8/39, loss=0.034304, lr=0.000250, time_each_step=1.21s, eta=1:28:6\n",
      "2022-07-06 20:41:17 [INFO]\t[TRAIN] Epoch=389/500, Step=18/39, loss=0.019183, lr=0.000250, time_each_step=0.84s, eta=1:1:18\n",
      "2022-07-06 20:41:26 [INFO]\t[TRAIN] Epoch=389/500, Step=28/39, loss=0.031692, lr=0.000250, time_each_step=0.83s, eta=1:0:41\n",
      "2022-07-06 20:41:34 [INFO]\t[TRAIN] Epoch=389/500, Step=38/39, loss=0.038686, lr=0.000250, time_each_step=0.83s, eta=1:0:21\n",
      "2022-07-06 20:41:35 [INFO]\t[TRAIN] Epoch 389 finished, loss=0.026723608 .\n",
      "2022-07-06 20:41:45 [INFO]\t[TRAIN] Epoch=390/500, Step=9/39, loss=0.026590, lr=0.000250, time_each_step=1.09s, eta=1:18:29\n",
      "2022-07-06 20:41:53 [INFO]\t[TRAIN] Epoch=390/500, Step=19/39, loss=0.024219, lr=0.000250, time_each_step=0.83s, eta=1:0:16\n",
      "2022-07-06 20:42:02 [INFO]\t[TRAIN] Epoch=390/500, Step=29/39, loss=0.024236, lr=0.000250, time_each_step=0.84s, eta=1:0:22\n",
      "2022-07-06 20:42:10 [INFO]\t[TRAIN] Epoch=390/500, Step=39/39, loss=0.019371, lr=0.000250, time_each_step=0.84s, eta=1:0:16\n",
      "2022-07-06 20:42:10 [INFO]\t[TRAIN] Epoch 390 finished, loss=0.025246264 .\n",
      "2022-07-06 20:42:10 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 20:42:10 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 20:42:12 [INFO]\t[EVAL] Finished, Epoch=390, miou=0.891174, category_iou=[0.98894054 0.79340828], oacc=0.989391, category_acc=[0.99304381 0.91134064], kappa=0.879249, category_F1-score=[0.99443952 0.88480497] .\n",
      "2022-07-06 20:42:12 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_360, miou=0.8925447692318851\n",
      "2022-07-06 20:42:13 [INFO]\tModel saved in /home/aistudio/exp/epoch_390.\n",
      "2022-07-06 20:42:24 [INFO]\t[TRAIN] Epoch=391/500, Step=10/39, loss=0.024739, lr=0.000250, time_each_step=1.18s, eta=1:24:23\n",
      "2022-07-06 20:42:33 [INFO]\t[TRAIN] Epoch=391/500, Step=20/39, loss=0.024319, lr=0.000250, time_each_step=0.84s, eta=0:59:53\n",
      "2022-07-06 20:42:41 [INFO]\t[TRAIN] Epoch=391/500, Step=30/39, loss=0.018590, lr=0.000250, time_each_step=0.84s, eta=0:59:39\n",
      "2022-07-06 20:42:49 [INFO]\t[TRAIN] Epoch 391 finished, loss=0.02515757 .\n",
      "2022-07-06 20:42:52 [INFO]\t[TRAIN] Epoch=392/500, Step=1/39, loss=0.035064, lr=0.000250, time_each_step=1.07s, eta=1:15:55\n",
      "2022-07-06 20:43:00 [INFO]\t[TRAIN] Epoch=392/500, Step=11/39, loss=0.021037, lr=0.000250, time_each_step=0.85s, eta=1:0:35\n",
      "2022-07-06 20:43:09 [INFO]\t[TRAIN] Epoch=392/500, Step=21/39, loss=0.025250, lr=0.000250, time_each_step=0.84s, eta=0:59:31\n",
      "2022-07-06 20:43:17 [INFO]\t[TRAIN] Epoch=392/500, Step=31/39, loss=0.020197, lr=0.000250, time_each_step=0.83s, eta=0:59:3\n",
      "2022-07-06 20:43:24 [INFO]\t[TRAIN] Epoch 392 finished, loss=0.02601876 .\n",
      "2022-07-06 20:43:28 [INFO]\t[TRAIN] Epoch=393/500, Step=2/39, loss=0.035032, lr=0.000250, time_each_step=1.08s, eta=1:16:10\n",
      "2022-07-06 20:43:37 [INFO]\t[TRAIN] Epoch=393/500, Step=12/39, loss=0.010694, lr=0.000250, time_each_step=0.85s, eta=1:0:8\n",
      "2022-07-06 20:43:45 [INFO]\t[TRAIN] Epoch=393/500, Step=22/39, loss=0.024768, lr=0.000250, time_each_step=0.83s, eta=0:58:33\n",
      "2022-07-06 20:43:53 [INFO]\t[TRAIN] Epoch=393/500, Step=32/39, loss=0.025515, lr=0.000250, time_each_step=0.83s, eta=0:58:25\n",
      "2022-07-06 20:43:59 [INFO]\t[TRAIN] Epoch 393 finished, loss=0.026549837 .\n",
      "2022-07-06 20:44:05 [INFO]\t[TRAIN] Epoch=394/500, Step=3/39, loss=0.025255, lr=0.000250, time_each_step=1.12s, eta=1:17:59\n",
      "2022-07-06 20:44:13 [INFO]\t[TRAIN] Epoch=394/500, Step=13/39, loss=0.017910, lr=0.000250, time_each_step=0.85s, eta=0:59:16\n",
      "2022-07-06 20:44:21 [INFO]\t[TRAIN] Epoch=394/500, Step=23/39, loss=0.015374, lr=0.000250, time_each_step=0.83s, eta=0:58:3\n",
      "2022-07-06 20:44:30 [INFO]\t[TRAIN] Epoch=394/500, Step=33/39, loss=0.015711, lr=0.000250, time_each_step=0.84s, eta=0:58:4\n",
      "2022-07-06 20:44:35 [INFO]\t[TRAIN] Epoch 394 finished, loss=0.026394634 .\n",
      "2022-07-06 20:44:41 [INFO]\t[TRAIN] Epoch=395/500, Step=4/39, loss=0.018259, lr=0.000250, time_each_step=1.08s, eta=1:14:34\n",
      "2022-07-06 20:44:49 [INFO]\t[TRAIN] Epoch=395/500, Step=14/39, loss=0.018360, lr=0.000250, time_each_step=0.84s, eta=0:57:57\n",
      "2022-07-06 20:44:57 [INFO]\t[TRAIN] Epoch=395/500, Step=24/39, loss=0.021146, lr=0.000250, time_each_step=0.83s, eta=0:57:30\n",
      "2022-07-06 20:45:06 [INFO]\t[TRAIN] Epoch=395/500, Step=34/39, loss=0.010930, lr=0.000250, time_each_step=0.83s, eta=0:57:16\n",
      "2022-07-06 20:45:10 [INFO]\t[TRAIN] Epoch 395 finished, loss=0.025054673 .\n",
      "2022-07-06 20:45:17 [INFO]\t[TRAIN] Epoch=396/500, Step=5/39, loss=0.033182, lr=0.000250, time_each_step=1.15s, eta=1:18:40\n",
      "2022-07-06 20:45:26 [INFO]\t[TRAIN] Epoch=396/500, Step=15/39, loss=0.020769, lr=0.000250, time_each_step=0.84s, eta=0:57:36\n",
      "2022-07-06 20:45:34 [INFO]\t[TRAIN] Epoch=396/500, Step=25/39, loss=0.025905, lr=0.000250, time_each_step=0.84s, eta=0:57:20\n",
      "2022-07-06 20:45:43 [INFO]\t[TRAIN] Epoch=396/500, Step=35/39, loss=0.035143, lr=0.000250, time_each_step=0.84s, eta=0:57:0\n",
      "2022-07-06 20:45:46 [INFO]\t[TRAIN] Epoch 396 finished, loss=0.027094355 .\n",
      "2022-07-06 20:45:54 [INFO]\t[TRAIN] Epoch=397/500, Step=6/39, loss=0.017848, lr=0.000250, time_each_step=1.09s, eta=1:13:41\n",
      "2022-07-06 20:46:02 [INFO]\t[TRAIN] Epoch=397/500, Step=16/39, loss=0.028844, lr=0.000250, time_each_step=0.84s, eta=0:56:38\n",
      "2022-07-06 20:46:10 [INFO]\t[TRAIN] Epoch=397/500, Step=26/39, loss=0.029785, lr=0.000250, time_each_step=0.83s, eta=0:56:14\n",
      "2022-07-06 20:46:19 [INFO]\t[TRAIN] Epoch=397/500, Step=36/39, loss=0.041300, lr=0.000250, time_each_step=0.83s, eta=0:56:7\n",
      "2022-07-06 20:46:21 [INFO]\t[TRAIN] Epoch 397 finished, loss=0.026122756 .\n",
      "2022-07-06 20:46:30 [INFO]\t[TRAIN] Epoch=398/500, Step=7/39, loss=0.035704, lr=0.000250, time_each_step=1.13s, eta=1:15:54\n",
      "2022-07-06 20:46:39 [INFO]\t[TRAIN] Epoch=398/500, Step=17/39, loss=0.026058, lr=0.000250, time_each_step=0.86s, eta=0:57:35\n",
      "2022-07-06 20:46:47 [INFO]\t[TRAIN] Epoch=398/500, Step=27/39, loss=0.030747, lr=0.000250, time_each_step=0.84s, eta=0:55:59\n",
      "2022-07-06 20:46:55 [INFO]\t[TRAIN] Epoch=398/500, Step=37/39, loss=0.017159, lr=0.000250, time_each_step=0.84s, eta=0:55:49\n",
      "2022-07-06 20:46:57 [INFO]\t[TRAIN] Epoch 398 finished, loss=0.027472313 .\n",
      "2022-07-06 20:47:07 [INFO]\t[TRAIN] Epoch=399/500, Step=8/39, loss=0.021475, lr=0.000250, time_each_step=1.17s, eta=1:18:3\n",
      "2022-07-06 20:47:16 [INFO]\t[TRAIN] Epoch=399/500, Step=18/39, loss=0.035112, lr=0.000250, time_each_step=0.84s, eta=0:55:35\n",
      "2022-07-06 20:47:24 [INFO]\t[TRAIN] Epoch=399/500, Step=28/39, loss=0.025466, lr=0.000250, time_each_step=0.84s, eta=0:55:34\n",
      "2022-07-06 20:47:32 [INFO]\t[TRAIN] Epoch=399/500, Step=38/39, loss=0.030790, lr=0.000250, time_each_step=0.83s, eta=0:54:57\n",
      "2022-07-06 20:47:33 [INFO]\t[TRAIN] Epoch 399 finished, loss=0.026370673 .\n",
      "2022-07-06 20:47:44 [INFO]\t[TRAIN] Epoch=400/500, Step=9/39, loss=0.034209, lr=0.000250, time_each_step=1.12s, eta=1:13:24\n",
      "2022-07-06 20:47:52 [INFO]\t[TRAIN] Epoch=400/500, Step=19/39, loss=0.022292, lr=0.000250, time_each_step=0.84s, eta=0:55:0\n",
      "2022-07-06 20:48:00 [INFO]\t[TRAIN] Epoch=400/500, Step=29/39, loss=0.022568, lr=0.000250, time_each_step=0.83s, eta=0:54:35\n",
      "2022-07-06 20:48:09 [INFO]\t[TRAIN] Epoch=400/500, Step=39/39, loss=0.018194, lr=0.000250, time_each_step=0.83s, eta=0:54:21\n",
      "2022-07-06 20:48:09 [INFO]\t[TRAIN] Epoch 400 finished, loss=0.0264059 .\n",
      "2022-07-06 20:48:09 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 20:48:09 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 20:48:11 [INFO]\t[EVAL] Finished, Epoch=400, miou=0.892038, category_iou=[0.98898099 0.79509432], oacc=0.989433, category_acc=[0.99331349 0.90743242], kappa=0.880316, category_F1-score=[0.99445997 0.88585242] .\n",
      "2022-07-06 20:48:11 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_360, miou=0.8925447692318851\n",
      "2022-07-06 20:48:11 [INFO]\tModel saved in /home/aistudio/exp/epoch_400.\n",
      "2022-07-06 20:48:22 [INFO]\t[TRAIN] Epoch=401/500, Step=10/39, loss=0.021847, lr=0.000250, time_each_step=1.08s, eta=1:10:20\n",
      "2022-07-06 20:48:30 [INFO]\t[TRAIN] Epoch=401/500, Step=20/39, loss=0.037158, lr=0.000250, time_each_step=0.83s, eta=0:54:18\n",
      "2022-07-06 20:48:39 [INFO]\t[TRAIN] Epoch=401/500, Step=30/39, loss=0.026754, lr=0.000250, time_each_step=0.83s, eta=0:54:6\n",
      "2022-07-06 20:48:46 [INFO]\t[TRAIN] Epoch 401 finished, loss=0.026067996 .\n",
      "2022-07-06 20:48:50 [INFO]\t[TRAIN] Epoch=402/500, Step=1/39, loss=0.027508, lr=0.000250, time_each_step=1.08s, eta=1:9:53\n",
      "2022-07-06 20:48:58 [INFO]\t[TRAIN] Epoch=402/500, Step=11/39, loss=0.023288, lr=0.000250, time_each_step=0.84s, eta=0:54:20\n",
      "2022-07-06 20:49:06 [INFO]\t[TRAIN] Epoch=402/500, Step=21/39, loss=0.012011, lr=0.000250, time_each_step=0.84s, eta=0:53:45\n",
      "2022-07-06 20:49:15 [INFO]\t[TRAIN] Epoch=402/500, Step=31/39, loss=0.016670, lr=0.000250, time_each_step=0.83s, eta=0:53:29\n",
      "2022-07-06 20:49:21 [INFO]\t[TRAIN] Epoch 402 finished, loss=0.026371779 .\n",
      "2022-07-06 20:49:26 [INFO]\t[TRAIN] Epoch=403/500, Step=2/39, loss=0.039113, lr=0.000250, time_each_step=1.08s, eta=1:8:55\n",
      "2022-07-06 20:49:34 [INFO]\t[TRAIN] Epoch=403/500, Step=12/39, loss=0.028252, lr=0.000250, time_each_step=0.85s, eta=0:54:31\n",
      "2022-07-06 20:49:42 [INFO]\t[TRAIN] Epoch=403/500, Step=22/39, loss=0.021704, lr=0.000250, time_each_step=0.83s, eta=0:53:3\n",
      "2022-07-06 20:49:51 [INFO]\t[TRAIN] Epoch=403/500, Step=32/39, loss=0.029245, lr=0.000250, time_each_step=0.84s, eta=0:53:22\n",
      "2022-07-06 20:49:57 [INFO]\t[TRAIN] Epoch 403 finished, loss=0.02514276 .\n",
      "2022-07-06 20:50:02 [INFO]\t[TRAIN] Epoch=404/500, Step=3/39, loss=0.018651, lr=0.000250, time_each_step=1.08s, eta=1:8:27\n",
      "2022-07-06 20:50:10 [INFO]\t[TRAIN] Epoch=404/500, Step=13/39, loss=0.026256, lr=0.000250, time_each_step=0.85s, eta=0:53:56\n",
      "2022-07-06 20:50:19 [INFO]\t[TRAIN] Epoch=404/500, Step=23/39, loss=0.024141, lr=0.000250, time_each_step=0.83s, eta=0:52:33\n",
      "2022-07-06 20:50:27 [INFO]\t[TRAIN] Epoch=404/500, Step=33/39, loss=0.022463, lr=0.000250, time_each_step=0.84s, eta=0:52:37\n",
      "2022-07-06 20:50:32 [INFO]\t[TRAIN] Epoch 404 finished, loss=0.025517678 .\n",
      "2022-07-06 20:50:38 [INFO]\t[TRAIN] Epoch=405/500, Step=4/39, loss=0.017691, lr=0.000250, time_each_step=1.13s, eta=1:10:32\n",
      "2022-07-06 20:50:47 [INFO]\t[TRAIN] Epoch=405/500, Step=14/39, loss=0.013280, lr=0.000250, time_each_step=0.85s, eta=0:52:52\n",
      "2022-07-06 20:50:55 [INFO]\t[TRAIN] Epoch=405/500, Step=24/39, loss=0.024407, lr=0.000250, time_each_step=0.84s, eta=0:52:12\n",
      "2022-07-06 20:51:04 [INFO]\t[TRAIN] Epoch=405/500, Step=34/39, loss=0.028351, lr=0.000250, time_each_step=0.83s, eta=0:51:51\n",
      "2022-07-06 20:51:08 [INFO]\t[TRAIN] Epoch 405 finished, loss=0.026378244 .\n",
      "2022-07-06 20:51:14 [INFO]\t[TRAIN] Epoch=406/500, Step=5/39, loss=0.027237, lr=0.000250, time_each_step=1.08s, eta=1:6:51\n",
      "2022-07-06 20:51:23 [INFO]\t[TRAIN] Epoch=406/500, Step=15/39, loss=0.027864, lr=0.000250, time_each_step=0.84s, eta=0:52:1\n",
      "2022-07-06 20:51:31 [INFO]\t[TRAIN] Epoch=406/500, Step=25/39, loss=0.027794, lr=0.000250, time_each_step=0.83s, eta=0:51:31\n",
      "2022-07-06 20:51:40 [INFO]\t[TRAIN] Epoch=406/500, Step=35/39, loss=0.031656, lr=0.000250, time_each_step=0.83s, eta=0:51:17\n",
      "2022-07-06 20:51:43 [INFO]\t[TRAIN] Epoch 406 finished, loss=0.025840139 .\n",
      "2022-07-06 20:51:51 [INFO]\t[TRAIN] Epoch=407/500, Step=6/39, loss=0.022757, lr=0.000250, time_each_step=1.1s, eta=1:7:21\n",
      "2022-07-06 20:51:59 [INFO]\t[TRAIN] Epoch=407/500, Step=16/39, loss=0.021740, lr=0.000250, time_each_step=0.86s, eta=0:52:46\n",
      "2022-07-06 20:52:08 [INFO]\t[TRAIN] Epoch=407/500, Step=26/39, loss=0.030634, lr=0.000250, time_each_step=0.83s, eta=0:50:54\n",
      "2022-07-06 20:52:16 [INFO]\t[TRAIN] Epoch=407/500, Step=36/39, loss=0.018209, lr=0.000250, time_each_step=0.83s, eta=0:50:38\n",
      "2022-07-06 20:52:19 [INFO]\t[TRAIN] Epoch 407 finished, loss=0.026412567 .\n",
      "2022-07-06 20:52:27 [INFO]\t[TRAIN] Epoch=408/500, Step=7/39, loss=0.014304, lr=0.000250, time_each_step=1.1s, eta=1:6:40\n",
      "2022-07-06 20:52:35 [INFO]\t[TRAIN] Epoch=408/500, Step=17/39, loss=0.039476, lr=0.000250, time_each_step=0.84s, eta=0:50:37\n",
      "2022-07-06 20:52:44 [INFO]\t[TRAIN] Epoch=408/500, Step=27/39, loss=0.023087, lr=0.000250, time_each_step=0.84s, eta=0:50:34\n",
      "2022-07-06 20:52:52 [INFO]\t[TRAIN] Epoch=408/500, Step=37/39, loss=0.031387, lr=0.000250, time_each_step=0.83s, eta=0:50:5\n",
      "2022-07-06 20:52:54 [INFO]\t[TRAIN] Epoch 408 finished, loss=0.027713047 .\n",
      "2022-07-06 20:53:03 [INFO]\t[TRAIN] Epoch=409/500, Step=8/39, loss=0.047690, lr=0.000250, time_each_step=1.11s, eta=1:6:45\n",
      "2022-07-06 20:53:12 [INFO]\t[TRAIN] Epoch=409/500, Step=18/39, loss=0.019644, lr=0.000250, time_each_step=0.84s, eta=0:50:16\n",
      "2022-07-06 20:53:20 [INFO]\t[TRAIN] Epoch=409/500, Step=28/39, loss=0.018975, lr=0.000250, time_each_step=0.84s, eta=0:50:8\n",
      "2022-07-06 20:53:29 [INFO]\t[TRAIN] Epoch=409/500, Step=38/39, loss=0.024511, lr=0.000250, time_each_step=0.85s, eta=0:50:26\n",
      "2022-07-06 20:53:30 [INFO]\t[TRAIN] Epoch 409 finished, loss=0.026538301 .\n",
      "2022-07-06 20:53:40 [INFO]\t[TRAIN] Epoch=410/500, Step=9/39, loss=0.026094, lr=0.000250, time_each_step=1.1s, eta=1:4:57\n",
      "2022-07-06 20:53:48 [INFO]\t[TRAIN] Epoch=410/500, Step=19/39, loss=0.017509, lr=0.000250, time_each_step=0.84s, eta=0:49:55\n",
      "2022-07-06 20:53:57 [INFO]\t[TRAIN] Epoch=410/500, Step=29/39, loss=0.029416, lr=0.000250, time_each_step=0.84s, eta=0:49:22\n",
      "2022-07-06 20:54:05 [INFO]\t[TRAIN] Epoch=410/500, Step=39/39, loss=0.012733, lr=0.000250, time_each_step=0.83s, eta=0:49:2\n",
      "2022-07-06 20:54:05 [INFO]\t[TRAIN] Epoch 410 finished, loss=0.025338136 .\n",
      "2022-07-06 20:54:05 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 20:54:05 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 20:54:07 [INFO]\t[EVAL] Finished, Epoch=410, miou=0.892500, category_iou=[0.98908677 0.79591237], oacc=0.989532, category_acc=[0.99312704 0.91275191], kappa=0.880878, category_F1-score=[0.99451345 0.88635992] .\n",
      "2022-07-06 20:54:07 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_360, miou=0.8925447692318851\n",
      "2022-07-06 20:54:07 [INFO]\tModel saved in /home/aistudio/exp/epoch_410.\n",
      "2022-07-06 20:54:19 [INFO]\t[TRAIN] Epoch=411/500, Step=10/39, loss=0.034963, lr=0.000250, time_each_step=1.12s, eta=1:5:33\n",
      "2022-07-06 20:54:27 [INFO]\t[TRAIN] Epoch=411/500, Step=20/39, loss=0.030152, lr=0.000250, time_each_step=0.84s, eta=0:48:59\n",
      "2022-07-06 20:54:35 [INFO]\t[TRAIN] Epoch=411/500, Step=30/39, loss=0.009897, lr=0.000250, time_each_step=0.84s, eta=0:48:43\n",
      "2022-07-06 20:54:43 [INFO]\t[TRAIN] Epoch 411 finished, loss=0.026329735 .\n",
      "2022-07-06 20:54:46 [INFO]\t[TRAIN] Epoch=412/500, Step=1/39, loss=0.026229, lr=0.000250, time_each_step=1.09s, eta=1:3:11\n",
      "2022-07-06 20:54:55 [INFO]\t[TRAIN] Epoch=412/500, Step=11/39, loss=0.035439, lr=0.000250, time_each_step=0.86s, eta=0:49:38\n",
      "2022-07-06 20:55:03 [INFO]\t[TRAIN] Epoch=412/500, Step=21/39, loss=0.028479, lr=0.000250, time_each_step=0.85s, eta=0:48:58\n",
      "2022-07-06 20:55:12 [INFO]\t[TRAIN] Epoch=412/500, Step=31/39, loss=0.029236, lr=0.000250, time_each_step=0.86s, eta=0:49:18\n",
      "2022-07-06 20:55:19 [INFO]\t[TRAIN] Epoch 412 finished, loss=0.027182683 .\n",
      "2022-07-06 20:55:23 [INFO]\t[TRAIN] Epoch=413/500, Step=2/39, loss=0.027250, lr=0.000250, time_each_step=1.08s, eta=1:1:52\n",
      "2022-07-06 20:55:31 [INFO]\t[TRAIN] Epoch=413/500, Step=12/39, loss=0.025970, lr=0.000250, time_each_step=0.85s, eta=0:48:34\n",
      "2022-07-06 20:55:40 [INFO]\t[TRAIN] Epoch=413/500, Step=22/39, loss=0.017545, lr=0.000250, time_each_step=0.83s, eta=0:47:38\n",
      "2022-07-06 20:55:48 [INFO]\t[TRAIN] Epoch=413/500, Step=32/39, loss=0.023915, lr=0.000250, time_each_step=0.83s, eta=0:47:27\n",
      "2022-07-06 20:55:54 [INFO]\t[TRAIN] Epoch 413 finished, loss=0.027346931 .\n",
      "2022-07-06 20:55:59 [INFO]\t[TRAIN] Epoch=414/500, Step=3/39, loss=0.022293, lr=0.000250, time_each_step=1.08s, eta=1:1:32\n",
      "2022-07-06 20:56:07 [INFO]\t[TRAIN] Epoch=414/500, Step=13/39, loss=0.027736, lr=0.000250, time_each_step=0.85s, eta=0:48:19\n",
      "2022-07-06 20:56:16 [INFO]\t[TRAIN] Epoch=414/500, Step=23/39, loss=0.029698, lr=0.000250, time_each_step=0.84s, eta=0:47:28\n",
      "2022-07-06 20:56:24 [INFO]\t[TRAIN] Epoch=414/500, Step=33/39, loss=0.023093, lr=0.000250, time_each_step=0.83s, eta=0:46:56\n",
      "2022-07-06 20:56:29 [INFO]\t[TRAIN] Epoch 414 finished, loss=0.026258249 .\n",
      "2022-07-06 20:56:35 [INFO]\t[TRAIN] Epoch=415/500, Step=4/39, loss=0.028427, lr=0.000250, time_each_step=1.11s, eta=1:2:3\n",
      "2022-07-06 20:56:44 [INFO]\t[TRAIN] Epoch=415/500, Step=14/39, loss=0.023317, lr=0.000250, time_each_step=0.85s, eta=0:47:27\n",
      "2022-07-06 20:56:52 [INFO]\t[TRAIN] Epoch=415/500, Step=24/39, loss=0.040304, lr=0.000250, time_each_step=0.83s, eta=0:46:33\n",
      "2022-07-06 20:57:01 [INFO]\t[TRAIN] Epoch=415/500, Step=34/39, loss=0.039314, lr=0.000250, time_each_step=0.84s, eta=0:46:44\n",
      "2022-07-06 20:57:05 [INFO]\t[TRAIN] Epoch 415 finished, loss=0.02581962 .\n",
      "2022-07-06 20:57:11 [INFO]\t[TRAIN] Epoch=416/500, Step=5/39, loss=0.025366, lr=0.000250, time_each_step=1.08s, eta=0:59:57\n",
      "2022-07-06 20:57:20 [INFO]\t[TRAIN] Epoch=416/500, Step=15/39, loss=0.021205, lr=0.000250, time_each_step=0.85s, eta=0:47:8\n",
      "2022-07-06 20:57:28 [INFO]\t[TRAIN] Epoch=416/500, Step=25/39, loss=0.028723, lr=0.000250, time_each_step=0.83s, eta=0:45:58\n",
      "2022-07-06 20:57:37 [INFO]\t[TRAIN] Epoch=416/500, Step=35/39, loss=0.032237, lr=0.000250, time_each_step=0.83s, eta=0:45:49\n",
      "2022-07-06 20:57:40 [INFO]\t[TRAIN] Epoch 416 finished, loss=0.02530165 .\n",
      "2022-07-06 20:57:48 [INFO]\t[TRAIN] Epoch=417/500, Step=6/39, loss=0.018558, lr=0.000250, time_each_step=1.08s, eta=0:59:23\n",
      "2022-07-06 20:57:56 [INFO]\t[TRAIN] Epoch=417/500, Step=16/39, loss=0.033375, lr=0.000250, time_each_step=0.84s, eta=0:45:48\n",
      "2022-07-06 20:58:04 [INFO]\t[TRAIN] Epoch=417/500, Step=26/39, loss=0.011942, lr=0.000250, time_each_step=0.85s, eta=0:46:9\n",
      "2022-07-06 20:58:13 [INFO]\t[TRAIN] Epoch=417/500, Step=36/39, loss=0.033051, lr=0.000250, time_each_step=0.83s, eta=0:45:21\n",
      "2022-07-06 20:58:16 [INFO]\t[TRAIN] Epoch 417 finished, loss=0.025336567 .\n",
      "2022-07-06 20:58:24 [INFO]\t[TRAIN] Epoch=418/500, Step=7/39, loss=0.032600, lr=0.000250, time_each_step=1.13s, eta=1:1:17\n",
      "2022-07-06 20:58:33 [INFO]\t[TRAIN] Epoch=418/500, Step=17/39, loss=0.012209, lr=0.000250, time_each_step=0.84s, eta=0:45:9\n",
      "2022-07-06 20:58:41 [INFO]\t[TRAIN] Epoch=418/500, Step=27/39, loss=0.025247, lr=0.000250, time_each_step=0.83s, eta=0:44:52\n",
      "2022-07-06 20:58:49 [INFO]\t[TRAIN] Epoch=418/500, Step=37/39, loss=0.026570, lr=0.000250, time_each_step=0.83s, eta=0:44:47\n",
      "2022-07-06 20:58:51 [INFO]\t[TRAIN] Epoch 418 finished, loss=0.025325017 .\n",
      "2022-07-06 20:59:00 [INFO]\t[TRAIN] Epoch=419/500, Step=8/39, loss=0.033351, lr=0.000250, time_each_step=1.09s, eta=0:58:14\n",
      "2022-07-06 20:59:09 [INFO]\t[TRAIN] Epoch=419/500, Step=18/39, loss=0.020263, lr=0.000250, time_each_step=0.85s, eta=0:45:19\n",
      "2022-07-06 20:59:17 [INFO]\t[TRAIN] Epoch=419/500, Step=28/39, loss=0.029101, lr=0.000250, time_each_step=0.83s, eta=0:44:20\n",
      "2022-07-06 20:59:26 [INFO]\t[TRAIN] Epoch=419/500, Step=38/39, loss=0.013205, lr=0.000250, time_each_step=0.83s, eta=0:44:7\n",
      "2022-07-06 20:59:27 [INFO]\t[TRAIN] Epoch 419 finished, loss=0.027032312 .\n",
      "2022-07-06 20:59:37 [INFO]\t[TRAIN] Epoch=420/500, Step=9/39, loss=0.022617, lr=0.000250, time_each_step=1.09s, eta=0:57:28\n",
      "2022-07-06 20:59:45 [INFO]\t[TRAIN] Epoch=420/500, Step=19/39, loss=0.016751, lr=0.000250, time_each_step=0.84s, eta=0:44:3\n",
      "2022-07-06 20:59:53 [INFO]\t[TRAIN] Epoch=420/500, Step=29/39, loss=0.016784, lr=0.000250, time_each_step=0.83s, eta=0:43:48\n",
      "2022-07-06 21:00:02 [INFO]\t[TRAIN] Epoch=420/500, Step=39/39, loss=0.018150, lr=0.000250, time_each_step=0.83s, eta=0:43:29\n",
      "2022-07-06 21:00:02 [INFO]\t[TRAIN] Epoch 420 finished, loss=0.02616241 .\n",
      "2022-07-06 21:00:02 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 21:00:02 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 21:00:04 [INFO]\t[EVAL] Finished, Epoch=420, miou=0.894532, category_iou=[0.98910664 0.7999576 ], oacc=0.989561, category_acc=[0.99407979 0.89698758], kappa=0.883387, category_F1-score=[0.99452349 0.88886272] .\n",
      "2022-07-06 21:00:04 [INFO]\tModel saved in /home/aistudio/exp/best_model.\n",
      "2022-07-06 21:00:04 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_420, miou=0.8945321201756344\n",
      "2022-07-06 21:00:05 [INFO]\tModel saved in /home/aistudio/exp/epoch_420.\n",
      "2022-07-06 21:00:16 [INFO]\t[TRAIN] Epoch=421/500, Step=10/39, loss=0.026284, lr=0.000250, time_each_step=1.12s, eta=0:58:11\n",
      "2022-07-06 21:00:24 [INFO]\t[TRAIN] Epoch=421/500, Step=20/39, loss=0.018938, lr=0.000250, time_each_step=0.84s, eta=0:43:50\n",
      "2022-07-06 21:00:33 [INFO]\t[TRAIN] Epoch=421/500, Step=30/39, loss=0.031233, lr=0.000250, time_each_step=0.84s, eta=0:43:38\n",
      "2022-07-06 21:00:40 [INFO]\t[TRAIN] Epoch 421 finished, loss=0.026297227 .\n",
      "2022-07-06 21:00:44 [INFO]\t[TRAIN] Epoch=422/500, Step=1/39, loss=0.027991, lr=0.000250, time_each_step=1.11s, eta=0:57:19\n",
      "2022-07-06 21:00:52 [INFO]\t[TRAIN] Epoch=422/500, Step=11/39, loss=0.029877, lr=0.000250, time_each_step=0.84s, eta=0:43:22\n",
      "2022-07-06 21:01:01 [INFO]\t[TRAIN] Epoch=422/500, Step=21/39, loss=0.032051, lr=0.000250, time_each_step=0.84s, eta=0:42:55\n",
      "2022-07-06 21:01:09 [INFO]\t[TRAIN] Epoch=422/500, Step=31/39, loss=0.044091, lr=0.000250, time_each_step=0.83s, eta=0:42:40\n",
      "2022-07-06 21:01:16 [INFO]\t[TRAIN] Epoch 422 finished, loss=0.02533459 .\n",
      "2022-07-06 21:01:21 [INFO]\t[TRAIN] Epoch=423/500, Step=2/39, loss=0.028880, lr=0.000250, time_each_step=1.16s, eta=0:59:8\n",
      "2022-07-06 21:01:29 [INFO]\t[TRAIN] Epoch=423/500, Step=12/39, loss=0.023434, lr=0.000250, time_each_step=0.84s, eta=0:42:47\n",
      "2022-07-06 21:01:38 [INFO]\t[TRAIN] Epoch=423/500, Step=22/39, loss=0.011542, lr=0.000250, time_each_step=0.84s, eta=0:42:24\n",
      "2022-07-06 21:01:46 [INFO]\t[TRAIN] Epoch=423/500, Step=32/39, loss=0.021008, lr=0.000250, time_each_step=0.83s, eta=0:42:6\n",
      "2022-07-06 21:01:52 [INFO]\t[TRAIN] Epoch 423 finished, loss=0.025421306 .\n",
      "2022-07-06 21:01:57 [INFO]\t[TRAIN] Epoch=424/500, Step=3/39, loss=0.033182, lr=0.000250, time_each_step=1.08s, eta=0:54:13\n",
      "2022-07-06 21:02:05 [INFO]\t[TRAIN] Epoch=424/500, Step=13/39, loss=0.032696, lr=0.000250, time_each_step=0.84s, eta=0:42:17\n",
      "2022-07-06 21:02:14 [INFO]\t[TRAIN] Epoch=424/500, Step=23/39, loss=0.021620, lr=0.000250, time_each_step=0.84s, eta=0:41:47\n",
      "2022-07-06 21:02:22 [INFO]\t[TRAIN] Epoch=424/500, Step=33/39, loss=0.017606, lr=0.000250, time_each_step=0.84s, eta=0:41:47\n",
      "2022-07-06 21:02:27 [INFO]\t[TRAIN] Epoch 424 finished, loss=0.02601736 .\n",
      "2022-07-06 21:02:33 [INFO]\t[TRAIN] Epoch=425/500, Step=4/39, loss=0.026049, lr=0.000250, time_each_step=1.08s, eta=0:53:27\n",
      "2022-07-06 21:02:41 [INFO]\t[TRAIN] Epoch=425/500, Step=14/39, loss=0.028593, lr=0.000250, time_each_step=0.86s, eta=0:42:25\n",
      "2022-07-06 21:02:50 [INFO]\t[TRAIN] Epoch=425/500, Step=24/39, loss=0.019715, lr=0.000250, time_each_step=0.84s, eta=0:41:28\n",
      "2022-07-06 21:02:58 [INFO]\t[TRAIN] Epoch=425/500, Step=34/39, loss=0.016812, lr=0.000250, time_each_step=0.83s, eta=0:40:58\n",
      "2022-07-06 21:03:03 [INFO]\t[TRAIN] Epoch 425 finished, loss=0.02653457 .\n",
      "2022-07-06 21:03:09 [INFO]\t[TRAIN] Epoch=426/500, Step=5/39, loss=0.016976, lr=0.000250, time_each_step=1.1s, eta=0:53:46\n",
      "2022-07-06 21:03:18 [INFO]\t[TRAIN] Epoch=426/500, Step=15/39, loss=0.019255, lr=0.000250, time_each_step=0.84s, eta=0:41:9\n",
      "2022-07-06 21:03:26 [INFO]\t[TRAIN] Epoch=426/500, Step=25/39, loss=0.021772, lr=0.000250, time_each_step=0.84s, eta=0:40:49\n",
      "2022-07-06 21:03:35 [INFO]\t[TRAIN] Epoch=426/500, Step=35/39, loss=0.016016, lr=0.000250, time_each_step=0.83s, eta=0:40:24\n",
      "2022-07-06 21:03:38 [INFO]\t[TRAIN] Epoch 426 finished, loss=0.02498655 .\n",
      "2022-07-06 21:03:46 [INFO]\t[TRAIN] Epoch=427/500, Step=6/39, loss=0.028091, lr=0.000250, time_each_step=1.13s, eta=0:54:45\n",
      "2022-07-06 21:03:54 [INFO]\t[TRAIN] Epoch=427/500, Step=16/39, loss=0.020576, lr=0.000250, time_each_step=0.85s, eta=0:40:47\n",
      "2022-07-06 21:04:03 [INFO]\t[TRAIN] Epoch=427/500, Step=26/39, loss=0.030346, lr=0.000250, time_each_step=0.84s, eta=0:40:12\n",
      "2022-07-06 21:04:11 [INFO]\t[TRAIN] Epoch=427/500, Step=36/39, loss=0.044289, lr=0.000250, time_each_step=0.83s, eta=0:39:50\n",
      "2022-07-06 21:04:14 [INFO]\t[TRAIN] Epoch 427 finished, loss=0.026060456 .\n",
      "2022-07-06 21:04:25 [INFO]\t[TRAIN] Epoch=428/500, Step=7/39, loss=0.013478, lr=0.000250, time_each_step=1.37s, eta=1:5:11\n",
      "2022-07-06 21:04:33 [INFO]\t[TRAIN] Epoch=428/500, Step=17/39, loss=0.034993, lr=0.000250, time_each_step=0.85s, eta=0:40:30\n",
      "2022-07-06 21:04:42 [INFO]\t[TRAIN] Epoch=428/500, Step=27/39, loss=0.032316, lr=0.000250, time_each_step=0.83s, eta=0:39:28\n",
      "2022-07-06 21:04:50 [INFO]\t[TRAIN] Epoch=428/500, Step=37/39, loss=0.031531, lr=0.000250, time_each_step=0.84s, eta=0:39:31\n",
      "2022-07-06 21:04:52 [INFO]\t[TRAIN] Epoch 428 finished, loss=0.025880018 .\n",
      "2022-07-06 21:05:01 [INFO]\t[TRAIN] Epoch=429/500, Step=8/39, loss=0.020738, lr=0.000250, time_each_step=1.09s, eta=0:51:0\n",
      "2022-07-06 21:05:10 [INFO]\t[TRAIN] Epoch=429/500, Step=18/39, loss=0.021179, lr=0.000250, time_each_step=0.84s, eta=0:39:15\n",
      "2022-07-06 21:05:18 [INFO]\t[TRAIN] Epoch=429/500, Step=28/39, loss=0.022754, lr=0.000250, time_each_step=0.83s, eta=0:38:58\n",
      "2022-07-06 21:05:26 [INFO]\t[TRAIN] Epoch=429/500, Step=38/39, loss=0.034875, lr=0.000250, time_each_step=0.83s, eta=0:38:46\n",
      "2022-07-06 21:05:27 [INFO]\t[TRAIN] Epoch 429 finished, loss=0.02439624 .\n",
      "2022-07-06 21:05:37 [INFO]\t[TRAIN] Epoch=430/500, Step=9/39, loss=0.031583, lr=0.000250, time_each_step=1.08s, eta=0:49:56\n",
      "2022-07-06 21:05:45 [INFO]\t[TRAIN] Epoch=430/500, Step=19/39, loss=0.027518, lr=0.000250, time_each_step=0.83s, eta=0:38:30\n",
      "2022-07-06 21:05:54 [INFO]\t[TRAIN] Epoch=430/500, Step=29/39, loss=0.023184, lr=0.000250, time_each_step=0.84s, eta=0:38:47\n",
      "2022-07-06 21:06:02 [INFO]\t[TRAIN] Epoch=430/500, Step=39/39, loss=0.032529, lr=0.000250, time_each_step=0.83s, eta=0:38:7\n",
      "2022-07-06 21:06:02 [INFO]\t[TRAIN] Epoch 430 finished, loss=0.025918068 .\n",
      "2022-07-06 21:06:02 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 21:06:02 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 21:06:04 [INFO]\t[EVAL] Finished, Epoch=430, miou=0.892420, category_iou=[0.98899749 0.7958421 ], oacc=0.989450, category_acc=[0.99343968 0.9055868 ], kappa=0.880787, category_F1-score=[0.99446831 0.88631634] .\n",
      "2022-07-06 21:06:04 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_420, miou=0.8945321201756344\n",
      "2022-07-06 21:06:05 [INFO]\tModel saved in /home/aistudio/exp/epoch_430.\n",
      "2022-07-06 21:06:16 [INFO]\t[TRAIN] Epoch=431/500, Step=10/39, loss=0.033346, lr=0.000125, time_each_step=1.1s, eta=0:49:56\n",
      "2022-07-06 21:06:24 [INFO]\t[TRAIN] Epoch=431/500, Step=20/39, loss=0.033768, lr=0.000125, time_each_step=0.84s, eta=0:38:4\n",
      "2022-07-06 21:06:33 [INFO]\t[TRAIN] Epoch=431/500, Step=30/39, loss=0.025799, lr=0.000125, time_each_step=0.84s, eta=0:38:7\n",
      "2022-07-06 21:06:40 [INFO]\t[TRAIN] Epoch 431 finished, loss=0.025250813 .\n",
      "2022-07-06 21:06:43 [INFO]\t[TRAIN] Epoch=432/500, Step=1/39, loss=0.018420, lr=0.000125, time_each_step=1.07s, eta=0:48:17\n",
      "2022-07-06 21:06:52 [INFO]\t[TRAIN] Epoch=432/500, Step=11/39, loss=0.028197, lr=0.000125, time_each_step=0.86s, eta=0:38:28\n",
      "2022-07-06 21:07:01 [INFO]\t[TRAIN] Epoch=432/500, Step=21/39, loss=0.023232, lr=0.000125, time_each_step=0.85s, eta=0:37:54\n",
      "2022-07-06 21:07:09 [INFO]\t[TRAIN] Epoch=432/500, Step=31/39, loss=0.025946, lr=0.000125, time_each_step=0.84s, eta=0:37:15\n",
      "2022-07-06 21:07:16 [INFO]\t[TRAIN] Epoch 432 finished, loss=0.024134394 .\n",
      "2022-07-06 21:07:20 [INFO]\t[TRAIN] Epoch=433/500, Step=2/39, loss=0.045667, lr=0.000125, time_each_step=1.08s, eta=0:47:54\n",
      "2022-07-06 21:07:28 [INFO]\t[TRAIN] Epoch=433/500, Step=12/39, loss=0.021420, lr=0.000125, time_each_step=0.85s, eta=0:37:33\n",
      "2022-07-06 21:07:37 [INFO]\t[TRAIN] Epoch=433/500, Step=22/39, loss=0.033085, lr=0.000125, time_each_step=0.84s, eta=0:36:58\n",
      "2022-07-06 21:07:45 [INFO]\t[TRAIN] Epoch=433/500, Step=32/39, loss=0.029650, lr=0.000125, time_each_step=0.83s, eta=0:36:38\n",
      "2022-07-06 21:07:51 [INFO]\t[TRAIN] Epoch 433 finished, loss=0.024959074 .\n",
      "2022-07-06 21:07:56 [INFO]\t[TRAIN] Epoch=434/500, Step=3/39, loss=0.030086, lr=0.000125, time_each_step=1.12s, eta=0:48:48\n",
      "2022-07-06 21:08:06 [INFO]\t[TRAIN] Epoch=434/500, Step=13/39, loss=0.029451, lr=0.000125, time_each_step=0.96s, eta=0:41:38\n",
      "2022-07-06 21:08:14 [INFO]\t[TRAIN] Epoch=434/500, Step=23/39, loss=0.009294, lr=0.000125, time_each_step=0.84s, eta=0:36:20\n",
      "2022-07-06 21:08:23 [INFO]\t[TRAIN] Epoch=434/500, Step=33/39, loss=0.029855, lr=0.000125, time_each_step=0.83s, eta=0:36:6\n",
      "2022-07-06 21:08:28 [INFO]\t[TRAIN] Epoch 434 finished, loss=0.026408553 .\n",
      "2022-07-06 21:08:34 [INFO]\t[TRAIN] Epoch=435/500, Step=4/39, loss=0.010413, lr=0.000125, time_each_step=1.1s, eta=0:47:22\n",
      "2022-07-06 21:08:42 [INFO]\t[TRAIN] Epoch=435/500, Step=14/39, loss=0.027592, lr=0.000125, time_each_step=0.86s, eta=0:36:52\n",
      "2022-07-06 21:08:51 [INFO]\t[TRAIN] Epoch=435/500, Step=24/39, loss=0.017455, lr=0.000125, time_each_step=0.83s, eta=0:35:34\n",
      "2022-07-06 21:08:59 [INFO]\t[TRAIN] Epoch=435/500, Step=34/39, loss=0.041178, lr=0.000125, time_each_step=0.83s, eta=0:35:27\n",
      "2022-07-06 21:09:03 [INFO]\t[TRAIN] Epoch 435 finished, loss=0.026381236 .\n",
      "2022-07-06 21:09:10 [INFO]\t[TRAIN] Epoch=436/500, Step=5/39, loss=0.011078, lr=0.000125, time_each_step=1.09s, eta=0:45:58\n",
      "2022-07-06 21:09:18 [INFO]\t[TRAIN] Epoch=436/500, Step=15/39, loss=0.020817, lr=0.000125, time_each_step=0.85s, eta=0:35:46\n",
      "2022-07-06 21:09:27 [INFO]\t[TRAIN] Epoch=436/500, Step=25/39, loss=0.018223, lr=0.000125, time_each_step=0.84s, eta=0:35:13\n",
      "2022-07-06 21:09:35 [INFO]\t[TRAIN] Epoch=436/500, Step=35/39, loss=0.024894, lr=0.000125, time_each_step=0.84s, eta=0:35:12\n",
      "2022-07-06 21:09:39 [INFO]\t[TRAIN] Epoch 436 finished, loss=0.025605777 .\n",
      "2022-07-06 21:09:46 [INFO]\t[TRAIN] Epoch=437/500, Step=6/39, loss=0.031518, lr=0.000125, time_each_step=1.11s, eta=0:46:17\n",
      "2022-07-06 21:09:55 [INFO]\t[TRAIN] Epoch=437/500, Step=16/39, loss=0.017787, lr=0.000125, time_each_step=0.84s, eta=0:34:58\n",
      "2022-07-06 21:10:03 [INFO]\t[TRAIN] Epoch=437/500, Step=26/39, loss=0.022795, lr=0.000125, time_each_step=0.83s, eta=0:34:34\n",
      "2022-07-06 21:10:11 [INFO]\t[TRAIN] Epoch=437/500, Step=36/39, loss=0.036916, lr=0.000125, time_each_step=0.84s, eta=0:34:39\n",
      "2022-07-06 21:10:14 [INFO]\t[TRAIN] Epoch 437 finished, loss=0.026013227 .\n",
      "2022-07-06 21:10:23 [INFO]\t[TRAIN] Epoch=438/500, Step=7/39, loss=0.014976, lr=0.000125, time_each_step=1.16s, eta=0:47:42\n",
      "2022-07-06 21:10:32 [INFO]\t[TRAIN] Epoch=438/500, Step=17/39, loss=0.020232, lr=0.000125, time_each_step=0.84s, eta=0:34:24\n",
      "2022-07-06 21:10:40 [INFO]\t[TRAIN] Epoch=438/500, Step=27/39, loss=0.028159, lr=0.000125, time_each_step=0.83s, eta=0:34:0\n",
      "2022-07-06 21:10:48 [INFO]\t[TRAIN] Epoch=438/500, Step=37/39, loss=0.026639, lr=0.000125, time_each_step=0.83s, eta=0:33:47\n",
      "2022-07-06 21:10:50 [INFO]\t[TRAIN] Epoch 438 finished, loss=0.026159726 .\n",
      "2022-07-06 21:10:59 [INFO]\t[TRAIN] Epoch=439/500, Step=8/39, loss=0.029507, lr=0.000125, time_each_step=1.09s, eta=0:43:49\n",
      "2022-07-06 21:11:08 [INFO]\t[TRAIN] Epoch=439/500, Step=18/39, loss=0.026497, lr=0.000125, time_each_step=0.84s, eta=0:33:44\n",
      "2022-07-06 21:11:16 [INFO]\t[TRAIN] Epoch=439/500, Step=28/39, loss=0.026615, lr=0.000125, time_each_step=0.84s, eta=0:33:39\n",
      "2022-07-06 21:11:25 [INFO]\t[TRAIN] Epoch=439/500, Step=38/39, loss=0.021511, lr=0.000125, time_each_step=0.83s, eta=0:33:12\n",
      "2022-07-06 21:11:25 [INFO]\t[TRAIN] Epoch 439 finished, loss=0.026113115 .\n",
      "2022-07-06 21:11:36 [INFO]\t[TRAIN] Epoch=440/500, Step=9/39, loss=0.014746, lr=0.000125, time_each_step=1.09s, eta=0:43:13\n",
      "2022-07-06 21:11:44 [INFO]\t[TRAIN] Epoch=440/500, Step=19/39, loss=0.028035, lr=0.000125, time_each_step=0.84s, eta=0:33:16\n",
      "2022-07-06 21:11:52 [INFO]\t[TRAIN] Epoch=440/500, Step=29/39, loss=0.023250, lr=0.000125, time_each_step=0.84s, eta=0:33:2\n",
      "2022-07-06 21:12:01 [INFO]\t[TRAIN] Epoch=440/500, Step=39/39, loss=0.016448, lr=0.000125, time_each_step=0.83s, eta=0:32:39\n",
      "2022-07-06 21:12:01 [INFO]\t[TRAIN] Epoch 440 finished, loss=0.025427945 .\n",
      "2022-07-06 21:12:01 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 21:12:01 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 21:12:03 [INFO]\t[EVAL] Finished, Epoch=440, miou=0.893333, category_iou=[0.98908757 0.79757775], oacc=0.989537, category_acc=[0.99354214 0.90557105], kappa=0.881908, category_F1-score=[0.99451385 0.88739166] .\n",
      "2022-07-06 21:12:03 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_420, miou=0.8945321201756344\n",
      "2022-07-06 21:12:03 [INFO]\tModel saved in /home/aistudio/exp/epoch_440.\n",
      "2022-07-06 21:12:14 [INFO]\t[TRAIN] Epoch=441/500, Step=10/39, loss=0.022753, lr=0.000125, time_each_step=1.1s, eta=0:42:56\n",
      "2022-07-06 21:12:23 [INFO]\t[TRAIN] Epoch=441/500, Step=20/39, loss=0.024035, lr=0.000125, time_each_step=0.86s, eta=0:33:19\n",
      "2022-07-06 21:12:31 [INFO]\t[TRAIN] Epoch=441/500, Step=30/39, loss=0.019040, lr=0.000125, time_each_step=0.85s, eta=0:32:43\n",
      "2022-07-06 21:12:39 [INFO]\t[TRAIN] Epoch 441 finished, loss=0.02501056 .\n",
      "2022-07-06 21:12:42 [INFO]\t[TRAIN] Epoch=442/500, Step=1/39, loss=0.027826, lr=0.000125, time_each_step=1.11s, eta=0:42:34\n",
      "2022-07-06 21:12:51 [INFO]\t[TRAIN] Epoch=442/500, Step=11/39, loss=0.024616, lr=0.000125, time_each_step=0.85s, eta=0:32:44\n",
      "2022-07-06 21:12:59 [INFO]\t[TRAIN] Epoch=442/500, Step=21/39, loss=0.019406, lr=0.000125, time_each_step=0.84s, eta=0:32:5\n",
      "2022-07-06 21:13:08 [INFO]\t[TRAIN] Epoch=442/500, Step=31/39, loss=0.019779, lr=0.000125, time_each_step=0.83s, eta=0:31:42\n",
      "2022-07-06 21:13:14 [INFO]\t[TRAIN] Epoch 442 finished, loss=0.025295775 .\n",
      "2022-07-06 21:13:20 [INFO]\t[TRAIN] Epoch=443/500, Step=2/39, loss=0.021907, lr=0.000125, time_each_step=1.19s, eta=0:44:53\n",
      "2022-07-06 21:13:28 [INFO]\t[TRAIN] Epoch=443/500, Step=12/39, loss=0.028345, lr=0.000125, time_each_step=0.85s, eta=0:32:4\n",
      "2022-07-06 21:13:36 [INFO]\t[TRAIN] Epoch=443/500, Step=22/39, loss=0.041206, lr=0.000125, time_each_step=0.83s, eta=0:31:17\n",
      "2022-07-06 21:13:45 [INFO]\t[TRAIN] Epoch=443/500, Step=32/39, loss=0.040491, lr=0.000125, time_each_step=0.84s, eta=0:31:18\n",
      "2022-07-06 21:13:51 [INFO]\t[TRAIN] Epoch 443 finished, loss=0.025774488 .\n",
      "2022-07-06 21:13:56 [INFO]\t[TRAIN] Epoch=444/500, Step=3/39, loss=0.015841, lr=0.000125, time_each_step=1.09s, eta=0:40:22\n",
      "2022-07-06 21:14:04 [INFO]\t[TRAIN] Epoch=444/500, Step=13/39, loss=0.029024, lr=0.000125, time_each_step=0.86s, eta=0:31:42\n",
      "2022-07-06 21:14:13 [INFO]\t[TRAIN] Epoch=444/500, Step=23/39, loss=0.032078, lr=0.000125, time_each_step=0.83s, eta=0:30:44\n",
      "2022-07-06 21:14:21 [INFO]\t[TRAIN] Epoch=444/500, Step=33/39, loss=0.019528, lr=0.000125, time_each_step=0.84s, eta=0:30:41\n",
      "2022-07-06 21:14:26 [INFO]\t[TRAIN] Epoch 444 finished, loss=0.024888715 .\n",
      "2022-07-06 21:14:32 [INFO]\t[TRAIN] Epoch=445/500, Step=4/39, loss=0.025329, lr=0.000125, time_each_step=1.08s, eta=0:39:34\n",
      "2022-07-06 21:14:41 [INFO]\t[TRAIN] Epoch=445/500, Step=14/39, loss=0.011457, lr=0.000125, time_each_step=0.85s, eta=0:30:45\n",
      "2022-07-06 21:14:49 [INFO]\t[TRAIN] Epoch=445/500, Step=24/39, loss=0.026004, lr=0.000125, time_each_step=0.84s, eta=0:30:16\n",
      "2022-07-06 21:14:57 [INFO]\t[TRAIN] Epoch=445/500, Step=34/39, loss=0.016344, lr=0.000125, time_each_step=0.83s, eta=0:30:1\n",
      "2022-07-06 21:15:01 [INFO]\t[TRAIN] Epoch 445 finished, loss=0.026449041 .\n",
      "2022-07-06 21:15:09 [INFO]\t[TRAIN] Epoch=446/500, Step=5/39, loss=0.022602, lr=0.000125, time_each_step=1.13s, eta=0:40:24\n",
      "2022-07-06 21:15:17 [INFO]\t[TRAIN] Epoch=446/500, Step=15/39, loss=0.047591, lr=0.000125, time_each_step=0.85s, eta=0:30:23\n",
      "2022-07-06 21:15:25 [INFO]\t[TRAIN] Epoch=446/500, Step=25/39, loss=0.035281, lr=0.000125, time_each_step=0.83s, eta=0:29:40\n",
      "2022-07-06 21:15:34 [INFO]\t[TRAIN] Epoch=446/500, Step=35/39, loss=0.014161, lr=0.000125, time_each_step=0.83s, eta=0:29:28\n",
      "2022-07-06 21:15:37 [INFO]\t[TRAIN] Epoch 446 finished, loss=0.024891563 .\n",
      "2022-07-06 21:15:45 [INFO]\t[TRAIN] Epoch=447/500, Step=6/39, loss=0.017595, lr=0.000125, time_each_step=1.09s, eta=0:38:26\n",
      "2022-07-06 21:15:53 [INFO]\t[TRAIN] Epoch=447/500, Step=16/39, loss=0.021316, lr=0.000125, time_each_step=0.84s, eta=0:29:22\n",
      "2022-07-06 21:16:02 [INFO]\t[TRAIN] Epoch=447/500, Step=26/39, loss=0.031218, lr=0.000125, time_each_step=0.84s, eta=0:29:9\n",
      "2022-07-06 21:16:10 [INFO]\t[TRAIN] Epoch=447/500, Step=36/39, loss=0.030846, lr=0.000125, time_each_step=0.83s, eta=0:28:56\n",
      "2022-07-06 21:16:13 [INFO]\t[TRAIN] Epoch 447 finished, loss=0.025015455 .\n",
      "2022-07-06 21:16:21 [INFO]\t[TRAIN] Epoch=448/500, Step=7/39, loss=0.030733, lr=0.000125, time_each_step=1.13s, eta=0:38:49\n",
      "2022-07-06 21:16:30 [INFO]\t[TRAIN] Epoch=448/500, Step=17/39, loss=0.027288, lr=0.000125, time_each_step=0.84s, eta=0:28:51\n",
      "2022-07-06 21:16:38 [INFO]\t[TRAIN] Epoch=448/500, Step=27/39, loss=0.047709, lr=0.000125, time_each_step=0.84s, eta=0:28:40\n",
      "2022-07-06 21:16:46 [INFO]\t[TRAIN] Epoch=448/500, Step=37/39, loss=0.043466, lr=0.000125, time_each_step=0.83s, eta=0:28:25\n",
      "2022-07-06 21:16:48 [INFO]\t[TRAIN] Epoch 448 finished, loss=0.025850534 .\n",
      "2022-07-06 21:16:58 [INFO]\t[TRAIN] Epoch=449/500, Step=8/39, loss=0.038844, lr=0.000125, time_each_step=1.12s, eta=0:37:48\n",
      "2022-07-06 21:17:06 [INFO]\t[TRAIN] Epoch=449/500, Step=18/39, loss=0.034315, lr=0.000125, time_each_step=0.84s, eta=0:28:20\n",
      "2022-07-06 21:17:15 [INFO]\t[TRAIN] Epoch=449/500, Step=28/39, loss=0.028146, lr=0.000125, time_each_step=0.84s, eta=0:28:11\n",
      "2022-07-06 21:17:23 [INFO]\t[TRAIN] Epoch=449/500, Step=38/39, loss=0.027273, lr=0.000125, time_each_step=0.83s, eta=0:27:47\n",
      "2022-07-06 21:17:24 [INFO]\t[TRAIN] Epoch 449 finished, loss=0.024297418 .\n",
      "2022-07-06 21:17:34 [INFO]\t[TRAIN] Epoch=450/500, Step=9/39, loss=0.022580, lr=0.000125, time_each_step=1.1s, eta=0:36:34\n",
      "2022-07-06 21:17:43 [INFO]\t[TRAIN] Epoch=450/500, Step=19/39, loss=0.024618, lr=0.000125, time_each_step=0.85s, eta=0:28:10\n",
      "2022-07-06 21:17:51 [INFO]\t[TRAIN] Epoch=450/500, Step=29/39, loss=0.033819, lr=0.000125, time_each_step=0.83s, eta=0:27:23\n",
      "2022-07-06 21:17:59 [INFO]\t[TRAIN] Epoch=450/500, Step=39/39, loss=0.017544, lr=0.000125, time_each_step=0.83s, eta=0:27:17\n",
      "2022-07-06 21:17:59 [INFO]\t[TRAIN] Epoch 450 finished, loss=0.025982061 .\n",
      "2022-07-06 21:17:59 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 21:17:59 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 21:18:01 [INFO]\t[EVAL] Finished, Epoch=450, miou=0.891544, category_iou=[0.98897635 0.79411213], oacc=0.989426, category_acc=[0.99308669 0.91129039], kappa=0.879705, category_F1-score=[0.99445763 0.88524247] .\n",
      "2022-07-06 21:18:01 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_420, miou=0.8945321201756344\n",
      "2022-07-06 21:18:02 [INFO]\tModel saved in /home/aistudio/exp/epoch_450.\n",
      "2022-07-06 21:18:13 [INFO]\t[TRAIN] Epoch=451/500, Step=10/39, loss=0.024686, lr=0.000125, time_each_step=1.09s, eta=0:35:31\n",
      "2022-07-06 21:18:21 [INFO]\t[TRAIN] Epoch=451/500, Step=20/39, loss=0.023214, lr=0.000125, time_each_step=0.85s, eta=0:27:22\n",
      "2022-07-06 21:18:30 [INFO]\t[TRAIN] Epoch=451/500, Step=30/39, loss=0.014361, lr=0.000125, time_each_step=0.83s, eta=0:26:48\n",
      "2022-07-06 21:18:37 [INFO]\t[TRAIN] Epoch 451 finished, loss=0.026058745 .\n",
      "2022-07-06 21:18:41 [INFO]\t[TRAIN] Epoch=452/500, Step=1/39, loss=0.021168, lr=0.000125, time_each_step=1.11s, eta=0:35:21\n",
      "2022-07-06 21:18:49 [INFO]\t[TRAIN] Epoch=452/500, Step=11/39, loss=0.020873, lr=0.000125, time_each_step=0.85s, eta=0:26:58\n",
      "2022-07-06 21:18:58 [INFO]\t[TRAIN] Epoch=452/500, Step=21/39, loss=0.026785, lr=0.000125, time_each_step=0.84s, eta=0:26:34\n",
      "2022-07-06 21:19:06 [INFO]\t[TRAIN] Epoch=452/500, Step=31/39, loss=0.043527, lr=0.000125, time_each_step=0.83s, eta=0:26:17\n",
      "2022-07-06 21:19:13 [INFO]\t[TRAIN] Epoch 452 finished, loss=0.02580369 .\n",
      "2022-07-06 21:19:17 [INFO]\t[TRAIN] Epoch=453/500, Step=2/39, loss=0.019793, lr=0.000125, time_each_step=1.08s, eta=0:33:51\n",
      "2022-07-06 21:19:26 [INFO]\t[TRAIN] Epoch=453/500, Step=12/39, loss=0.035004, lr=0.000125, time_each_step=0.86s, eta=0:26:49\n",
      "2022-07-06 21:19:34 [INFO]\t[TRAIN] Epoch=453/500, Step=22/39, loss=0.033881, lr=0.000125, time_each_step=0.84s, eta=0:26:2\n",
      "2022-07-06 21:19:42 [INFO]\t[TRAIN] Epoch=453/500, Step=32/39, loss=0.021674, lr=0.000125, time_each_step=0.84s, eta=0:25:54\n",
      "2022-07-06 21:19:48 [INFO]\t[TRAIN] Epoch 453 finished, loss=0.02639381 .\n",
      "2022-07-06 21:19:53 [INFO]\t[TRAIN] Epoch=454/500, Step=3/39, loss=0.020692, lr=0.000125, time_each_step=1.07s, eta=0:32:46\n",
      "2022-07-06 21:20:02 [INFO]\t[TRAIN] Epoch=454/500, Step=13/39, loss=0.038165, lr=0.000125, time_each_step=0.86s, eta=0:26:15\n",
      "2022-07-06 21:20:10 [INFO]\t[TRAIN] Epoch=454/500, Step=23/39, loss=0.021716, lr=0.000125, time_each_step=0.84s, eta=0:25:35\n",
      "2022-07-06 21:20:19 [INFO]\t[TRAIN] Epoch=454/500, Step=33/39, loss=0.020304, lr=0.000125, time_each_step=0.83s, eta=0:25:7\n",
      "2022-07-06 21:20:24 [INFO]\t[TRAIN] Epoch 454 finished, loss=0.024613185 .\n",
      "2022-07-06 21:20:30 [INFO]\t[TRAIN] Epoch=455/500, Step=4/39, loss=0.022505, lr=0.000125, time_each_step=1.09s, eta=0:32:42\n",
      "2022-07-06 21:20:38 [INFO]\t[TRAIN] Epoch=455/500, Step=14/39, loss=0.019268, lr=0.000125, time_each_step=0.87s, eta=0:25:51\n",
      "2022-07-06 21:20:47 [INFO]\t[TRAIN] Epoch=455/500, Step=24/39, loss=0.025087, lr=0.000125, time_each_step=0.84s, eta=0:24:51\n",
      "2022-07-06 21:20:55 [INFO]\t[TRAIN] Epoch=455/500, Step=34/39, loss=0.027581, lr=0.000125, time_each_step=0.83s, eta=0:24:35\n",
      "2022-07-06 21:20:59 [INFO]\t[TRAIN] Epoch 455 finished, loss=0.024615865 .\n",
      "2022-07-06 21:21:06 [INFO]\t[TRAIN] Epoch=456/500, Step=5/39, loss=0.025265, lr=0.000125, time_each_step=1.11s, eta=0:32:39\n",
      "2022-07-06 21:21:15 [INFO]\t[TRAIN] Epoch=456/500, Step=15/39, loss=0.036157, lr=0.000125, time_each_step=0.84s, eta=0:24:31\n",
      "2022-07-06 21:21:23 [INFO]\t[TRAIN] Epoch=456/500, Step=25/39, loss=0.023032, lr=0.000125, time_each_step=0.83s, eta=0:24:11\n",
      "2022-07-06 21:21:31 [INFO]\t[TRAIN] Epoch=456/500, Step=35/39, loss=0.035575, lr=0.000125, time_each_step=0.83s, eta=0:24:6\n",
      "2022-07-06 21:21:35 [INFO]\t[TRAIN] Epoch 456 finished, loss=0.025725108 .\n",
      "2022-07-06 21:21:42 [INFO]\t[TRAIN] Epoch=457/500, Step=6/39, loss=0.025063, lr=0.000125, time_each_step=1.07s, eta=0:30:48\n",
      "2022-07-06 21:21:51 [INFO]\t[TRAIN] Epoch=457/500, Step=16/39, loss=0.020478, lr=0.000125, time_each_step=0.84s, eta=0:24:4\n",
      "2022-07-06 21:21:59 [INFO]\t[TRAIN] Epoch=457/500, Step=26/39, loss=0.029998, lr=0.000125, time_each_step=0.83s, eta=0:23:39\n",
      "2022-07-06 21:22:07 [INFO]\t[TRAIN] Epoch=457/500, Step=36/39, loss=0.021740, lr=0.000125, time_each_step=0.83s, eta=0:23:28\n",
      "2022-07-06 21:22:10 [INFO]\t[TRAIN] Epoch 457 finished, loss=0.025159514 .\n",
      "2022-07-06 21:22:18 [INFO]\t[TRAIN] Epoch=458/500, Step=7/39, loss=0.025961, lr=0.000125, time_each_step=1.08s, eta=0:30:16\n",
      "2022-07-06 21:22:27 [INFO]\t[TRAIN] Epoch=458/500, Step=17/39, loss=0.028716, lr=0.000125, time_each_step=0.84s, eta=0:23:20\n",
      "2022-07-06 21:22:35 [INFO]\t[TRAIN] Epoch=458/500, Step=27/39, loss=0.029152, lr=0.000125, time_each_step=0.84s, eta=0:23:10\n",
      "2022-07-06 21:22:43 [INFO]\t[TRAIN] Epoch=458/500, Step=37/39, loss=0.018982, lr=0.000125, time_each_step=0.84s, eta=0:22:59\n",
      "2022-07-06 21:22:45 [INFO]\t[TRAIN] Epoch 458 finished, loss=0.026221022 .\n",
      "2022-07-06 21:22:55 [INFO]\t[TRAIN] Epoch=459/500, Step=8/39, loss=0.024453, lr=0.000125, time_each_step=1.12s, eta=0:30:36\n",
      "2022-07-06 21:23:03 [INFO]\t[TRAIN] Epoch=459/500, Step=18/39, loss=0.022786, lr=0.000125, time_each_step=0.84s, eta=0:22:54\n",
      "2022-07-06 21:23:12 [INFO]\t[TRAIN] Epoch=459/500, Step=28/39, loss=0.022833, lr=0.000125, time_each_step=0.84s, eta=0:22:37\n",
      "2022-07-06 21:23:20 [INFO]\t[TRAIN] Epoch=459/500, Step=38/39, loss=0.026812, lr=0.000125, time_each_step=0.83s, eta=0:22:21\n",
      "2022-07-06 21:23:21 [INFO]\t[TRAIN] Epoch 459 finished, loss=0.02650901 .\n",
      "2022-07-06 21:23:31 [INFO]\t[TRAIN] Epoch=460/500, Step=9/39, loss=0.021500, lr=0.000125, time_each_step=1.09s, eta=0:28:56\n",
      "2022-07-06 21:23:39 [INFO]\t[TRAIN] Epoch=460/500, Step=19/39, loss=0.020456, lr=0.000125, time_each_step=0.84s, eta=0:22:22\n",
      "2022-07-06 21:23:48 [INFO]\t[TRAIN] Epoch=460/500, Step=29/39, loss=0.038658, lr=0.000125, time_each_step=0.83s, eta=0:21:57\n",
      "2022-07-06 21:23:56 [INFO]\t[TRAIN] Epoch=460/500, Step=39/39, loss=0.015907, lr=0.000125, time_each_step=0.83s, eta=0:21:49\n",
      "2022-07-06 21:23:56 [INFO]\t[TRAIN] Epoch 460 finished, loss=0.025566453 .\n",
      "2022-07-06 21:23:56 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 21:23:56 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 21:23:58 [INFO]\t[EVAL] Finished, Epoch=460, miou=0.893861, category_iou=[0.98911914 0.79860242], oacc=0.989569, category_acc=[0.99368411 0.90377049], kappa=0.882557, category_F1-score=[0.99452981 0.88802551] .\n",
      "2022-07-06 21:23:58 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_420, miou=0.8945321201756344\n",
      "2022-07-06 21:23:59 [INFO]\tModel saved in /home/aistudio/exp/epoch_460.\n",
      "2022-07-06 21:24:10 [INFO]\t[TRAIN] Epoch=461/500, Step=10/39, loss=0.034746, lr=0.000125, time_each_step=1.11s, eta=0:28:43\n",
      "2022-07-06 21:24:18 [INFO]\t[TRAIN] Epoch=461/500, Step=20/39, loss=0.016530, lr=0.000125, time_each_step=0.84s, eta=0:21:34\n",
      "2022-07-06 21:24:26 [INFO]\t[TRAIN] Epoch=461/500, Step=30/39, loss=0.018113, lr=0.000125, time_each_step=0.83s, eta=0:21:22\n",
      "2022-07-06 21:24:34 [INFO]\t[TRAIN] Epoch 461 finished, loss=0.026751677 .\n",
      "2022-07-06 21:24:37 [INFO]\t[TRAIN] Epoch=462/500, Step=1/39, loss=0.029057, lr=0.000125, time_each_step=1.08s, eta=0:27:27\n",
      "2022-07-06 21:24:46 [INFO]\t[TRAIN] Epoch=462/500, Step=11/39, loss=0.029904, lr=0.000125, time_each_step=0.87s, eta=0:21:56\n",
      "2022-07-06 21:24:54 [INFO]\t[TRAIN] Epoch=462/500, Step=21/39, loss=0.047143, lr=0.000125, time_each_step=0.84s, eta=0:21:2\n",
      "2022-07-06 21:25:03 [INFO]\t[TRAIN] Epoch=462/500, Step=31/39, loss=0.026615, lr=0.000125, time_each_step=0.84s, eta=0:20:54\n",
      "2022-07-06 21:25:09 [INFO]\t[TRAIN] Epoch 462 finished, loss=0.025228353 .\n",
      "2022-07-06 21:25:14 [INFO]\t[TRAIN] Epoch=463/500, Step=2/39, loss=0.019707, lr=0.000125, time_each_step=1.09s, eta=0:27:6\n",
      "2022-07-06 21:25:22 [INFO]\t[TRAIN] Epoch=463/500, Step=12/39, loss=0.027800, lr=0.000125, time_each_step=0.84s, eta=0:20:48\n",
      "2022-07-06 21:25:30 [INFO]\t[TRAIN] Epoch=463/500, Step=22/39, loss=0.032642, lr=0.000125, time_each_step=0.83s, eta=0:20:24\n",
      "2022-07-06 21:25:39 [INFO]\t[TRAIN] Epoch=463/500, Step=32/39, loss=0.018418, lr=0.000125, time_each_step=0.83s, eta=0:20:15\n",
      "2022-07-06 21:25:45 [INFO]\t[TRAIN] Epoch 463 finished, loss=0.025904054 .\n",
      "2022-07-06 21:25:50 [INFO]\t[TRAIN] Epoch=464/500, Step=3/39, loss=0.024006, lr=0.000125, time_each_step=1.08s, eta=0:26:1\n",
      "2022-07-06 21:25:58 [INFO]\t[TRAIN] Epoch=464/500, Step=13/39, loss=0.025950, lr=0.000125, time_each_step=0.84s, eta=0:20:8\n",
      "2022-07-06 21:26:06 [INFO]\t[TRAIN] Epoch=464/500, Step=23/39, loss=0.018214, lr=0.000125, time_each_step=0.83s, eta=0:19:52\n",
      "2022-07-06 21:26:15 [INFO]\t[TRAIN] Epoch=464/500, Step=33/39, loss=0.018625, lr=0.000125, time_each_step=0.84s, eta=0:19:45\n",
      "2022-07-06 21:26:20 [INFO]\t[TRAIN] Epoch 464 finished, loss=0.026792832 .\n",
      "2022-07-06 21:26:26 [INFO]\t[TRAIN] Epoch=465/500, Step=4/39, loss=0.017243, lr=0.000125, time_each_step=1.08s, eta=0:25:17\n",
      "2022-07-06 21:26:34 [INFO]\t[TRAIN] Epoch=465/500, Step=14/39, loss=0.019394, lr=0.000125, time_each_step=0.84s, eta=0:19:31\n",
      "2022-07-06 21:26:42 [INFO]\t[TRAIN] Epoch=465/500, Step=24/39, loss=0.034202, lr=0.000125, time_each_step=0.83s, eta=0:19:17\n",
      "2022-07-06 21:26:51 [INFO]\t[TRAIN] Epoch=465/500, Step=34/39, loss=0.025831, lr=0.000125, time_each_step=0.84s, eta=0:19:16\n",
      "2022-07-06 21:26:55 [INFO]\t[TRAIN] Epoch 465 finished, loss=0.026454434 .\n",
      "2022-07-06 21:27:02 [INFO]\t[TRAIN] Epoch=466/500, Step=5/39, loss=0.019627, lr=0.000125, time_each_step=1.07s, eta=0:24:22\n",
      "2022-07-06 21:27:10 [INFO]\t[TRAIN] Epoch=466/500, Step=15/39, loss=0.017131, lr=0.000125, time_each_step=0.84s, eta=0:19:2\n",
      "2022-07-06 21:27:18 [INFO]\t[TRAIN] Epoch=466/500, Step=25/39, loss=0.027812, lr=0.000125, time_each_step=0.84s, eta=0:18:47\n",
      "2022-07-06 21:27:27 [INFO]\t[TRAIN] Epoch=466/500, Step=35/39, loss=0.022214, lr=0.000125, time_each_step=0.83s, eta=0:18:36\n",
      "2022-07-06 21:27:30 [INFO]\t[TRAIN] Epoch 466 finished, loss=0.025491651 .\n",
      "2022-07-06 21:27:38 [INFO]\t[TRAIN] Epoch=467/500, Step=6/39, loss=0.037663, lr=0.000125, time_each_step=1.08s, eta=0:23:55\n",
      "2022-07-06 21:27:46 [INFO]\t[TRAIN] Epoch=467/500, Step=16/39, loss=0.035529, lr=0.000125, time_each_step=0.84s, eta=0:18:28\n",
      "2022-07-06 21:27:54 [INFO]\t[TRAIN] Epoch=467/500, Step=26/39, loss=0.019309, lr=0.000125, time_each_step=0.84s, eta=0:18:15\n",
      "2022-07-06 21:28:03 [INFO]\t[TRAIN] Epoch=467/500, Step=36/39, loss=0.028095, lr=0.000125, time_each_step=0.83s, eta=0:18:1\n",
      "2022-07-06 21:28:05 [INFO]\t[TRAIN] Epoch 467 finished, loss=0.024417492 .\n",
      "2022-07-06 21:28:14 [INFO]\t[TRAIN] Epoch=468/500, Step=7/39, loss=0.029042, lr=0.000125, time_each_step=1.08s, eta=0:23:14\n",
      "2022-07-06 21:28:22 [INFO]\t[TRAIN] Epoch=468/500, Step=17/39, loss=0.016233, lr=0.000125, time_each_step=0.84s, eta=0:17:59\n",
      "2022-07-06 21:28:30 [INFO]\t[TRAIN] Epoch=468/500, Step=27/39, loss=0.024057, lr=0.000125, time_each_step=0.83s, eta=0:17:37\n",
      "2022-07-06 21:28:39 [INFO]\t[TRAIN] Epoch=468/500, Step=37/39, loss=0.033942, lr=0.000125, time_each_step=0.83s, eta=0:17:30\n",
      "2022-07-06 21:28:41 [INFO]\t[TRAIN] Epoch 468 finished, loss=0.024752716 .\n",
      "2022-07-06 21:28:50 [INFO]\t[TRAIN] Epoch=469/500, Step=8/39, loss=0.017772, lr=0.000125, time_each_step=1.08s, eta=0:22:25\n",
      "2022-07-06 21:28:58 [INFO]\t[TRAIN] Epoch=469/500, Step=18/39, loss=0.029618, lr=0.000125, time_each_step=0.84s, eta=0:17:24\n",
      "2022-07-06 21:29:06 [INFO]\t[TRAIN] Epoch=469/500, Step=28/39, loss=0.044900, lr=0.000125, time_each_step=0.83s, eta=0:17:3\n",
      "2022-07-06 21:29:15 [INFO]\t[TRAIN] Epoch=469/500, Step=38/39, loss=0.030598, lr=0.000125, time_each_step=0.83s, eta=0:16:53\n",
      "2022-07-06 21:29:16 [INFO]\t[TRAIN] Epoch 469 finished, loss=0.025808958 .\n",
      "2022-07-06 21:29:26 [INFO]\t[TRAIN] Epoch=470/500, Step=9/39, loss=0.028770, lr=0.000125, time_each_step=1.1s, eta=0:22:0\n",
      "2022-07-06 21:29:34 [INFO]\t[TRAIN] Epoch=470/500, Step=19/39, loss=0.027782, lr=0.000125, time_each_step=0.83s, eta=0:16:36\n",
      "2022-07-06 21:29:42 [INFO]\t[TRAIN] Epoch=470/500, Step=29/39, loss=0.032252, lr=0.000125, time_each_step=0.83s, eta=0:16:28\n",
      "2022-07-06 21:29:51 [INFO]\t[TRAIN] Epoch=470/500, Step=39/39, loss=0.019839, lr=0.000125, time_each_step=0.83s, eta=0:16:18\n",
      "2022-07-06 21:29:51 [INFO]\t[TRAIN] Epoch 470 finished, loss=0.02523526 .\n",
      "2022-07-06 21:29:51 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 21:29:51 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 21:29:53 [INFO]\t[EVAL] Finished, Epoch=470, miou=0.892567, category_iou=[0.98903855 0.79609626], oacc=0.989488, category_acc=[0.99335142 0.90789354], kappa=0.880966, category_F1-score=[0.99448907 0.88647394] .\n",
      "2022-07-06 21:29:53 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_420, miou=0.8945321201756344\n",
      "2022-07-06 21:29:53 [INFO]\tModel saved in /home/aistudio/exp/epoch_470.\n",
      "2022-07-06 21:30:05 [INFO]\t[TRAIN] Epoch=471/500, Step=10/39, loss=0.023526, lr=0.000125, time_each_step=1.13s, eta=0:21:52\n",
      "2022-07-06 21:30:13 [INFO]\t[TRAIN] Epoch=471/500, Step=20/39, loss=0.024345, lr=0.000125, time_each_step=0.83s, eta=0:16:3\n",
      "2022-07-06 21:30:21 [INFO]\t[TRAIN] Epoch=471/500, Step=30/39, loss=0.025857, lr=0.000125, time_each_step=0.84s, eta=0:15:59\n",
      "2022-07-06 21:30:29 [INFO]\t[TRAIN] Epoch 471 finished, loss=0.02519785 .\n",
      "2022-07-06 21:30:32 [INFO]\t[TRAIN] Epoch=472/500, Step=1/39, loss=0.023866, lr=0.000125, time_each_step=1.07s, eta=0:20:19\n",
      "2022-07-06 21:30:41 [INFO]\t[TRAIN] Epoch=472/500, Step=11/39, loss=0.026822, lr=0.000125, time_each_step=0.85s, eta=0:15:58\n",
      "2022-07-06 21:30:49 [INFO]\t[TRAIN] Epoch=472/500, Step=21/39, loss=0.026225, lr=0.000125, time_each_step=0.83s, eta=0:15:29\n",
      "2022-07-06 21:30:57 [INFO]\t[TRAIN] Epoch=472/500, Step=31/39, loss=0.027333, lr=0.000125, time_each_step=0.83s, eta=0:15:22\n",
      "2022-07-06 21:31:04 [INFO]\t[TRAIN] Epoch 472 finished, loss=0.0253481 .\n",
      "2022-07-06 21:31:08 [INFO]\t[TRAIN] Epoch=473/500, Step=2/39, loss=0.021218, lr=0.000125, time_each_step=1.07s, eta=0:19:34\n",
      "2022-07-06 21:31:17 [INFO]\t[TRAIN] Epoch=473/500, Step=12/39, loss=0.021331, lr=0.000125, time_each_step=0.84s, eta=0:15:17\n",
      "2022-07-06 21:31:25 [INFO]\t[TRAIN] Epoch=473/500, Step=22/39, loss=0.013294, lr=0.000125, time_each_step=0.84s, eta=0:15:5\n",
      "2022-07-06 21:31:33 [INFO]\t[TRAIN] Epoch=473/500, Step=32/39, loss=0.021226, lr=0.000125, time_each_step=0.83s, eta=0:14:48\n",
      "2022-07-06 21:31:39 [INFO]\t[TRAIN] Epoch 473 finished, loss=0.0255422 .\n",
      "2022-07-06 21:31:44 [INFO]\t[TRAIN] Epoch=474/500, Step=3/39, loss=0.024190, lr=0.000125, time_each_step=1.07s, eta=0:18:50\n",
      "2022-07-06 21:31:53 [INFO]\t[TRAIN] Epoch=474/500, Step=13/39, loss=0.022348, lr=0.000125, time_each_step=0.84s, eta=0:14:42\n",
      "2022-07-06 21:32:01 [INFO]\t[TRAIN] Epoch=474/500, Step=23/39, loss=0.015322, lr=0.000125, time_each_step=0.83s, eta=0:14:25\n",
      "2022-07-06 21:32:09 [INFO]\t[TRAIN] Epoch=474/500, Step=33/39, loss=0.018037, lr=0.000125, time_each_step=0.84s, eta=0:14:22\n",
      "2022-07-06 21:32:14 [INFO]\t[TRAIN] Epoch 474 finished, loss=0.025212044 .\n",
      "2022-07-06 21:32:20 [INFO]\t[TRAIN] Epoch=475/500, Step=4/39, loss=0.043826, lr=0.000125, time_each_step=1.07s, eta=0:18:11\n",
      "2022-07-06 21:32:29 [INFO]\t[TRAIN] Epoch=475/500, Step=14/39, loss=0.031821, lr=0.000125, time_each_step=0.85s, eta=0:14:20\n",
      "2022-07-06 21:32:37 [INFO]\t[TRAIN] Epoch=475/500, Step=24/39, loss=0.016947, lr=0.000125, time_each_step=0.83s, eta=0:13:50\n",
      "2022-07-06 21:32:45 [INFO]\t[TRAIN] Epoch=475/500, Step=34/39, loss=0.014252, lr=0.000125, time_each_step=0.83s, eta=0:13:42\n",
      "2022-07-06 21:32:50 [INFO]\t[TRAIN] Epoch 475 finished, loss=0.025701117 .\n",
      "2022-07-06 21:32:56 [INFO]\t[TRAIN] Epoch=476/500, Step=5/39, loss=0.038275, lr=0.000125, time_each_step=1.08s, eta=0:17:31\n",
      "2022-07-06 21:33:05 [INFO]\t[TRAIN] Epoch=476/500, Step=15/39, loss=0.013774, lr=0.000125, time_each_step=0.84s, eta=0:13:31\n",
      "2022-07-06 21:33:13 [INFO]\t[TRAIN] Epoch=476/500, Step=25/39, loss=0.029493, lr=0.000125, time_each_step=0.84s, eta=0:13:20\n",
      "2022-07-06 21:33:21 [INFO]\t[TRAIN] Epoch=476/500, Step=35/39, loss=0.012055, lr=0.000125, time_each_step=0.83s, eta=0:13:8\n",
      "2022-07-06 21:33:25 [INFO]\t[TRAIN] Epoch 476 finished, loss=0.025659863 .\n",
      "2022-07-06 21:33:32 [INFO]\t[TRAIN] Epoch=477/500, Step=6/39, loss=0.033704, lr=0.000125, time_each_step=1.1s, eta=0:17:9\n",
      "2022-07-06 21:33:41 [INFO]\t[TRAIN] Epoch=477/500, Step=16/39, loss=0.022675, lr=0.000125, time_each_step=0.84s, eta=0:13:1\n",
      "2022-07-06 21:33:49 [INFO]\t[TRAIN] Epoch=477/500, Step=26/39, loss=0.034817, lr=0.000125, time_each_step=0.83s, eta=0:12:43\n",
      "2022-07-06 21:33:58 [INFO]\t[TRAIN] Epoch=477/500, Step=36/39, loss=0.028848, lr=0.000125, time_each_step=0.83s, eta=0:12:35\n",
      "2022-07-06 21:34:00 [INFO]\t[TRAIN] Epoch 477 finished, loss=0.0259449 .\n",
      "2022-07-06 21:34:09 [INFO]\t[TRAIN] Epoch=478/500, Step=7/39, loss=0.049390, lr=0.000125, time_each_step=1.1s, eta=0:16:26\n",
      "2022-07-06 21:34:17 [INFO]\t[TRAIN] Epoch=478/500, Step=17/39, loss=0.016547, lr=0.000125, time_each_step=0.85s, eta=0:12:35\n",
      "2022-07-06 21:34:26 [INFO]\t[TRAIN] Epoch=478/500, Step=27/39, loss=0.022234, lr=0.000125, time_each_step=0.83s, eta=0:12:11\n",
      "2022-07-06 21:34:34 [INFO]\t[TRAIN] Epoch=478/500, Step=37/39, loss=0.023550, lr=0.000125, time_each_step=0.83s, eta=0:12:2\n",
      "2022-07-06 21:34:36 [INFO]\t[TRAIN] Epoch 478 finished, loss=0.025171565 .\n",
      "2022-07-06 21:34:45 [INFO]\t[TRAIN] Epoch=479/500, Step=8/39, loss=0.019315, lr=0.000125, time_each_step=1.08s, eta=0:15:27\n",
      "2022-07-06 21:34:53 [INFO]\t[TRAIN] Epoch=479/500, Step=18/39, loss=0.021322, lr=0.000125, time_each_step=0.84s, eta=0:11:48\n",
      "2022-07-06 21:35:02 [INFO]\t[TRAIN] Epoch=479/500, Step=28/39, loss=0.033405, lr=0.000125, time_each_step=0.83s, eta=0:11:38\n",
      "2022-07-06 21:35:10 [INFO]\t[TRAIN] Epoch=479/500, Step=38/39, loss=0.023175, lr=0.000125, time_each_step=0.84s, eta=0:11:30\n",
      "2022-07-06 21:35:11 [INFO]\t[TRAIN] Epoch 479 finished, loss=0.025655838 .\n",
      "2022-07-06 21:35:21 [INFO]\t[TRAIN] Epoch=480/500, Step=9/39, loss=0.035731, lr=0.000125, time_each_step=1.1s, eta=0:14:57\n",
      "2022-07-06 21:35:29 [INFO]\t[TRAIN] Epoch=480/500, Step=19/39, loss=0.010325, lr=0.000125, time_each_step=0.84s, eta=0:11:12\n",
      "2022-07-06 21:35:38 [INFO]\t[TRAIN] Epoch=480/500, Step=29/39, loss=0.030445, lr=0.000125, time_each_step=0.84s, eta=0:11:5\n",
      "2022-07-06 21:35:46 [INFO]\t[TRAIN] Epoch=480/500, Step=39/39, loss=0.016451, lr=0.000125, time_each_step=0.83s, eta=0:10:54\n",
      "2022-07-06 21:35:46 [INFO]\t[TRAIN] Epoch 480 finished, loss=0.024782633 .\n",
      "2022-07-06 21:35:46 [WARNING]\tSegmenter only supports batch_size=1 for each gpu/cpu card during evaluation, so batch_size is forcibly set to 1.\n",
      "2022-07-06 21:35:46 [INFO]\tStart to evaluate(total_samples=10, total_steps=10)...\n",
      "2022-07-06 21:35:48 [INFO]\t[EVAL] Finished, Epoch=480, miou=0.892474, category_iou=[0.98909815 0.79584937], oacc=0.989543, category_acc=[0.99306932 0.91399877], kappa=0.880845, category_F1-score=[0.9945192  0.88632085] .\n",
      "2022-07-06 21:35:48 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_420, miou=0.8945321201756344\n",
      "2022-07-06 21:35:49 [INFO]\tModel saved in /home/aistudio/exp/epoch_480.\n",
      "2022-07-06 21:35:59 [INFO]\t[TRAIN] Epoch=481/500, Step=10/39, loss=0.038769, lr=0.000125, time_each_step=1.08s, eta=0:13:56\n",
      "2022-07-06 21:36:08 [INFO]\t[TRAIN] Epoch=481/500, Step=20/39, loss=0.018910, lr=0.000125, time_each_step=0.83s, eta=0:10:37\n",
      "2022-07-06 21:36:16 [INFO]\t[TRAIN] Epoch=481/500, Step=30/39, loss=0.016995, lr=0.000125, time_each_step=0.83s, eta=0:10:28\n",
      "2022-07-06 21:36:24 [INFO]\t[TRAIN] Epoch 481 finished, loss=0.026336774 .\n",
      "2022-07-06 21:36:27 [INFO]\t[TRAIN] Epoch=482/500, Step=1/39, loss=0.027827, lr=0.000125, time_each_step=1.08s, eta=0:13:19\n",
      "2022-07-06 21:36:35 [INFO]\t[TRAIN] Epoch=482/500, Step=11/39, loss=0.021272, lr=0.000125, time_each_step=0.85s, eta=0:10:21\n",
      "2022-07-06 21:36:44 [INFO]\t[TRAIN] Epoch=482/500, Step=21/39, loss=0.023481, lr=0.000125, time_each_step=0.84s, eta=0:10:8\n",
      "2022-07-06 21:36:52 [INFO]\t[TRAIN] Epoch=482/500, Step=31/39, loss=0.028454, lr=0.000125, time_each_step=0.83s, eta=0:9:55\n",
      "2022-07-06 21:36:59 [INFO]\t[TRAIN] Epoch 482 finished, loss=0.0271421 .\n",
      "2022-07-06 21:37:03 [INFO]\t[TRAIN] Epoch=483/500, Step=2/39, loss=0.029911, lr=0.000125, time_each_step=1.06s, eta=0:12:29\n",
      "2022-07-06 21:37:11 [INFO]\t[TRAIN] Epoch=483/500, Step=12/39, loss=0.047259, lr=0.000125, time_each_step=0.84s, eta=0:9:46\n",
      "2022-07-06 21:37:20 [INFO]\t[TRAIN] Epoch=483/500, Step=22/39, loss=0.023856, lr=0.000125, time_each_step=0.83s, eta=0:9:30\n",
      "2022-07-06 21:37:28 [INFO]\t[TRAIN] Epoch=483/500, Step=32/39, loss=0.026055, lr=0.000125, time_each_step=0.84s, eta=0:9:25\n",
      "2022-07-06 21:37:34 [INFO]\t[TRAIN] Epoch 483 finished, loss=0.024801422 .\n",
      "2022-07-06 21:37:39 [INFO]\t[TRAIN] Epoch=484/500, Step=3/39, loss=0.023592, lr=0.000125, time_each_step=1.07s, eta=0:11:51\n",
      "2022-07-06 21:37:47 [INFO]\t[TRAIN] Epoch=484/500, Step=13/39, loss=0.030666, lr=0.000125, time_each_step=0.85s, eta=0:9:18\n",
      "2022-07-06 21:37:56 [INFO]\t[TRAIN] Epoch=484/500, Step=23/39, loss=0.024069, lr=0.000125, time_each_step=0.83s, eta=0:8:57\n",
      "2022-07-06 21:38:04 [INFO]\t[TRAIN] Epoch=484/500, Step=33/39, loss=0.017283, lr=0.000125, time_each_step=0.83s, eta=0:8:48\n",
      "2022-07-06 21:38:09 [INFO]\t[TRAIN] Epoch 484 finished, loss=0.024801634 .\n",
      "2022-07-06 21:38:15 [INFO]\t[TRAIN] Epoch=485/500, Step=4/39, loss=0.023662, lr=0.000125, time_each_step=1.09s, eta=0:11:20\n",
      "2022-07-06 21:38:24 [INFO]\t[TRAIN] Epoch=485/500, Step=14/39, loss=0.028393, lr=0.000125, time_each_step=0.84s, eta=0:8:38\n",
      "2022-07-06 21:38:32 [INFO]\t[TRAIN] Epoch=485/500, Step=24/39, loss=0.037909, lr=0.000125, time_each_step=0.84s, eta=0:8:25\n",
      "2022-07-06 21:38:40 [INFO]\t[TRAIN] Epoch=485/500, Step=34/39, loss=0.011625, lr=0.000125, time_each_step=0.83s, eta=0:8:14\n",
      "2022-07-06 21:38:45 [INFO]\t[TRAIN] Epoch 485 finished, loss=0.025460724 .\n",
      "2022-07-06 21:38:52 [INFO]\t[TRAIN] Epoch=486/500, Step=5/39, loss=0.037409, lr=0.000125, time_each_step=1.11s, eta=0:10:45\n",
      "2022-07-06 21:39:00 [INFO]\t[TRAIN] Epoch=486/500, Step=15/39, loss=0.012903, lr=0.000125, time_each_step=0.84s, eta=0:8:2\n",
      "2022-07-06 21:39:08 [INFO]\t[TRAIN] Epoch=486/500, Step=25/39, loss=0.024720, lr=0.000125, time_each_step=0.83s, eta=0:7:50\n",
      "2022-07-06 21:39:17 [INFO]\t[TRAIN] Epoch=486/500, Step=35/39, loss=0.019182, lr=0.000125, time_each_step=0.84s, eta=0:7:43\n",
      "2022-07-06 21:39:20 [INFO]\t[TRAIN] Epoch 486 finished, loss=0.024756992 .\n",
      "2022-07-06 21:39:27 [INFO]\t[TRAIN] Epoch=487/500, Step=6/39, loss=0.028005, lr=0.000125, time_each_step=1.08s, eta=0:9:45\n",
      "2022-07-06 21:39:36 [INFO]\t[TRAIN] Epoch=487/500, Step=16/39, loss=0.017680, lr=0.000125, time_each_step=0.84s, eta=0:7:30\n",
      "2022-07-06 21:39:44 [INFO]\t[TRAIN] Epoch=487/500, Step=26/39, loss=0.030458, lr=0.000125, time_each_step=0.84s, eta=0:7:18\n",
      "2022-07-06 21:39:53 [INFO]\t[TRAIN] Epoch=487/500, Step=36/39, loss=0.034733, lr=0.000125, time_each_step=0.83s, eta=0:7:9\n",
      "2022-07-06 21:39:55 [INFO]\t[TRAIN] Epoch 487 finished, loss=0.025726382 .\n",
      "2022-07-06 21:40:04 [INFO]\t[TRAIN] Epoch=488/500, Step=7/39, loss=0.016870, lr=0.000125, time_each_step=1.08s, eta=0:9:3\n",
      "2022-07-06 21:40:12 [INFO]\t[TRAIN] Epoch=488/500, Step=17/39, loss=0.025271, lr=0.000125, time_each_step=0.84s, eta=0:6:55\n"
     ]
    }
   ],
   "source": [
    "# 调用PaddleRS API实现一键训练\n",
    "model.train(\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    train_dataset=train_dataset,\n",
    "    train_batch_size=TRAIN_BATCH_SIZE,\n",
    "    eval_dataset=eval_dataset,\n",
    "    optimizer=optimizer,\n",
    "    save_interval_epochs=SAVE_INTERVAL_EPOCHS,\n",
    "    # 每多少次迭代记录一次日志\n",
    "    log_interval_steps=10,  \n",
    "    save_dir=EXP_DIR,\n",
    "    # 是否使用early stopping策略，当精度不再改善时提前终止训练\n",
    "    early_stop=False,\n",
    "    # 是否启用VisualDL日志功能\n",
    "    use_vdl=True,\n",
    "    # 指定从某个检查点继续训练\n",
    "    resume_checkpoint=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 查看实验目录中存储的已训练好的模型\n",
    "# `best_model`子目录对应验证集上指标最好的模型\n",
    "# 其中，`eval_details.json`包含验证阶段记录的混淆矩阵信息；`model.pdopt`包含训练过程中使用到的优化器的状态参数；\n",
    "# `model.pdparams`包含模型的权重参数；`model.yml`包含模型的配置文件（包括预处理参数、模型规格参数等）\n",
    "!ls /home/aistudio/exp/best_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型推理\n",
    "\n",
    "使用AI Studio高级版硬件配置（16G V100）和默认的超参数，推理总时长约为4分钟。\n",
    "\n",
    "推理脚本使用固定阈值法从变化概率图获取二值变化图（binary change map），默认阈值为0.5，可根据模型实际表现调整阈值。当然，也可以换用[Otsu法](https://baike.baidu.com/item/otsu/16252828?fr=aladdin)、[k-means聚类法](https://baike.baidu.com/item/K%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/15779627)等更先进的阈值分割算法。\n",
    "        \n",
    "模型前向推理结果存储在`EXP_DIR`目录下的out子目录中，可将该子目录内的文件打包、并将压缩文件重命名后提交到比赛系统。在提交结果前，请仔细阅读[提交规范](https://aistudio.baidu.com/aistudio/competition/detail/151/0/submit-result)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义推理阶段使用的数据集\n",
    "\n",
    "class InferDataset(paddle.io.Dataset):\n",
    "    \"\"\"\n",
    "    变化检测推理数据集。\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): 数据集所在的目录路径。\n",
    "        transforms (paddlers.transforms.Compose): 需要执行的数据变换操作。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir,\n",
    "        transforms\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.data_dir = data_dir\n",
    "        self.transforms = deepcopy(transforms)\n",
    "\n",
    "        pdrs.transforms.arrange_transforms(\n",
    "            model_type='changedetector',\n",
    "            transforms=self.transforms,\n",
    "            mode='test'\n",
    "        )\n",
    "\n",
    "        with open(osp.join(data_dir, 'test.txt'), 'r') as f:\n",
    "            lines = f.read()\n",
    "            lines = lines.strip().split('\\n')\n",
    "\n",
    "        samples = []\n",
    "        names = []\n",
    "        for line in lines:\n",
    "            items = line.strip().split(' ')\n",
    "            items = list(map(pdrs.utils.path_normalization, items))\n",
    "            item_dict = {\n",
    "                'image_t1': osp.join(data_dir, items[0]),\n",
    "                'image_t2': osp.join(data_dir, items[1])\n",
    "            }\n",
    "            samples.append(item_dict)\n",
    "            names.append(osp.basename(items[0]))\n",
    "\n",
    "        self.samples = samples\n",
    "        self.names = names\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name = self.names[idx]\n",
    "        sample = deepcopy(self.samples[idx])\n",
    "        output = self.transforms(sample)\n",
    "        return name, \\\n",
    "               paddle.to_tensor(output[0]), \\\n",
    "               paddle.to_tensor(output[1]),\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 考虑到原始影像尺寸较大，以下类和函数与影像裁块-拼接有关。\n",
    "\n",
    "class WindowGenerator:\n",
    "    def __init__(self, h, w, ch, cw, si=1, sj=1):\n",
    "        self.h = h\n",
    "        self.w = w\n",
    "        self.ch = ch\n",
    "        self.cw = cw\n",
    "        if self.h < self.ch or self.w < self.cw:\n",
    "            raise NotImplementedError\n",
    "        self.si = si\n",
    "        self.sj = sj\n",
    "        self._i, self._j = 0, 0\n",
    "\n",
    "    def __next__(self):\n",
    "        # 列优先移动（C-order）\n",
    "        if self._i > self.h:\n",
    "            raise StopIteration\n",
    "        \n",
    "        bottom = min(self._i+self.ch, self.h)\n",
    "        right = min(self._j+self.cw, self.w)\n",
    "        top = max(0, bottom-self.ch)\n",
    "        left = max(0, right-self.cw)\n",
    "\n",
    "        if self._j >= self.w-self.cw:\n",
    "            if self._i >= self.h-self.ch:\n",
    "                # 设置一个非法值，使得迭代可以early stop\n",
    "                self._i = self.h+1\n",
    "            self._goto_next_row()\n",
    "        else:\n",
    "            self._j += self.sj\n",
    "            if self._j > self.w:\n",
    "                self._goto_next_row()\n",
    "\n",
    "        return slice(top, bottom, 1), slice(left, right, 1)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def _goto_next_row(self):\n",
    "        self._i += self.si\n",
    "        self._j = 0\n",
    "\n",
    "    \n",
    "def crop_patches(dataloader, ori_size, window_size, stride):\n",
    "    \"\"\"\n",
    "    将`dataloader`中的数据裁块。\n",
    "\n",
    "    Args:\n",
    "        dataloader (paddle.io.DataLoader): 可迭代对象，能够产生原始样本（每个样本中包含任意数量影像）。\n",
    "        ori_size (tuple): 原始影像的长和宽，表示为二元组形式(h,w)。\n",
    "        window_size (int): 裁块大小。\n",
    "        stride (int): 裁块使用的滑窗每次在水平或垂直方向上移动的像素数。\n",
    "\n",
    "    Returns:\n",
    "        一个生成器，能够产生iter(`dataloader`)中每一项的裁块结果。一幅图像产生的块在batch维度拼接。例如，当`ori_size`为1024，而\n",
    "            `window_size`和`stride`均为512时，`crop_patches`返回的每一项的batch_size都将是iter(`dataloader`)中对应项的4倍。\n",
    "    \"\"\"\n",
    "\n",
    "    for name, *ims in dataloader:\n",
    "        ims = list(ims)\n",
    "        h, w = ori_size\n",
    "        win_gen = WindowGenerator(h, w, window_size, window_size, stride, stride)\n",
    "        all_patches = []\n",
    "        for rows, cols in win_gen:\n",
    "            # NOTE: 此处不能使用生成器，否则因为lazy evaluation的缘故会导致结果不是预期的\n",
    "            patches = [im[...,rows,cols] for im in ims]\n",
    "            all_patches.append(patches)\n",
    "        yield name[0], tuple(map(partial(paddle.concat, axis=0), zip(*all_patches)))\n",
    "\n",
    "\n",
    "def recons_prob_map(patches, ori_size, window_size, stride):\n",
    "    \"\"\"从裁块结果重建原始尺寸影像，与`crop_patches`相对应\"\"\"\n",
    "    # NOTE: 目前只能处理batch size为1的情况\n",
    "    h, w = ori_size\n",
    "    win_gen = WindowGenerator(h, w, window_size, window_size, stride, stride)\n",
    "    prob_map = np.zeros((h,w), dtype=np.float)\n",
    "    cnt = np.zeros((h,w), dtype=np.float)\n",
    "    # XXX: 需要保证win_gen与patches具有相同长度。此处未做检查\n",
    "    for (rows, cols), patch in zip(win_gen, patches):\n",
    "        prob_map[rows, cols] += patch\n",
    "        cnt[rows, cols] += 1\n",
    "    prob_map /= cnt\n",
    "    return prob_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 若输出目录不存在，则新建之（递归创建目录）\n",
    "out_dir = osp.join(EXP_DIR, 'out')\n",
    "if not osp.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "# 为模型加载历史最佳权重\n",
    "state_dict = paddle.load(BEST_CKP_PATH)\n",
    "# 同样通过net属性访问组网对象\n",
    "model.net.set_state_dict(state_dict)\n",
    "\n",
    "# 实例化测试集\n",
    "test_dataset = InferDataset(\n",
    "    DATA_DIR,\n",
    "    # 注意，测试阶段使用的归一化方式需与训练时相同\n",
    "    T.Compose([\n",
    "        T.Normalize(\n",
    "            mean=[0.5, 0.5, 0.5],\n",
    "            std=[0.5, 0.5, 0.5]\n",
    "        )\n",
    "    ])\n",
    ")\n",
    "\n",
    "# 创建DataLoader\n",
    "test_dataloader = paddle.io.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    return_list=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 推理过程主循环\n",
    "info(\"模型推理开始\")\n",
    "\n",
    "model.net.eval()\n",
    "len_test = len(test_dataset)\n",
    "test_patches = crop_patches(\n",
    "    test_dataloader,\n",
    "    ORIGINAL_SIZE,\n",
    "    CROP_SIZE,\n",
    "    STRIDE\n",
    ")\n",
    "with paddle.no_grad():\n",
    "    for name, (t1, t2) in tqdm(test_patches, total=len_test):\n",
    "        shape = paddle.shape(t1)\n",
    "        pred = paddle.zeros(shape=(shape[0],2,*shape[2:]))\n",
    "        for i in range(0, shape[0], INFER_BATCH_SIZE):\n",
    "            pred[i:i+INFER_BATCH_SIZE] = model.net(t1[i:i+INFER_BATCH_SIZE], t2[i:i+INFER_BATCH_SIZE])[0]\n",
    "        # 取softmax结果的第1（从0开始计数）个通道的输出作为变化概率\n",
    "        prob = paddle.nn.functional.softmax(pred, axis=1)[:,1]\n",
    "        # 由patch重建完整概率图\n",
    "        prob = recons_prob_map(prob.numpy(), ORIGINAL_SIZE, CROP_SIZE, STRIDE)\n",
    "        # 默认将阈值设置为0.5，即，将变化概率大于0.5的像素点分为变化类\n",
    "        out = quantize(prob>0.41)\n",
    "\n",
    "        imsave(osp.join(out_dir, name), out, check_contrast=False)\n",
    "\n",
    "info(\"模型推理完成\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 推理结果展示\n",
    "# 重复运行本单元可以查看不同结果\n",
    "\n",
    "def show_images_in_row(im_paths, fig, title=''):\n",
    "    n = len(im_paths)\n",
    "    fig.suptitle(title)\n",
    "    axs = fig.subplots(nrows=1, ncols=n)\n",
    "    for idx, (path, ax) in enumerate(zip(im_paths, axs)):\n",
    "        # 去掉刻度线和边框\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['bottom'].set_visible(False)\n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.get_xaxis().set_ticks([])\n",
    "        ax.get_yaxis().set_ticks([])\n",
    "\n",
    "        im = imread(path)\n",
    "        ax.imshow(im)\n",
    "\n",
    "\n",
    "# 需要展示的样本个数\n",
    "num_imgs_to_show = 4\n",
    "# 随机抽取样本\n",
    "chosen_indices = random.choices(range(len_test), k=num_imgs_to_show)\n",
    "\n",
    "# 参考 https://stackoverflow.com/a/68209152\n",
    "fig = plt.figure(constrained_layout=True)\n",
    "fig.suptitle(\"Inference Results\")\n",
    "\n",
    "subfigs = fig.subfigures(nrows=3, ncols=1)\n",
    "\n",
    "# 读入第一时相影像\n",
    "im_paths = [osp.join(DATA_DIR, test_dataset.samples[idx]['image_t1']) for idx in chosen_indices]\n",
    "show_images_in_row(im_paths, subfigs[0], title='Image 1')\n",
    "\n",
    "# 读入第二时相影像\n",
    "im_paths = [osp.join(DATA_DIR, test_dataset.samples[idx]['image_t2']) for idx in chosen_indices]\n",
    "show_images_in_row(im_paths, subfigs[1], title='Image 2')\n",
    "\n",
    "# 读入变化图\n",
    "im_paths = [osp.join(out_dir, test_dataset.names[idx]) for idx in chosen_indices]\n",
    "show_images_in_row(im_paths, subfigs[2], title='Change Map')\n",
    "\n",
    "# 渲染结果\n",
    "fig.canvas.draw()\n",
    "Image.frombytes('RGB', fig.canvas.get_width_height(), fig.canvas.tostring_rgb())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 将推理结果打包并压缩为zip文件。如果修改了默认输出目录，也需要在此指令中做出对应修改。\n",
    "# 官方typo: submission -> submisson\n",
    "!zip -j submisson.zip /home/aistudio/exp/out/* > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考资料\n",
    "---\n",
    "\n",
    "- [遥感数据介绍](https://github.com/PaddleCV-SIG/PaddleRS/blob/develop/docs/data/rs_data_cn.md)\n",
    "- [PaddleRS文档](https://github.com/PaddleCV-SIG/PaddleRS/blob/develop/tutorials/train/README.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
